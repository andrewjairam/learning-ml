{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: CIFAR10\n",
    "- 32x32 pixel images that classify 10 labels:\n",
    "    - 0 = airplane\n",
    "    - 1 = automobile\n",
    "    - 2 = bird\n",
    "    - 3 = cat\n",
    "    - 4 = deer\n",
    "    - 5 = dog\n",
    "    - 6 = frog\n",
    "    - 7 = horse\n",
    "    - 8 = ship\n",
    "    - 9 = truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# Import torch core functionalities\n",
    "import torch\n",
    "# torch neural network library\n",
    "import torch.nn as nn\n",
    "# Activation functions\n",
    "import torch.nn.functional as F\n",
    "# Optimizer to do gradient descent\n",
    "import torch.optim as optim\n",
    "# For stuff like data \n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get and prepare the Data (in Pytorch Tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: Manual (We won't use this for this implementation)\n",
    "- Generally worse to do, but nice to get some intuition about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_data = torchvision.datasets.CIFAR10('data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the data:\n",
    "- each datapoint is given as a tuple of a pillow image and a label (see above)\n",
    "- unpacking the pillow image gives a 3x32x32 tensor (say we call it img_tensor)\n",
    "- img_tensor[0, :, :] = red intensity of each pixel, [1, :, :] = green intensity and [2, :, :] is blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDxyiiiv3E8wKKKKACiiigAooooA//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAQElEQVR4Ae3SsQkAAAgDwej+OytO8JXdW4cIRyqZfF5/ll+3D1BYIolQAAOuSCIUwIArkggFMOCKJEIBDLgiJFqhxgE/FKDuYgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_to_tensor is initialized as a method that converts an image to a tensor\n",
    "img_to_tensor = torchvision.transforms.ToTensor()\n",
    "# test tensor to img\n",
    "tensor_to_img = torchvision.transforms.ToPILImage()\n",
    "#plt.imshow(cifar10_data[0][0])\n",
    "t = img_to_tensor(cifar10_data[0][0])\n",
    "t[0]\n",
    "\n",
    "test = torch.FloatTensor(3,32,32)\n",
    "test[0, :, :] = 0\n",
    "test[1, :, :] = 0\n",
    "test[2, :, :] = 1\n",
    "test_img = tensor_to_img(test)\n",
    "test_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key point about torch.nn.conv2d:\n",
    "- we can input 4D tensors in the format: nSamples x mChannels x height x width to the convolutional layers, so for our case:\n",
    "    - 50 000 training samples\n",
    "    - 3 channels (RGB)\n",
    "    - 32x32 images\n",
    "    - need a 50 000 x 3 x 32 x 32 input tensor to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the data in this shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 3, 32, 32])\n",
      "torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "# Collect tensors in a list, concatenate them using stack\n",
    "X = []\n",
    "y = [] # For the output we will collect the integers as a list and convert to a longtensor later\n",
    "\n",
    "for (image, label) in cifar10_data:\n",
    "    X.append(img_to_tensor(image))\n",
    "    y.append(label)\n",
    "\n",
    "X_train = torch.stack(X)\n",
    "y_train = torch.LongTensor(y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: Use Data loading in pytorch\n",
    "- Generally nicer, can load your own data too\n",
    "- allows for automation of batch training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "img_to_tensor = torchvision.transforms.ToTensor()\n",
    "train_data = torchvision.datasets.CIFAR10('data', train=True, download=True, transform=img_to_tensor)\n",
    "print(train_data)\n",
    "# Train data[0][0] is the img tensor for the first sample\n",
    "# Train data[0][1] is the label for the first sample\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10('data', train=False, download=True, transform=img_to_tensor)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to split the training set into training data and validation data\n",
    "- recall: We update the weights based on the training loss, but judge model performance based on that training on validation loss\n",
    "- once weights are set, we leave them fixed and use the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid_size as a percent to split train_data\n",
    "valid_size = 0.20\n",
    "# Want to randomly shuffle the indices so we split training data and validation data randomly\n",
    "indices = list(range(len(train_data)))\n",
    "# shuffle indices list\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(indices)\n",
    "# Define split as the number of samples in the validation set according to the % split defined as valid_size\n",
    "split = int(valid_size * len(train_data)) \n",
    "valid_idx, train_idx = indices[:split], indices[split:] \n",
    "# Define sampler using these indices, which will be used for data loading:\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data using the below block of code, which we won't run yet: we might want to tune the batch size as a hyperparameter, and we'll do that in a box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = '???'\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.Dataloader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Understand CNN Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try one layer of the NN with discussed dimensions:\n",
    "- in_channels = 3 because we have 3 input channels: R,G and B\n",
    "- out_Channels = 6: a hyperparameter: number of kernels/filters applied in the layer\n",
    "- kernel size = 3, by convention we always use 3x3 kernels\n",
    "- stride = 1\n",
    "    - How the convolution is done:\n",
    "        - the layer has a 3-d filter w0\n",
    "        - to train on a, for example, red input: x[0, :, :], \n",
    "            - w0[0, :, :] is the 2d kernel that is applied to x[0, :, :]\n",
    "            - in one iteration of convolution (i.e. one stride):\n",
    "                - the layer does elementwise multiplication with the section of x[0,:,:] and w0[0,:,:], and sums everything up\n",
    "                    - say we get a result $R_{red}$\n",
    "                - repeat for the other channels (blue and green) to get $R_{blue}$ and $R_{green}$\n",
    "                - sum ALL the products of all the channels (i.e. $R_{red} + R_{blue} + R_{green}$ )\n",
    "                - add some bias term from some bias vector b0\n",
    "                - that corresponds to one square of the output\n",
    "                - move \"left\" to the next part of the image, and step equal to the stride\n",
    "        - that process is repeated for each kernel (w0,w1,w2,...,b1,b2,b3,... etc.)\n",
    "        - gives an output that has one dimension per kernel applied\n",
    "- 'same' padding means that an amount of zeros are padded on the input so that the output retains the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab one image\n",
    "for test_x in X_train:\n",
    "    break\n",
    "\n",
    "conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding='same')\n",
    "x = conv1(test_x)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we got 6 outputs from one input, with unchanged dimensions (i.e. each output retains the 32x32 original image dimensions), as expected, since we defined 6 kernels (by setting 6 out_channels), and we made the image padded enough such that it retains the same dimensions.\n",
    "\n",
    "Note: we can input either one input (which is 3d), or a 4-D tensor into the convolutional layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One pooling layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 16, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(kernel_size = 2, stride=2)\n",
    "x = pool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying max pooling, we reduce the DIMENSIONS (i.e. 32x32 -> 16x16), but not the OUTPUTS (i.e. the 6 outputs of the convolution layer fed into the pooling layer still result in 6 output). <br>\n",
    "\n",
    "Recall that we could calculate the out dimensions for either convolution/pooling layers using the formula: <br>\n",
    "\n",
    "$o = \\frac{i+2p-k}{s} + 1$\n",
    "\n",
    "where: <br>\n",
    "- $i$ = original image dimensions before the transformation: \n",
    "    - we had a 32x32 input, so $i = 32$\n",
    "- $p$ = padding\n",
    "    - we don't pad the pooling layer since we want to reduce the dimensions, so $p = 0$\n",
    "- $k$ = kernel dimensions\n",
    "    - we inputted $k = 2$\n",
    "- s = stride length\n",
    "    - we inputted $s = 2$\n",
    "\n",
    "The above parameters in the equation give $o = 16$, as expected. We could change parameters and get different dimensions, which can be calculated using the above formula. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: make the CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, we use a convolutional kernel of size 3. It was proved by the VGG CNN that all convolutions can be approximated by a 3x3 kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_kernel_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the neural network (i.e. number of convolution/pooling layers and their setup) is a hyperparameter. Let's use a VGG-style CNN architecture:\n",
    "\n",
    "- Input -> conv layer 1 w/ dropout -> conv layer 2 -> pool 1\n",
    "- conv layer 3 w/ dropout -> conv layer 4 -> pool 2\n",
    "- linear fully connected 1 -> linear fully connected 2 -> linear fc3 (the output layer) -> softmax -> output classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- summary: 2 conv layers, 1 pool, repeat, output to linear -> classifier <br>\n",
    "Note: in this architecture, \n",
    "- the convolution layers do not reduce dimensions: i.e. set padding = same.\n",
    "- the number of kernels is constant in each of the paired conv. layers, and INCREASES the deeper you go\n",
    "    - as an example: in VGG, the first 2 conv layers used 64 kernels each, then pooled, then the next layer used 128 kernels, then pooled, then next 2 used 256 kernels\n",
    "    - resulted in outputs getting \"thicker\" but smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below image visualizes the original VGG CNN, which is the inspiration for this implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VGG structure Visualized](https://www.researchgate.net/profile/Hasane-Shaik/publication/369178183/figure/fig5/AS:11431281127143024@1678957943550/VGG-Neural-Network-Architecture-Source.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial input = 3 (RGB)\n",
    "\n",
    "# conv layer 1\n",
    "num_filters_1 = 6\n",
    "conv_stride_1 = 1\n",
    "\n",
    "# dropout probability 1\n",
    "drop1 = 0.2 \n",
    "\n",
    "# conv layer 2\n",
    "num_filters_2 = num_filters_1\n",
    "conv_stride_2 = 1\n",
    "\n",
    "# pooling 1\n",
    "pool_kernel_1 = 2\n",
    "pool_stride_1 = 2\n",
    "\n",
    "# conv layer 3\n",
    "num_filters_3 = 12\n",
    "conv_stride_3 = 1\n",
    "\n",
    "# dropout probability 2\n",
    "drop2 = 0.2 \n",
    "\n",
    "# conv layer 4\n",
    "num_filters_4 = num_filters_3\n",
    "conv_stride_4 = 1\n",
    "\n",
    "# pooling 2\n",
    "pool_kernel_2 = 2\n",
    "pool_stride_2 = 2\n",
    "\n",
    "# linear 1\n",
    "linear_units_1 = 80\n",
    "# linear 2\n",
    "linear_units_2 = 40\n",
    "\n",
    "# Final output = 10\n",
    "\n",
    "# Training hyperparameters\n",
    "learn_rate = 0.001\n",
    "epochs = 1000 #4500\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "my_conv = nn.Conv2d(in_channels=3, out_channels=num_filters_1, kernel_size=conv_kernel_size, stride=conv_stride_1, padding='same')\n",
    "\n",
    "# grab one image\n",
    "for sample in X_train:\n",
    "    break\n",
    "\n",
    "test_x = my_conv(sample)\n",
    "test_x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # -> current DIM of one sample: 3x32x32\n",
    "\n",
    "        ### Section 1: first block of convolution\n",
    "\n",
    "        # 1st layer: in channels = 3 (RGB), out channels = number of filters we defined as hyperparameter\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=num_filters_1, kernel_size=conv_kernel_size, stride=conv_stride_1, padding='same')\n",
    "        self.dropout1 = nn.Dropout(drop1)\n",
    "        # -> current DIM of one sample: (num_filters_1)x32x32\n",
    "\n",
    "        # 2nd layer: in_channels = out channels of 1st layer, out_channels = num of filters we defined as hyperparameter\n",
    "        self.conv2 = nn.Conv2d(in_channels=num_filters_1, out_channels=num_filters_2, kernel_size=conv_kernel_size, stride=conv_stride_2, padding='same')\n",
    "        \n",
    "        # -> current DIM of one sample: (num_filters_2)x32x32\n",
    "\n",
    "        # 1st pooling layer\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=pool_kernel_1, stride=pool_stride_1)\n",
    "\n",
    "        # -> current DIM of one sample: o1 = (i+2p-k)/s + 1 = (32+2(0)-pool_kernel_1)/(pool_stride_1) + 1 = (32 - pool_kernel_1 + pool_stride_1)/(pool_stride_1)\n",
    "        # o1 = (i+2p-k)/s + 1 = (32+2(0)-pool_kernel_1)/(pool_stride_1) + 1 = (32 - pool_kernel_1 + pool_stride_1)/(pool_stride_1)\n",
    "        # so current dim: (num_filters_2) x (32 - pool_kernel_1 + pool_stride_1)/(pool_stride_1) x (32 - pool_kernel_1 + pool_stride_1)/(pool_stride_1)\n",
    "        self.o1 = int(((32 - pool_kernel_1) / (pool_stride_1)) + 1)\n",
    "\n",
    "        ### Section 2: second block of convolution\n",
    "\n",
    "        # 3rd layer: in = num_filters_2, out = num_filters 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=num_filters_2, out_channels=num_filters_3, kernel_size=conv_kernel_size, stride=conv_stride_3, padding='same')\n",
    "        self.dropout2 = nn.Dropout(drop2)\n",
    "        # -> current DIM of one sample: (num_filters_3) x o1 x o1\n",
    "\n",
    "        # 4th layer: in = num_filters_3, out = num_filters 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=num_filters_3, out_channels=num_filters_4, kernel_size=conv_kernel_size, stride=conv_stride_4, padding='same')\n",
    "\n",
    "        # -> current DIM of one sample: (num_filters_4) x o1 x o1\n",
    "\n",
    "        # second pooling\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=pool_kernel_2, stride=pool_stride_2)\n",
    "\n",
    "        # current DIM of one sample: o2 = (o1 - pool_kernel_2 + pool_stride_2)/(pool_stride_2)\n",
    "        # gives: dim = num_filters_4 x o2 x o2\n",
    "        self.o2 = int(((self.o1 - pool_kernel_2) / (pool_stride_2)) + 1)\n",
    "\n",
    "        ### section 3: Linear layers\n",
    "        \n",
    "        # -> Current DIM of one sample: flattened to 1x(num_filters_4 x o2 x o2)\n",
    "\n",
    "        self.fc1 = nn.Linear(num_filters_4*self.o2*self.o2, linear_units_1)\n",
    "\n",
    "        # -> Current DIM of one sample: 1 x linear_units_1\n",
    "\n",
    "        self.fc2 = nn.Linear(linear_units_1, linear_units_2)\n",
    "\n",
    "        # -> Current DIM of one sample: 1 x linear_units_2\n",
    "\n",
    "        self.out = nn.Linear(linear_units_2, 10)\n",
    "\n",
    "        # -> Current DIM of one sample: 1 x 10\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Flatten x for linear layers \n",
    "        x = x.view(-1, num_filters_4*self.o2*self.o2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = F.tanh(self.fc1(x))\n",
    "        # x = F.tanh(self.fc2(x))\n",
    "        # NOTE: no activation for the final output\n",
    "        x = self.out(x)\n",
    "        # DONT Apply softmax\n",
    "        #return F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (conv4): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=768, out_features=80, bias=True)\n",
       "  (fc2): Linear(in_features=80, out_features=40, bias=True)\n",
       "  (out): Linear(in_features=40, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make the loss function optimizer for backpropagation:\n",
    "\n",
    "- using a cross entropy loss criterion (note, this is conventional for multi-class classification): <br>\n",
    "$ H(p, q) = -\\sum_{x \\epsilon classes} p(x)log q(x) $\n",
    "- we'll use the Adam optimizer, which is a common industry choice since it needs minimal tuning:\n",
    "    - Gets rapid convergence\n",
    "    - why? incorporates Adaptive learning rate and momentum in gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss function optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learn_rate)\n",
    "learn_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let's track the time needed to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up batch training with the Dataloader module:\n",
    "- batch size is a hyperparameter inputted in the hyperparameter block above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The samplers we defined above is essentially the same as shuffle=True, except we needed to use them to split training and validation\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize what this Dataloader object does:\n",
    "- divides the training set by the batch size, rounded up\n",
    "    - i.e. if we select batchsize = 6: the training data gets divided as 50 000 * (1-0.2) / 6 = 6666.666 = 6667 buckets/batches\n",
    "        - the 1-0.2 comes because we coded above that 20% of the training data should be split into validation data \n",
    "    - stores training tensor and training label in a tuple that can be enumerated\n",
    "- We train by: \n",
    "    - taking one batch at a time, \n",
    "    - making a prediction on each item in the batch\n",
    "    - find the loss of the predictions on the batch to the actual labels of the batch\n",
    "    - backpropagate to update weights (kernel values for convolutional layers, linear weights for fully connected layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([500, 3, 32, 32])\n",
      "tensor([8, 8, 3, 7, 7, 1, 5, 4, 3, 1, 0, 5, 4, 9, 6, 9, 9, 3, 4, 5, 2, 1, 8, 8,\n",
      "        6, 8, 1, 2, 0, 7, 2, 0, 1, 3, 6, 6, 1, 3, 0, 2, 8, 0, 6, 7, 6, 8, 4, 1,\n",
      "        3, 0, 4, 8, 1, 4, 1, 4, 0, 3, 8, 6, 4, 2, 9, 6, 0, 4, 2, 0, 2, 3, 3, 9,\n",
      "        4, 8, 7, 8, 1, 1, 5, 6, 5, 2, 5, 2, 2, 3, 8, 0, 0, 6, 3, 2, 3, 5, 7, 5,\n",
      "        9, 7, 2, 8, 5, 7, 4, 8, 9, 2, 1, 9, 8, 1, 2, 6, 0, 4, 3, 3, 7, 2, 5, 2,\n",
      "        3, 3, 3, 6, 6, 1, 6, 2, 2, 5, 0, 9, 3, 7, 9, 1, 3, 8, 2, 0, 0, 3, 0, 1,\n",
      "        5, 6, 3, 8, 1, 8, 2, 6, 0, 8, 3, 7, 7, 4, 3, 7, 5, 4, 0, 9, 8, 1, 5, 8,\n",
      "        7, 7, 0, 3, 2, 9, 5, 0, 5, 5, 4, 7, 6, 4, 8, 7, 6, 6, 0, 6, 6, 6, 7, 6,\n",
      "        7, 3, 3, 9, 9, 4, 2, 8, 1, 2, 3, 5, 6, 1, 3, 7, 1, 4, 8, 6, 3, 3, 2, 3,\n",
      "        2, 8, 1, 4, 6, 1, 4, 4, 8, 5, 2, 9, 0, 7, 3, 9, 0, 7, 6, 8, 7, 7, 9, 9,\n",
      "        1, 0, 5, 3, 0, 1, 8, 3, 4, 8, 1, 5, 1, 5, 5, 7, 0, 6, 7, 5, 8, 8, 0, 6,\n",
      "        1, 9, 2, 3, 6, 5, 5, 0, 3, 7, 0, 8, 9, 3, 7, 0, 9, 5, 8, 8, 3, 8, 8, 8,\n",
      "        7, 8, 7, 0, 4, 5, 2, 5, 6, 2, 9, 8, 9, 4, 0, 3, 1, 9, 0, 8, 1, 7, 2, 9,\n",
      "        6, 8, 6, 3, 5, 2, 3, 2, 2, 0, 4, 1, 0, 5, 4, 7, 2, 7, 5, 7, 8, 6, 1, 4,\n",
      "        7, 5, 5, 7, 1, 2, 4, 4, 7, 4, 0, 5, 6, 2, 7, 0, 0, 1, 0, 0, 1, 9, 1, 5,\n",
      "        2, 0, 5, 1, 0, 0, 8, 3, 3, 8, 0, 0, 9, 5, 1, 0, 6, 1, 9, 5, 6, 7, 7, 8,\n",
      "        3, 5, 6, 6, 1, 8, 0, 4, 3, 9, 6, 7, 8, 6, 4, 5, 7, 7, 7, 9, 3, 0, 2, 4,\n",
      "        1, 3, 7, 4, 4, 2, 3, 3, 0, 6, 8, 5, 5, 0, 3, 3, 4, 4, 7, 7, 4, 0, 5, 8,\n",
      "        4, 9, 5, 2, 8, 2, 1, 1, 1, 4, 7, 4, 1, 2, 3, 2, 3, 0, 0, 9, 0, 1, 9, 1,\n",
      "        2, 7, 7, 7, 1, 6, 3, 9, 7, 8, 7, 5, 6, 1, 9, 7, 0, 6, 9, 8, 4, 9, 6, 1,\n",
      "        6, 3, 6, 3, 8, 0, 8, 3, 4, 4, 8, 3, 3, 4, 3, 3, 2, 2, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "for b,(X_train, y_train) in enumerate(train_loader):\n",
    "    print(b)\n",
    "    print(X_train.shape)\n",
    "    print(y_train)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loop:\n",
    "- make a prediction on training set\n",
    "- compute training loss and update weights using it\n",
    "- keep track of the accuracy of predictions for debug/model performance/sanity\n",
    "- after training (i.e. going through batches so that we cover all the training data), test on validation set\n",
    "    - no weight updates here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 40, Training Loss: 2.122230052947998\n",
      "Epoch: 0, Batch: 80, Training Loss: 1.97038733959198\n",
      "Epoch: 0, Validation Loss: 1.970468521118164\n",
      "Epoch: 1, Batch: 40, Training Loss: 1.8442213535308838\n",
      "Epoch: 1, Batch: 80, Training Loss: 1.854427695274353\n",
      "Epoch: 1, Validation Loss: 1.816688060760498\n",
      "Epoch: 2, Batch: 40, Training Loss: 1.7802191972732544\n",
      "Epoch: 2, Batch: 80, Training Loss: 1.8112419843673706\n",
      "Epoch: 2, Validation Loss: 1.714227318763733\n",
      "Epoch: 3, Batch: 40, Training Loss: 1.6624163389205933\n",
      "Epoch: 3, Batch: 80, Training Loss: 1.6202425956726074\n",
      "Epoch: 3, Validation Loss: 1.5982654094696045\n",
      "Epoch: 4, Batch: 40, Training Loss: 1.5341696739196777\n",
      "Epoch: 4, Batch: 80, Training Loss: 1.5025302171707153\n",
      "Epoch: 4, Validation Loss: 1.6011933088302612\n",
      "Epoch: 5, Batch: 40, Training Loss: 1.554792046546936\n",
      "Epoch: 5, Batch: 80, Training Loss: 1.5371434688568115\n",
      "Epoch: 5, Validation Loss: 1.5391980409622192\n",
      "Epoch: 6, Batch: 40, Training Loss: 1.4757146835327148\n",
      "Epoch: 6, Batch: 80, Training Loss: 1.3708957433700562\n",
      "Epoch: 6, Validation Loss: 1.4421314001083374\n",
      "Epoch: 7, Batch: 40, Training Loss: 1.439273476600647\n",
      "Epoch: 7, Batch: 80, Training Loss: 1.3639767169952393\n",
      "Epoch: 7, Validation Loss: 1.3949673175811768\n",
      "Epoch: 8, Batch: 40, Training Loss: 1.4782121181488037\n",
      "Epoch: 8, Batch: 80, Training Loss: 1.4240788221359253\n",
      "Epoch: 8, Validation Loss: 1.4238827228546143\n",
      "Epoch: 9, Batch: 40, Training Loss: 1.3104058504104614\n",
      "Epoch: 9, Batch: 80, Training Loss: 1.387853980064392\n",
      "Epoch: 9, Validation Loss: 1.3623629808425903\n",
      "Epoch: 10, Batch: 40, Training Loss: 1.3603880405426025\n",
      "Epoch: 10, Batch: 80, Training Loss: 1.3367421627044678\n",
      "Epoch: 10, Validation Loss: 1.407471776008606\n",
      "Epoch: 11, Batch: 40, Training Loss: 1.3123083114624023\n",
      "Epoch: 11, Batch: 80, Training Loss: 1.3338731527328491\n",
      "Epoch: 11, Validation Loss: 1.3113614320755005\n",
      "Epoch: 12, Batch: 40, Training Loss: 1.3267382383346558\n",
      "Epoch: 12, Batch: 80, Training Loss: 1.3579319715499878\n",
      "Epoch: 12, Validation Loss: 1.3414665460586548\n",
      "Epoch: 13, Batch: 40, Training Loss: 1.3227349519729614\n",
      "Epoch: 13, Batch: 80, Training Loss: 1.266055703163147\n",
      "Epoch: 13, Validation Loss: 1.338410496711731\n",
      "Epoch: 14, Batch: 40, Training Loss: 1.2606734037399292\n",
      "Epoch: 14, Batch: 80, Training Loss: 1.2939308881759644\n",
      "Epoch: 14, Validation Loss: 1.3228040933609009\n",
      "Epoch: 15, Batch: 40, Training Loss: 1.2586240768432617\n",
      "Epoch: 15, Batch: 80, Training Loss: 1.3241710662841797\n",
      "Epoch: 15, Validation Loss: 1.3559483289718628\n",
      "Epoch: 16, Batch: 40, Training Loss: 1.3667341470718384\n",
      "Epoch: 16, Batch: 80, Training Loss: 1.33756685256958\n",
      "Epoch: 16, Validation Loss: 1.278451919555664\n",
      "Epoch: 17, Batch: 40, Training Loss: 1.3298027515411377\n",
      "Epoch: 17, Batch: 80, Training Loss: 1.3093611001968384\n",
      "Epoch: 17, Validation Loss: 1.2839667797088623\n",
      "Epoch: 18, Batch: 40, Training Loss: 1.2566825151443481\n",
      "Epoch: 18, Batch: 80, Training Loss: 1.3122196197509766\n",
      "Epoch: 18, Validation Loss: 1.3243708610534668\n",
      "Epoch: 19, Batch: 40, Training Loss: 1.2121959924697876\n",
      "Epoch: 19, Batch: 80, Training Loss: 1.2850706577301025\n",
      "Epoch: 19, Validation Loss: 1.244731068611145\n",
      "Epoch: 20, Batch: 40, Training Loss: 1.3132879734039307\n",
      "Epoch: 20, Batch: 80, Training Loss: 1.2393810749053955\n",
      "Epoch: 20, Validation Loss: 1.2213259935379028\n",
      "Epoch: 21, Batch: 40, Training Loss: 1.209513545036316\n",
      "Epoch: 21, Batch: 80, Training Loss: 1.204723596572876\n",
      "Epoch: 21, Validation Loss: 1.2869181632995605\n",
      "Epoch: 22, Batch: 40, Training Loss: 1.2246986627578735\n",
      "Epoch: 22, Batch: 80, Training Loss: 1.1572028398513794\n",
      "Epoch: 22, Validation Loss: 1.2671641111373901\n",
      "Epoch: 23, Batch: 40, Training Loss: 1.2455523014068604\n",
      "Epoch: 23, Batch: 80, Training Loss: 1.2405060529708862\n",
      "Epoch: 23, Validation Loss: 1.2679997682571411\n",
      "Epoch: 24, Batch: 40, Training Loss: 1.2327126264572144\n",
      "Epoch: 24, Batch: 80, Training Loss: 1.1735368967056274\n",
      "Epoch: 24, Validation Loss: 1.309043526649475\n",
      "Epoch: 25, Batch: 40, Training Loss: 1.2409954071044922\n",
      "Epoch: 25, Batch: 80, Training Loss: 1.2231955528259277\n",
      "Epoch: 25, Validation Loss: 1.2680034637451172\n",
      "Epoch: 26, Batch: 40, Training Loss: 1.2338694334030151\n",
      "Epoch: 26, Batch: 80, Training Loss: 1.1459050178527832\n",
      "Epoch: 26, Validation Loss: 1.195764183998108\n",
      "Epoch: 27, Batch: 40, Training Loss: 1.1628636121749878\n",
      "Epoch: 27, Batch: 80, Training Loss: 1.227344274520874\n",
      "Epoch: 27, Validation Loss: 1.1486037969589233\n",
      "Epoch: 28, Batch: 40, Training Loss: 1.22544527053833\n",
      "Epoch: 28, Batch: 80, Training Loss: 1.1131939888000488\n",
      "Epoch: 28, Validation Loss: 1.1815271377563477\n",
      "Epoch: 29, Batch: 40, Training Loss: 1.107526421546936\n",
      "Epoch: 29, Batch: 80, Training Loss: 1.2012628316879272\n",
      "Epoch: 29, Validation Loss: 1.2491116523742676\n",
      "Epoch: 30, Batch: 40, Training Loss: 1.2406178712844849\n",
      "Epoch: 30, Batch: 80, Training Loss: 1.1655269861221313\n",
      "Epoch: 30, Validation Loss: 1.194321870803833\n",
      "Epoch: 31, Batch: 40, Training Loss: 1.0701510906219482\n",
      "Epoch: 31, Batch: 80, Training Loss: 1.1116942167282104\n",
      "Epoch: 31, Validation Loss: 1.201024055480957\n",
      "Epoch: 32, Batch: 40, Training Loss: 1.1355454921722412\n",
      "Epoch: 32, Batch: 80, Training Loss: 1.131020188331604\n",
      "Epoch: 32, Validation Loss: 1.1937963962554932\n",
      "Epoch: 33, Batch: 40, Training Loss: 1.1666210889816284\n",
      "Epoch: 33, Batch: 80, Training Loss: 1.200476884841919\n",
      "Epoch: 33, Validation Loss: 1.1215827465057373\n",
      "Epoch: 34, Batch: 40, Training Loss: 1.0787091255187988\n",
      "Epoch: 34, Batch: 80, Training Loss: 1.0872869491577148\n",
      "Epoch: 34, Validation Loss: 1.0957064628601074\n",
      "Epoch: 35, Batch: 40, Training Loss: 1.0730037689208984\n",
      "Epoch: 35, Batch: 80, Training Loss: 1.09928297996521\n",
      "Epoch: 35, Validation Loss: 1.2470958232879639\n",
      "Epoch: 36, Batch: 40, Training Loss: 1.1395891904830933\n",
      "Epoch: 36, Batch: 80, Training Loss: 1.077264428138733\n",
      "Epoch: 36, Validation Loss: 1.1541906595230103\n",
      "Epoch: 37, Batch: 40, Training Loss: 1.0722745656967163\n",
      "Epoch: 37, Batch: 80, Training Loss: 1.0606822967529297\n",
      "Epoch: 37, Validation Loss: 1.111719012260437\n",
      "Epoch: 38, Batch: 40, Training Loss: 1.0300027132034302\n",
      "Epoch: 38, Batch: 80, Training Loss: 1.1321897506713867\n",
      "Epoch: 38, Validation Loss: 1.0944010019302368\n",
      "Epoch: 39, Batch: 40, Training Loss: 1.0840359926223755\n",
      "Epoch: 39, Batch: 80, Training Loss: 1.0205756425857544\n",
      "Epoch: 39, Validation Loss: 1.102992057800293\n",
      "Epoch: 40, Batch: 40, Training Loss: 1.0585269927978516\n",
      "Epoch: 40, Batch: 80, Training Loss: 1.0290448665618896\n",
      "Epoch: 40, Validation Loss: 1.1546260118484497\n",
      "Epoch: 41, Batch: 40, Training Loss: 1.109818696975708\n",
      "Epoch: 41, Batch: 80, Training Loss: 1.0545512437820435\n",
      "Epoch: 41, Validation Loss: 1.1075549125671387\n",
      "Epoch: 42, Batch: 40, Training Loss: 1.0515384674072266\n",
      "Epoch: 42, Batch: 80, Training Loss: 1.077818751335144\n",
      "Epoch: 42, Validation Loss: 1.1554099321365356\n",
      "Epoch: 43, Batch: 40, Training Loss: 0.9993043541908264\n",
      "Epoch: 43, Batch: 80, Training Loss: 1.1714844703674316\n",
      "Epoch: 43, Validation Loss: 1.1120606660842896\n",
      "Epoch: 44, Batch: 40, Training Loss: 0.9761807322502136\n",
      "Epoch: 44, Batch: 80, Training Loss: 1.061953067779541\n",
      "Epoch: 44, Validation Loss: 1.1954786777496338\n",
      "Epoch: 45, Batch: 40, Training Loss: 0.9381787180900574\n",
      "Epoch: 45, Batch: 80, Training Loss: 1.0480124950408936\n",
      "Epoch: 45, Validation Loss: 1.2007848024368286\n",
      "Epoch: 46, Batch: 40, Training Loss: 1.0038188695907593\n",
      "Epoch: 46, Batch: 80, Training Loss: 1.0551762580871582\n",
      "Epoch: 46, Validation Loss: 1.1198810338974\n",
      "Epoch: 47, Batch: 40, Training Loss: 0.9894622564315796\n",
      "Epoch: 47, Batch: 80, Training Loss: 1.0056549310684204\n",
      "Epoch: 47, Validation Loss: 1.1605712175369263\n",
      "Epoch: 48, Batch: 40, Training Loss: 1.0488253831863403\n",
      "Epoch: 48, Batch: 80, Training Loss: 0.9503172636032104\n",
      "Epoch: 48, Validation Loss: 1.080978274345398\n",
      "Epoch: 49, Batch: 40, Training Loss: 0.9648561477661133\n",
      "Epoch: 49, Batch: 80, Training Loss: 1.0127675533294678\n",
      "Epoch: 49, Validation Loss: 1.0813281536102295\n",
      "Epoch: 50, Batch: 40, Training Loss: 1.021183967590332\n",
      "Epoch: 50, Batch: 80, Training Loss: 1.0309594869613647\n",
      "Epoch: 50, Validation Loss: 1.1269609928131104\n",
      "Epoch: 51, Batch: 40, Training Loss: 0.9979514479637146\n",
      "Epoch: 51, Batch: 80, Training Loss: 1.0161346197128296\n",
      "Epoch: 51, Validation Loss: 1.1244146823883057\n",
      "Epoch: 52, Batch: 40, Training Loss: 0.9958593249320984\n",
      "Epoch: 52, Batch: 80, Training Loss: 0.9520010948181152\n",
      "Epoch: 52, Validation Loss: 0.974959135055542\n",
      "Epoch: 53, Batch: 40, Training Loss: 0.989118754863739\n",
      "Epoch: 53, Batch: 80, Training Loss: 0.9795523881912231\n",
      "Epoch: 53, Validation Loss: 1.0584052801132202\n",
      "Epoch: 54, Batch: 40, Training Loss: 1.004928469657898\n",
      "Epoch: 54, Batch: 80, Training Loss: 1.0204037427902222\n",
      "Epoch: 54, Validation Loss: 1.0815386772155762\n",
      "Epoch: 55, Batch: 40, Training Loss: 0.9604312181472778\n",
      "Epoch: 55, Batch: 80, Training Loss: 1.024369716644287\n",
      "Epoch: 55, Validation Loss: 1.0747929811477661\n",
      "Epoch: 56, Batch: 40, Training Loss: 0.8820191025733948\n",
      "Epoch: 56, Batch: 80, Training Loss: 0.929198682308197\n",
      "Epoch: 56, Validation Loss: 1.087167501449585\n",
      "Epoch: 57, Batch: 40, Training Loss: 1.0159597396850586\n",
      "Epoch: 57, Batch: 80, Training Loss: 0.9752456545829773\n",
      "Epoch: 57, Validation Loss: 1.0501283407211304\n",
      "Epoch: 58, Batch: 40, Training Loss: 0.9042584896087646\n",
      "Epoch: 58, Batch: 80, Training Loss: 1.0458308458328247\n",
      "Epoch: 58, Validation Loss: 1.0236055850982666\n",
      "Epoch: 59, Batch: 40, Training Loss: 0.9062610268592834\n",
      "Epoch: 59, Batch: 80, Training Loss: 1.052014946937561\n",
      "Epoch: 59, Validation Loss: 1.0123878717422485\n",
      "Epoch: 60, Batch: 40, Training Loss: 1.028963565826416\n",
      "Epoch: 60, Batch: 80, Training Loss: 0.953324019908905\n",
      "Epoch: 60, Validation Loss: 1.015017032623291\n",
      "Epoch: 61, Batch: 40, Training Loss: 0.9871042966842651\n",
      "Epoch: 61, Batch: 80, Training Loss: 0.9464548230171204\n",
      "Epoch: 61, Validation Loss: 1.125400424003601\n",
      "Epoch: 62, Batch: 40, Training Loss: 0.9163963794708252\n",
      "Epoch: 62, Batch: 80, Training Loss: 0.9299665689468384\n",
      "Epoch: 62, Validation Loss: 1.1651755571365356\n",
      "Epoch: 63, Batch: 40, Training Loss: 0.9088478684425354\n",
      "Epoch: 63, Batch: 80, Training Loss: 0.9359017014503479\n",
      "Epoch: 63, Validation Loss: 1.0586024522781372\n",
      "Epoch: 64, Batch: 40, Training Loss: 0.8833407759666443\n",
      "Epoch: 64, Batch: 80, Training Loss: 0.9876714944839478\n",
      "Epoch: 64, Validation Loss: 1.0087218284606934\n",
      "Epoch: 65, Batch: 40, Training Loss: 0.8826237916946411\n",
      "Epoch: 65, Batch: 80, Training Loss: 0.970041036605835\n",
      "Epoch: 65, Validation Loss: 1.0017985105514526\n",
      "Epoch: 66, Batch: 40, Training Loss: 0.9579935073852539\n",
      "Epoch: 66, Batch: 80, Training Loss: 0.8552696108818054\n",
      "Epoch: 66, Validation Loss: 1.04153573513031\n",
      "Epoch: 67, Batch: 40, Training Loss: 0.9024643898010254\n",
      "Epoch: 67, Batch: 80, Training Loss: 0.9470290541648865\n",
      "Epoch: 67, Validation Loss: 1.1384905576705933\n",
      "Epoch: 68, Batch: 40, Training Loss: 0.9448469281196594\n",
      "Epoch: 68, Batch: 80, Training Loss: 0.8438677191734314\n",
      "Epoch: 68, Validation Loss: 0.9328257441520691\n",
      "Epoch: 69, Batch: 40, Training Loss: 0.9354449510574341\n",
      "Epoch: 69, Batch: 80, Training Loss: 0.9572890996932983\n",
      "Epoch: 69, Validation Loss: 1.091740369796753\n",
      "Epoch: 70, Batch: 40, Training Loss: 0.8080796003341675\n",
      "Epoch: 70, Batch: 80, Training Loss: 0.8667482137680054\n",
      "Epoch: 70, Validation Loss: 1.0906450748443604\n",
      "Epoch: 71, Batch: 40, Training Loss: 0.9169763922691345\n",
      "Epoch: 71, Batch: 80, Training Loss: 0.982384443283081\n",
      "Epoch: 71, Validation Loss: 1.0012457370758057\n",
      "Epoch: 72, Batch: 40, Training Loss: 0.9226213693618774\n",
      "Epoch: 72, Batch: 80, Training Loss: 0.8528922200202942\n",
      "Epoch: 72, Validation Loss: 0.9687994718551636\n",
      "Epoch: 73, Batch: 40, Training Loss: 0.9206913113594055\n",
      "Epoch: 73, Batch: 80, Training Loss: 1.0258091688156128\n",
      "Epoch: 73, Validation Loss: 1.0812751054763794\n",
      "Epoch: 74, Batch: 40, Training Loss: 0.9688432216644287\n",
      "Epoch: 74, Batch: 80, Training Loss: 0.9240162968635559\n",
      "Epoch: 74, Validation Loss: 0.9708970785140991\n",
      "Epoch: 75, Batch: 40, Training Loss: 0.9579541683197021\n",
      "Epoch: 75, Batch: 80, Training Loss: 0.8456865549087524\n",
      "Epoch: 75, Validation Loss: 1.073433756828308\n",
      "Epoch: 76, Batch: 40, Training Loss: 0.9034774899482727\n",
      "Epoch: 76, Batch: 80, Training Loss: 0.9213578104972839\n",
      "Epoch: 76, Validation Loss: 0.925142228603363\n",
      "Epoch: 77, Batch: 40, Training Loss: 0.925331711769104\n",
      "Epoch: 77, Batch: 80, Training Loss: 0.8729403614997864\n",
      "Epoch: 77, Validation Loss: 1.028866171836853\n",
      "Epoch: 78, Batch: 40, Training Loss: 0.9649835824966431\n",
      "Epoch: 78, Batch: 80, Training Loss: 0.8635894656181335\n",
      "Epoch: 78, Validation Loss: 0.9942028522491455\n",
      "Epoch: 79, Batch: 40, Training Loss: 0.8180736303329468\n",
      "Epoch: 79, Batch: 80, Training Loss: 0.8546206951141357\n",
      "Epoch: 79, Validation Loss: 1.0523051023483276\n",
      "Epoch: 80, Batch: 40, Training Loss: 0.8047604560852051\n",
      "Epoch: 80, Batch: 80, Training Loss: 0.8708324432373047\n",
      "Epoch: 80, Validation Loss: 1.0664860010147095\n",
      "Epoch: 81, Batch: 40, Training Loss: 0.746656596660614\n",
      "Epoch: 81, Batch: 80, Training Loss: 0.899362325668335\n",
      "Epoch: 81, Validation Loss: 1.0467766523361206\n",
      "Epoch: 82, Batch: 40, Training Loss: 0.852324903011322\n",
      "Epoch: 82, Batch: 80, Training Loss: 0.835203230381012\n",
      "Epoch: 82, Validation Loss: 1.041113257408142\n",
      "Epoch: 83, Batch: 40, Training Loss: 0.9332159161567688\n",
      "Epoch: 83, Batch: 80, Training Loss: 0.9557285308837891\n",
      "Epoch: 83, Validation Loss: 1.0608618259429932\n",
      "Epoch: 84, Batch: 40, Training Loss: 0.8515757322311401\n",
      "Epoch: 84, Batch: 80, Training Loss: 0.905174970626831\n",
      "Epoch: 84, Validation Loss: 1.0611414909362793\n",
      "Epoch: 85, Batch: 40, Training Loss: 0.8770184516906738\n",
      "Epoch: 85, Batch: 80, Training Loss: 0.8832612037658691\n",
      "Epoch: 85, Validation Loss: 1.0345368385314941\n",
      "Epoch: 86, Batch: 40, Training Loss: 0.8800453543663025\n",
      "Epoch: 86, Batch: 80, Training Loss: 0.8861360549926758\n",
      "Epoch: 86, Validation Loss: 1.0808885097503662\n",
      "Epoch: 87, Batch: 40, Training Loss: 0.8338060975074768\n",
      "Epoch: 87, Batch: 80, Training Loss: 0.8255431652069092\n",
      "Epoch: 87, Validation Loss: 1.0753291845321655\n",
      "Epoch: 88, Batch: 40, Training Loss: 0.8180858492851257\n",
      "Epoch: 88, Batch: 80, Training Loss: 0.8338834047317505\n",
      "Epoch: 88, Validation Loss: 1.0476343631744385\n",
      "Epoch: 89, Batch: 40, Training Loss: 0.8419014811515808\n",
      "Epoch: 89, Batch: 80, Training Loss: 0.8529652953147888\n",
      "Epoch: 89, Validation Loss: 0.9798399806022644\n",
      "Epoch: 90, Batch: 40, Training Loss: 0.8025394678115845\n",
      "Epoch: 90, Batch: 80, Training Loss: 0.7878364324569702\n",
      "Epoch: 90, Validation Loss: 1.087138056755066\n",
      "Epoch: 91, Batch: 40, Training Loss: 0.8695129156112671\n",
      "Epoch: 91, Batch: 80, Training Loss: 0.8277822732925415\n",
      "Epoch: 91, Validation Loss: 0.975950300693512\n",
      "Epoch: 92, Batch: 40, Training Loss: 0.8317118287086487\n",
      "Epoch: 92, Batch: 80, Training Loss: 0.797935962677002\n",
      "Epoch: 92, Validation Loss: 0.9751735925674438\n",
      "Epoch: 93, Batch: 40, Training Loss: 0.7757701873779297\n",
      "Epoch: 93, Batch: 80, Training Loss: 0.7888751029968262\n",
      "Epoch: 93, Validation Loss: 0.9828130602836609\n",
      "Epoch: 94, Batch: 40, Training Loss: 0.8410834074020386\n",
      "Epoch: 94, Batch: 80, Training Loss: 0.8301522731781006\n",
      "Epoch: 94, Validation Loss: 1.0267654657363892\n",
      "Epoch: 95, Batch: 40, Training Loss: 0.8819989562034607\n",
      "Epoch: 95, Batch: 80, Training Loss: 0.8802499175071716\n",
      "Epoch: 95, Validation Loss: 1.0558139085769653\n",
      "Epoch: 96, Batch: 40, Training Loss: 0.8970379829406738\n",
      "Epoch: 96, Batch: 80, Training Loss: 0.8020407557487488\n",
      "Epoch: 96, Validation Loss: 1.1377557516098022\n",
      "Epoch: 97, Batch: 40, Training Loss: 0.8243995308876038\n",
      "Epoch: 97, Batch: 80, Training Loss: 0.8565906286239624\n",
      "Epoch: 97, Validation Loss: 1.0324368476867676\n",
      "Epoch: 98, Batch: 40, Training Loss: 0.8327527642250061\n",
      "Epoch: 98, Batch: 80, Training Loss: 0.9100313186645508\n",
      "Epoch: 98, Validation Loss: 0.9105127453804016\n",
      "Epoch: 99, Batch: 40, Training Loss: 0.8190248012542725\n",
      "Epoch: 99, Batch: 80, Training Loss: 0.9009538888931274\n",
      "Epoch: 99, Validation Loss: 1.1287404298782349\n",
      "Epoch: 100, Batch: 40, Training Loss: 0.822091817855835\n",
      "Epoch: 100, Batch: 80, Training Loss: 0.8547946810722351\n",
      "Epoch: 100, Validation Loss: 1.0124226808547974\n",
      "Epoch: 101, Batch: 40, Training Loss: 0.7712920904159546\n",
      "Epoch: 101, Batch: 80, Training Loss: 0.7910066246986389\n",
      "Epoch: 101, Validation Loss: 1.0891095399856567\n",
      "Epoch: 102, Batch: 40, Training Loss: 0.88730788230896\n",
      "Epoch: 102, Batch: 80, Training Loss: 0.8562811613082886\n",
      "Epoch: 102, Validation Loss: 0.9790254831314087\n",
      "Epoch: 103, Batch: 40, Training Loss: 0.7882452607154846\n",
      "Epoch: 103, Batch: 80, Training Loss: 0.8009730577468872\n",
      "Epoch: 103, Validation Loss: 1.0977598428726196\n",
      "Epoch: 104, Batch: 40, Training Loss: 0.8172481656074524\n",
      "Epoch: 104, Batch: 80, Training Loss: 0.8756356835365295\n",
      "Epoch: 104, Validation Loss: 1.08463716506958\n",
      "Epoch: 105, Batch: 40, Training Loss: 0.8662288784980774\n",
      "Epoch: 105, Batch: 80, Training Loss: 0.9290179014205933\n",
      "Epoch: 105, Validation Loss: 1.0041334629058838\n",
      "Epoch: 106, Batch: 40, Training Loss: 0.8130666017532349\n",
      "Epoch: 106, Batch: 80, Training Loss: 0.8267221450805664\n",
      "Epoch: 106, Validation Loss: 0.9910374879837036\n",
      "Epoch: 107, Batch: 40, Training Loss: 0.7770563364028931\n",
      "Epoch: 107, Batch: 80, Training Loss: 0.7094606161117554\n",
      "Epoch: 107, Validation Loss: 0.939396321773529\n",
      "Epoch: 108, Batch: 40, Training Loss: 0.8217860460281372\n",
      "Epoch: 108, Batch: 80, Training Loss: 0.7719371318817139\n",
      "Epoch: 108, Validation Loss: 0.9564055800437927\n",
      "Epoch: 109, Batch: 40, Training Loss: 0.8271808624267578\n",
      "Epoch: 109, Batch: 80, Training Loss: 0.8253652453422546\n",
      "Epoch: 109, Validation Loss: 1.00401771068573\n",
      "Epoch: 110, Batch: 40, Training Loss: 0.8240782022476196\n",
      "Epoch: 110, Batch: 80, Training Loss: 0.8438361287117004\n",
      "Epoch: 110, Validation Loss: 1.1506949663162231\n",
      "Epoch: 111, Batch: 40, Training Loss: 0.8555325865745544\n",
      "Epoch: 111, Batch: 80, Training Loss: 0.7469800710678101\n",
      "Epoch: 111, Validation Loss: 1.0400116443634033\n",
      "Epoch: 112, Batch: 40, Training Loss: 0.7782183289527893\n",
      "Epoch: 112, Batch: 80, Training Loss: 0.7719910740852356\n",
      "Epoch: 112, Validation Loss: 1.0139120817184448\n",
      "Epoch: 113, Batch: 40, Training Loss: 0.8387985825538635\n",
      "Epoch: 113, Batch: 80, Training Loss: 0.8507413864135742\n",
      "Epoch: 113, Validation Loss: 0.9465693831443787\n",
      "Epoch: 114, Batch: 40, Training Loss: 0.7506403923034668\n",
      "Epoch: 114, Batch: 80, Training Loss: 0.7403287291526794\n",
      "Epoch: 114, Validation Loss: 1.090406894683838\n",
      "Epoch: 115, Batch: 40, Training Loss: 0.7760866284370422\n",
      "Epoch: 115, Batch: 80, Training Loss: 0.8903780579566956\n",
      "Epoch: 115, Validation Loss: 1.1282633543014526\n",
      "Epoch: 116, Batch: 40, Training Loss: 0.7304365038871765\n",
      "Epoch: 116, Batch: 80, Training Loss: 0.7743808031082153\n",
      "Epoch: 116, Validation Loss: 1.1556429862976074\n",
      "Epoch: 117, Batch: 40, Training Loss: 0.7994979619979858\n",
      "Epoch: 117, Batch: 80, Training Loss: 0.7699562907218933\n",
      "Epoch: 117, Validation Loss: 1.004292607307434\n",
      "Epoch: 118, Batch: 40, Training Loss: 0.7751770615577698\n",
      "Epoch: 118, Batch: 80, Training Loss: 0.7621901631355286\n",
      "Epoch: 118, Validation Loss: 1.0527018308639526\n",
      "Epoch: 119, Batch: 40, Training Loss: 0.8873599171638489\n",
      "Epoch: 119, Batch: 80, Training Loss: 0.7673981189727783\n",
      "Epoch: 119, Validation Loss: 1.0368572473526\n",
      "Epoch: 120, Batch: 40, Training Loss: 0.8143863677978516\n",
      "Epoch: 120, Batch: 80, Training Loss: 0.7782091498374939\n",
      "Epoch: 120, Validation Loss: 1.074491262435913\n",
      "Epoch: 121, Batch: 40, Training Loss: 0.777656078338623\n",
      "Epoch: 121, Batch: 80, Training Loss: 0.7977628707885742\n",
      "Epoch: 121, Validation Loss: 1.0185142755508423\n",
      "Epoch: 122, Batch: 40, Training Loss: 0.7997756004333496\n",
      "Epoch: 122, Batch: 80, Training Loss: 0.7331879138946533\n",
      "Epoch: 122, Validation Loss: 1.1768189668655396\n",
      "Epoch: 123, Batch: 40, Training Loss: 0.7806024551391602\n",
      "Epoch: 123, Batch: 80, Training Loss: 0.8831899166107178\n",
      "Epoch: 123, Validation Loss: 1.1475170850753784\n",
      "Epoch: 124, Batch: 40, Training Loss: 0.8095570802688599\n",
      "Epoch: 124, Batch: 80, Training Loss: 0.7167666554450989\n",
      "Epoch: 124, Validation Loss: 1.149658441543579\n",
      "Epoch: 125, Batch: 40, Training Loss: 0.8079904317855835\n",
      "Epoch: 125, Batch: 80, Training Loss: 0.7394940257072449\n",
      "Epoch: 125, Validation Loss: 0.9678851366043091\n",
      "Epoch: 126, Batch: 40, Training Loss: 0.8168532252311707\n",
      "Epoch: 126, Batch: 80, Training Loss: 0.7638545036315918\n",
      "Epoch: 126, Validation Loss: 1.1096546649932861\n",
      "Epoch: 127, Batch: 40, Training Loss: 0.7206060290336609\n",
      "Epoch: 127, Batch: 80, Training Loss: 0.7363594174385071\n",
      "Epoch: 127, Validation Loss: 1.0079772472381592\n",
      "Epoch: 128, Batch: 40, Training Loss: 0.7655543684959412\n",
      "Epoch: 128, Batch: 80, Training Loss: 0.8327169418334961\n",
      "Epoch: 128, Validation Loss: 1.0129274129867554\n",
      "Epoch: 129, Batch: 40, Training Loss: 0.6701062917709351\n",
      "Epoch: 129, Batch: 80, Training Loss: 0.8129798769950867\n",
      "Epoch: 129, Validation Loss: 0.9840059876441956\n",
      "Epoch: 130, Batch: 40, Training Loss: 0.7163432240486145\n",
      "Epoch: 130, Batch: 80, Training Loss: 0.715377926826477\n",
      "Epoch: 130, Validation Loss: 1.1276456117630005\n",
      "Epoch: 131, Batch: 40, Training Loss: 0.8613266944885254\n",
      "Epoch: 131, Batch: 80, Training Loss: 0.7381704449653625\n",
      "Epoch: 131, Validation Loss: 0.9089966416358948\n",
      "Epoch: 132, Batch: 40, Training Loss: 0.6855494379997253\n",
      "Epoch: 132, Batch: 80, Training Loss: 0.7555856704711914\n",
      "Epoch: 132, Validation Loss: 1.0770901441574097\n",
      "Epoch: 133, Batch: 40, Training Loss: 0.7717756628990173\n",
      "Epoch: 133, Batch: 80, Training Loss: 0.7682019472122192\n",
      "Epoch: 133, Validation Loss: 1.0534778833389282\n",
      "Epoch: 134, Batch: 40, Training Loss: 0.7034124732017517\n",
      "Epoch: 134, Batch: 80, Training Loss: 0.7155035138130188\n",
      "Epoch: 134, Validation Loss: 1.0745879411697388\n",
      "Epoch: 135, Batch: 40, Training Loss: 0.7530519962310791\n",
      "Epoch: 135, Batch: 80, Training Loss: 0.7911299467086792\n",
      "Epoch: 135, Validation Loss: 0.9874682426452637\n",
      "Epoch: 136, Batch: 40, Training Loss: 0.7113348245620728\n",
      "Epoch: 136, Batch: 80, Training Loss: 0.702435314655304\n",
      "Epoch: 136, Validation Loss: 0.97450190782547\n",
      "Epoch: 137, Batch: 40, Training Loss: 0.8065544366836548\n",
      "Epoch: 137, Batch: 80, Training Loss: 0.7355221509933472\n",
      "Epoch: 137, Validation Loss: 1.0942546129226685\n",
      "Epoch: 138, Batch: 40, Training Loss: 0.6908628344535828\n",
      "Epoch: 138, Batch: 80, Training Loss: 0.6791787147521973\n",
      "Epoch: 138, Validation Loss: 1.0568236112594604\n",
      "Epoch: 139, Batch: 40, Training Loss: 0.6725003123283386\n",
      "Epoch: 139, Batch: 80, Training Loss: 0.6875374913215637\n",
      "Epoch: 139, Validation Loss: 1.0722098350524902\n",
      "Epoch: 140, Batch: 40, Training Loss: 0.7454851269721985\n",
      "Epoch: 140, Batch: 80, Training Loss: 0.8209906220436096\n",
      "Epoch: 140, Validation Loss: 1.0104535818099976\n",
      "Epoch: 141, Batch: 40, Training Loss: 0.685198187828064\n",
      "Epoch: 141, Batch: 80, Training Loss: 0.754815936088562\n",
      "Epoch: 141, Validation Loss: 1.0763423442840576\n",
      "Epoch: 142, Batch: 40, Training Loss: 0.7917090058326721\n",
      "Epoch: 142, Batch: 80, Training Loss: 0.7358505725860596\n",
      "Epoch: 142, Validation Loss: 1.0583311319351196\n",
      "Epoch: 143, Batch: 40, Training Loss: 0.719609797000885\n",
      "Epoch: 143, Batch: 80, Training Loss: 0.8189396262168884\n",
      "Epoch: 143, Validation Loss: 1.0610805749893188\n",
      "Epoch: 144, Batch: 40, Training Loss: 0.760179340839386\n",
      "Epoch: 144, Batch: 80, Training Loss: 0.7252573370933533\n",
      "Epoch: 144, Validation Loss: 0.9983724355697632\n",
      "Epoch: 145, Batch: 40, Training Loss: 0.7211567759513855\n",
      "Epoch: 145, Batch: 80, Training Loss: 0.6470654010772705\n",
      "Epoch: 145, Validation Loss: 1.1705917119979858\n",
      "Epoch: 146, Batch: 40, Training Loss: 0.8511407971382141\n",
      "Epoch: 146, Batch: 80, Training Loss: 0.6189939975738525\n",
      "Epoch: 146, Validation Loss: 1.0413368940353394\n",
      "Epoch: 147, Batch: 40, Training Loss: 0.7431290149688721\n",
      "Epoch: 147, Batch: 80, Training Loss: 0.7578728795051575\n",
      "Epoch: 147, Validation Loss: 1.0148981809616089\n",
      "Epoch: 148, Batch: 40, Training Loss: 0.7224623560905457\n",
      "Epoch: 148, Batch: 80, Training Loss: 0.7211683988571167\n",
      "Epoch: 148, Validation Loss: 1.051898717880249\n",
      "Epoch: 149, Batch: 40, Training Loss: 0.6954076290130615\n",
      "Epoch: 149, Batch: 80, Training Loss: 0.7514594793319702\n",
      "Epoch: 149, Validation Loss: 0.9422378540039062\n",
      "Epoch: 150, Batch: 40, Training Loss: 0.7378183007240295\n",
      "Epoch: 150, Batch: 80, Training Loss: 0.7249115705490112\n",
      "Epoch: 150, Validation Loss: 1.028813362121582\n",
      "Epoch: 151, Batch: 40, Training Loss: 0.7383293509483337\n",
      "Epoch: 151, Batch: 80, Training Loss: 0.6066116094589233\n",
      "Epoch: 151, Validation Loss: 1.095332384109497\n",
      "Epoch: 152, Batch: 40, Training Loss: 0.7025030851364136\n",
      "Epoch: 152, Batch: 80, Training Loss: 0.6269233226776123\n",
      "Epoch: 152, Validation Loss: 0.9796085953712463\n",
      "Epoch: 153, Batch: 40, Training Loss: 0.6562044024467468\n",
      "Epoch: 153, Batch: 80, Training Loss: 0.7140325307846069\n",
      "Epoch: 153, Validation Loss: 1.01223623752594\n",
      "Epoch: 154, Batch: 40, Training Loss: 0.6958584189414978\n",
      "Epoch: 154, Batch: 80, Training Loss: 0.7301487922668457\n",
      "Epoch: 154, Validation Loss: 0.9405583739280701\n",
      "Epoch: 155, Batch: 40, Training Loss: 0.7507354021072388\n",
      "Epoch: 155, Batch: 80, Training Loss: 0.7342168688774109\n",
      "Epoch: 155, Validation Loss: 1.0259596109390259\n",
      "Epoch: 156, Batch: 40, Training Loss: 0.7028504610061646\n",
      "Epoch: 156, Batch: 80, Training Loss: 0.7200189828872681\n",
      "Epoch: 156, Validation Loss: 1.148457407951355\n",
      "Epoch: 157, Batch: 40, Training Loss: 0.7823889851570129\n",
      "Epoch: 157, Batch: 80, Training Loss: 0.6727666854858398\n",
      "Epoch: 157, Validation Loss: 1.0142738819122314\n",
      "Epoch: 158, Batch: 40, Training Loss: 0.7584194540977478\n",
      "Epoch: 158, Batch: 80, Training Loss: 0.6338814496994019\n",
      "Epoch: 158, Validation Loss: 0.9605131149291992\n",
      "Epoch: 159, Batch: 40, Training Loss: 0.6775919198989868\n",
      "Epoch: 159, Batch: 80, Training Loss: 0.6934858560562134\n",
      "Epoch: 159, Validation Loss: 1.0959861278533936\n",
      "Epoch: 160, Batch: 40, Training Loss: 0.7177907228469849\n",
      "Epoch: 160, Batch: 80, Training Loss: 0.6995037198066711\n",
      "Epoch: 160, Validation Loss: 0.9950175881385803\n",
      "Epoch: 161, Batch: 40, Training Loss: 0.6540868282318115\n",
      "Epoch: 161, Batch: 80, Training Loss: 0.673083484172821\n",
      "Epoch: 161, Validation Loss: 1.0289212465286255\n",
      "Epoch: 162, Batch: 40, Training Loss: 0.6694116592407227\n",
      "Epoch: 162, Batch: 80, Training Loss: 0.746199905872345\n",
      "Epoch: 162, Validation Loss: 1.0995064973831177\n",
      "Epoch: 163, Batch: 40, Training Loss: 0.8083649277687073\n",
      "Epoch: 163, Batch: 80, Training Loss: 0.7581128478050232\n",
      "Epoch: 163, Validation Loss: 0.9712142944335938\n",
      "Epoch: 164, Batch: 40, Training Loss: 0.7450230717658997\n",
      "Epoch: 164, Batch: 80, Training Loss: 0.7007108330726624\n",
      "Epoch: 164, Validation Loss: 1.083814263343811\n",
      "Epoch: 165, Batch: 40, Training Loss: 0.7314894199371338\n",
      "Epoch: 165, Batch: 80, Training Loss: 0.7424321174621582\n",
      "Epoch: 165, Validation Loss: 0.9877957701683044\n",
      "Epoch: 166, Batch: 40, Training Loss: 0.6834592819213867\n",
      "Epoch: 166, Batch: 80, Training Loss: 0.7700566649436951\n",
      "Epoch: 166, Validation Loss: 1.0963287353515625\n",
      "Epoch: 167, Batch: 40, Training Loss: 0.6477331519126892\n",
      "Epoch: 167, Batch: 80, Training Loss: 0.7013781666755676\n",
      "Epoch: 167, Validation Loss: 1.0333703756332397\n",
      "Epoch: 168, Batch: 40, Training Loss: 0.7078685760498047\n",
      "Epoch: 168, Batch: 80, Training Loss: 0.7319783568382263\n",
      "Epoch: 168, Validation Loss: 0.9980515837669373\n",
      "Epoch: 169, Batch: 40, Training Loss: 0.6407073140144348\n",
      "Epoch: 169, Batch: 80, Training Loss: 0.7123078107833862\n",
      "Epoch: 169, Validation Loss: 1.026394009590149\n",
      "Epoch: 170, Batch: 40, Training Loss: 0.6422168612480164\n",
      "Epoch: 170, Batch: 80, Training Loss: 0.7224476337432861\n",
      "Epoch: 170, Validation Loss: 1.0996580123901367\n",
      "Epoch: 171, Batch: 40, Training Loss: 0.632668673992157\n",
      "Epoch: 171, Batch: 80, Training Loss: 0.7278168797492981\n",
      "Epoch: 171, Validation Loss: 0.9131515026092529\n",
      "Epoch: 172, Batch: 40, Training Loss: 0.7202484011650085\n",
      "Epoch: 172, Batch: 80, Training Loss: 0.7703065276145935\n",
      "Epoch: 172, Validation Loss: 1.1580853462219238\n",
      "Epoch: 173, Batch: 40, Training Loss: 0.7490949034690857\n",
      "Epoch: 173, Batch: 80, Training Loss: 0.7225401997566223\n",
      "Epoch: 173, Validation Loss: 0.9931825995445251\n",
      "Epoch: 174, Batch: 40, Training Loss: 0.7224951386451721\n",
      "Epoch: 174, Batch: 80, Training Loss: 0.6640872955322266\n",
      "Epoch: 174, Validation Loss: 1.0548465251922607\n",
      "Epoch: 175, Batch: 40, Training Loss: 0.696655809879303\n",
      "Epoch: 175, Batch: 80, Training Loss: 0.7357959151268005\n",
      "Epoch: 175, Validation Loss: 0.9546433687210083\n",
      "Epoch: 176, Batch: 40, Training Loss: 0.672175943851471\n",
      "Epoch: 176, Batch: 80, Training Loss: 0.7587610483169556\n",
      "Epoch: 176, Validation Loss: 1.0202172994613647\n",
      "Epoch: 177, Batch: 40, Training Loss: 0.6745749115943909\n",
      "Epoch: 177, Batch: 80, Training Loss: 0.7193825244903564\n",
      "Epoch: 177, Validation Loss: 1.152486801147461\n",
      "Epoch: 178, Batch: 40, Training Loss: 0.6434193253517151\n",
      "Epoch: 178, Batch: 80, Training Loss: 0.637600839138031\n",
      "Epoch: 178, Validation Loss: 0.9927048683166504\n",
      "Epoch: 179, Batch: 40, Training Loss: 0.6485775113105774\n",
      "Epoch: 179, Batch: 80, Training Loss: 0.6905592679977417\n",
      "Epoch: 179, Validation Loss: 1.092212200164795\n",
      "Epoch: 180, Batch: 40, Training Loss: 0.7124261856079102\n",
      "Epoch: 180, Batch: 80, Training Loss: 0.7238836884498596\n",
      "Epoch: 180, Validation Loss: 1.031599998474121\n",
      "Epoch: 181, Batch: 40, Training Loss: 0.7272536158561707\n",
      "Epoch: 181, Batch: 80, Training Loss: 0.6522213220596313\n",
      "Epoch: 181, Validation Loss: 1.123102068901062\n",
      "Epoch: 182, Batch: 40, Training Loss: 0.6983292698860168\n",
      "Epoch: 182, Batch: 80, Training Loss: 0.701657235622406\n",
      "Epoch: 182, Validation Loss: 1.0806893110275269\n",
      "Epoch: 183, Batch: 40, Training Loss: 0.6059600710868835\n",
      "Epoch: 183, Batch: 80, Training Loss: 0.6592203378677368\n",
      "Epoch: 183, Validation Loss: 1.0732263326644897\n",
      "Epoch: 184, Batch: 40, Training Loss: 0.7086194753646851\n",
      "Epoch: 184, Batch: 80, Training Loss: 0.7033237218856812\n",
      "Epoch: 184, Validation Loss: 1.0148228406906128\n",
      "Epoch: 185, Batch: 40, Training Loss: 0.5751153826713562\n",
      "Epoch: 185, Batch: 80, Training Loss: 0.6593120694160461\n",
      "Epoch: 185, Validation Loss: 1.1692705154418945\n",
      "Epoch: 186, Batch: 40, Training Loss: 0.7498109936714172\n",
      "Epoch: 186, Batch: 80, Training Loss: 0.6686875224113464\n",
      "Epoch: 186, Validation Loss: 0.9193005561828613\n",
      "Epoch: 187, Batch: 40, Training Loss: 0.7064883708953857\n",
      "Epoch: 187, Batch: 80, Training Loss: 0.6756120920181274\n",
      "Epoch: 187, Validation Loss: 1.0287432670593262\n",
      "Epoch: 188, Batch: 40, Training Loss: 0.7076349258422852\n",
      "Epoch: 188, Batch: 80, Training Loss: 0.6468459367752075\n",
      "Epoch: 188, Validation Loss: 1.0974210500717163\n",
      "Epoch: 189, Batch: 40, Training Loss: 0.622001588344574\n",
      "Epoch: 189, Batch: 80, Training Loss: 0.7401217222213745\n",
      "Epoch: 189, Validation Loss: 1.1068428754806519\n",
      "Epoch: 190, Batch: 40, Training Loss: 0.715860903263092\n",
      "Epoch: 190, Batch: 80, Training Loss: 0.728662371635437\n",
      "Epoch: 190, Validation Loss: 1.0850138664245605\n",
      "Epoch: 191, Batch: 40, Training Loss: 0.70472651720047\n",
      "Epoch: 191, Batch: 80, Training Loss: 0.7179046273231506\n",
      "Epoch: 191, Validation Loss: 0.9789615273475647\n",
      "Epoch: 192, Batch: 40, Training Loss: 0.7034332752227783\n",
      "Epoch: 192, Batch: 80, Training Loss: 0.7003945112228394\n",
      "Epoch: 192, Validation Loss: 1.032302975654602\n",
      "Epoch: 193, Batch: 40, Training Loss: 0.68992680311203\n",
      "Epoch: 193, Batch: 80, Training Loss: 0.5898885130882263\n",
      "Epoch: 193, Validation Loss: 1.0694459676742554\n",
      "Epoch: 194, Batch: 40, Training Loss: 0.7170183062553406\n",
      "Epoch: 194, Batch: 80, Training Loss: 0.6563117504119873\n",
      "Epoch: 194, Validation Loss: 0.9384585022926331\n",
      "Epoch: 195, Batch: 40, Training Loss: 0.6600657105445862\n",
      "Epoch: 195, Batch: 80, Training Loss: 0.6965115070343018\n",
      "Epoch: 195, Validation Loss: 1.0549505949020386\n",
      "Epoch: 196, Batch: 40, Training Loss: 0.6679401993751526\n",
      "Epoch: 196, Batch: 80, Training Loss: 0.6423307657241821\n",
      "Epoch: 196, Validation Loss: 1.0523326396942139\n",
      "Epoch: 197, Batch: 40, Training Loss: 0.6378940343856812\n",
      "Epoch: 197, Batch: 80, Training Loss: 0.795769453048706\n",
      "Epoch: 197, Validation Loss: 1.0439927577972412\n",
      "Epoch: 198, Batch: 40, Training Loss: 0.686553418636322\n",
      "Epoch: 198, Batch: 80, Training Loss: 0.6997180581092834\n",
      "Epoch: 198, Validation Loss: 0.9388014078140259\n",
      "Epoch: 199, Batch: 40, Training Loss: 0.7285772562026978\n",
      "Epoch: 199, Batch: 80, Training Loss: 0.712782084941864\n",
      "Epoch: 199, Validation Loss: 1.0743528604507446\n",
      "Epoch: 200, Batch: 40, Training Loss: 0.6525994539260864\n",
      "Epoch: 200, Batch: 80, Training Loss: 0.6420559287071228\n",
      "Epoch: 200, Validation Loss: 1.1065938472747803\n",
      "Epoch: 201, Batch: 40, Training Loss: 0.6713266968727112\n",
      "Epoch: 201, Batch: 80, Training Loss: 0.6805253624916077\n",
      "Epoch: 201, Validation Loss: 0.9691739678382874\n",
      "Epoch: 202, Batch: 40, Training Loss: 0.7347298860549927\n",
      "Epoch: 202, Batch: 80, Training Loss: 0.6769817471504211\n",
      "Epoch: 202, Validation Loss: 0.9658207893371582\n",
      "Epoch: 203, Batch: 40, Training Loss: 0.7244073152542114\n",
      "Epoch: 203, Batch: 80, Training Loss: 0.6588409543037415\n",
      "Epoch: 203, Validation Loss: 1.1658079624176025\n",
      "Epoch: 204, Batch: 40, Training Loss: 0.6467887759208679\n",
      "Epoch: 204, Batch: 80, Training Loss: 0.6623520851135254\n",
      "Epoch: 204, Validation Loss: 1.0803672075271606\n",
      "Epoch: 205, Batch: 40, Training Loss: 0.6111329793930054\n",
      "Epoch: 205, Batch: 80, Training Loss: 0.7064083218574524\n",
      "Epoch: 205, Validation Loss: 1.102724552154541\n",
      "Epoch: 206, Batch: 40, Training Loss: 0.6057392954826355\n",
      "Epoch: 206, Batch: 80, Training Loss: 0.7348847389221191\n",
      "Epoch: 206, Validation Loss: 1.111867904663086\n",
      "Epoch: 207, Batch: 40, Training Loss: 0.6191897392272949\n",
      "Epoch: 207, Batch: 80, Training Loss: 0.6116564869880676\n",
      "Epoch: 207, Validation Loss: 1.0502593517303467\n",
      "Epoch: 208, Batch: 40, Training Loss: 0.6275169849395752\n",
      "Epoch: 208, Batch: 80, Training Loss: 0.6621801853179932\n",
      "Epoch: 208, Validation Loss: 0.9668347835540771\n",
      "Epoch: 209, Batch: 40, Training Loss: 0.7335370779037476\n",
      "Epoch: 209, Batch: 80, Training Loss: 0.6875304579734802\n",
      "Epoch: 209, Validation Loss: 1.1303753852844238\n",
      "Epoch: 210, Batch: 40, Training Loss: 0.7176963686943054\n",
      "Epoch: 210, Batch: 80, Training Loss: 0.77018803358078\n",
      "Epoch: 210, Validation Loss: 0.9983424544334412\n",
      "Epoch: 211, Batch: 40, Training Loss: 0.7818149924278259\n",
      "Epoch: 211, Batch: 80, Training Loss: 0.6180282831192017\n",
      "Epoch: 211, Validation Loss: 1.089884877204895\n",
      "Epoch: 212, Batch: 40, Training Loss: 0.7008645534515381\n",
      "Epoch: 212, Batch: 80, Training Loss: 0.6428301930427551\n",
      "Epoch: 212, Validation Loss: 0.8934105634689331\n",
      "Epoch: 213, Batch: 40, Training Loss: 0.7421305179595947\n",
      "Epoch: 213, Batch: 80, Training Loss: 0.6832267642021179\n",
      "Epoch: 213, Validation Loss: 1.1260859966278076\n",
      "Epoch: 214, Batch: 40, Training Loss: 0.6239674687385559\n",
      "Epoch: 214, Batch: 80, Training Loss: 0.6675548553466797\n",
      "Epoch: 214, Validation Loss: 1.1211273670196533\n",
      "Epoch: 215, Batch: 40, Training Loss: 0.6157232522964478\n",
      "Epoch: 215, Batch: 80, Training Loss: 0.6195018291473389\n",
      "Epoch: 215, Validation Loss: 1.1128429174423218\n",
      "Epoch: 216, Batch: 40, Training Loss: 0.6541823148727417\n",
      "Epoch: 216, Batch: 80, Training Loss: 0.699321985244751\n",
      "Epoch: 216, Validation Loss: 1.2144336700439453\n",
      "Epoch: 217, Batch: 40, Training Loss: 0.7042325735092163\n",
      "Epoch: 217, Batch: 80, Training Loss: 0.6540647745132446\n",
      "Epoch: 217, Validation Loss: 1.0880403518676758\n",
      "Epoch: 218, Batch: 40, Training Loss: 0.5981173515319824\n",
      "Epoch: 218, Batch: 80, Training Loss: 0.6360176205635071\n",
      "Epoch: 218, Validation Loss: 1.0068598985671997\n",
      "Epoch: 219, Batch: 40, Training Loss: 0.6329829692840576\n",
      "Epoch: 219, Batch: 80, Training Loss: 0.6176671981811523\n",
      "Epoch: 219, Validation Loss: 1.134102463722229\n",
      "Epoch: 220, Batch: 40, Training Loss: 0.6897783279418945\n",
      "Epoch: 220, Batch: 80, Training Loss: 0.7707664370536804\n",
      "Epoch: 220, Validation Loss: 1.0408883094787598\n",
      "Epoch: 221, Batch: 40, Training Loss: 0.6796085834503174\n",
      "Epoch: 221, Batch: 80, Training Loss: 0.76358562707901\n",
      "Epoch: 221, Validation Loss: 1.0401012897491455\n",
      "Epoch: 222, Batch: 40, Training Loss: 0.6411932706832886\n",
      "Epoch: 222, Batch: 80, Training Loss: 0.7318884134292603\n",
      "Epoch: 222, Validation Loss: 1.085342526435852\n",
      "Epoch: 223, Batch: 40, Training Loss: 0.6246327757835388\n",
      "Epoch: 223, Batch: 80, Training Loss: 0.6802214980125427\n",
      "Epoch: 223, Validation Loss: 1.0516612529754639\n",
      "Epoch: 224, Batch: 40, Training Loss: 0.6367627382278442\n",
      "Epoch: 224, Batch: 80, Training Loss: 0.6497637033462524\n",
      "Epoch: 224, Validation Loss: 1.1137179136276245\n",
      "Epoch: 225, Batch: 40, Training Loss: 0.6696252822875977\n",
      "Epoch: 225, Batch: 80, Training Loss: 0.6923900842666626\n",
      "Epoch: 225, Validation Loss: 1.0518321990966797\n",
      "Epoch: 226, Batch: 40, Training Loss: 0.6563196182250977\n",
      "Epoch: 226, Batch: 80, Training Loss: 0.5497689843177795\n",
      "Epoch: 226, Validation Loss: 1.0094057321548462\n",
      "Epoch: 227, Batch: 40, Training Loss: 0.7504323720932007\n",
      "Epoch: 227, Batch: 80, Training Loss: 0.6351096630096436\n",
      "Epoch: 227, Validation Loss: 0.962836742401123\n",
      "Epoch: 228, Batch: 40, Training Loss: 0.5952338576316833\n",
      "Epoch: 228, Batch: 80, Training Loss: 0.7317920327186584\n",
      "Epoch: 228, Validation Loss: 1.1036511659622192\n",
      "Epoch: 229, Batch: 40, Training Loss: 0.6191511750221252\n",
      "Epoch: 229, Batch: 80, Training Loss: 0.6675453782081604\n",
      "Epoch: 229, Validation Loss: 0.9091083407402039\n",
      "Epoch: 230, Batch: 40, Training Loss: 0.7050168514251709\n",
      "Epoch: 230, Batch: 80, Training Loss: 0.6467783451080322\n",
      "Epoch: 230, Validation Loss: 1.0359896421432495\n",
      "Epoch: 231, Batch: 40, Training Loss: 0.6616581678390503\n",
      "Epoch: 231, Batch: 80, Training Loss: 0.6679247617721558\n",
      "Epoch: 231, Validation Loss: 1.0238574743270874\n",
      "Epoch: 232, Batch: 40, Training Loss: 0.6474105715751648\n",
      "Epoch: 232, Batch: 80, Training Loss: 0.6293796300888062\n",
      "Epoch: 232, Validation Loss: 1.0114396810531616\n",
      "Epoch: 233, Batch: 40, Training Loss: 0.6406967043876648\n",
      "Epoch: 233, Batch: 80, Training Loss: 0.7223154902458191\n",
      "Epoch: 233, Validation Loss: 1.1374332904815674\n",
      "Epoch: 234, Batch: 40, Training Loss: 0.6075464487075806\n",
      "Epoch: 234, Batch: 80, Training Loss: 0.6990180611610413\n",
      "Epoch: 234, Validation Loss: 0.9676035046577454\n",
      "Epoch: 235, Batch: 40, Training Loss: 0.6768006086349487\n",
      "Epoch: 235, Batch: 80, Training Loss: 0.6872935891151428\n",
      "Epoch: 235, Validation Loss: 1.1481523513793945\n",
      "Epoch: 236, Batch: 40, Training Loss: 0.6368097066879272\n",
      "Epoch: 236, Batch: 80, Training Loss: 0.6379343271255493\n",
      "Epoch: 236, Validation Loss: 1.1003012657165527\n",
      "Epoch: 237, Batch: 40, Training Loss: 0.6181680560112\n",
      "Epoch: 237, Batch: 80, Training Loss: 0.7409167885780334\n",
      "Epoch: 237, Validation Loss: 1.143815040588379\n",
      "Epoch: 238, Batch: 40, Training Loss: 0.6666533350944519\n",
      "Epoch: 238, Batch: 80, Training Loss: 0.5984015464782715\n",
      "Epoch: 238, Validation Loss: 1.0146782398223877\n",
      "Epoch: 239, Batch: 40, Training Loss: 0.6953323483467102\n",
      "Epoch: 239, Batch: 80, Training Loss: 0.5489897131919861\n",
      "Epoch: 239, Validation Loss: 1.1353535652160645\n",
      "Epoch: 240, Batch: 40, Training Loss: 0.6682001948356628\n",
      "Epoch: 240, Batch: 80, Training Loss: 0.5929425954818726\n",
      "Epoch: 240, Validation Loss: 1.1284328699111938\n",
      "Epoch: 241, Batch: 40, Training Loss: 0.6270692348480225\n",
      "Epoch: 241, Batch: 80, Training Loss: 0.6149490475654602\n",
      "Epoch: 241, Validation Loss: 1.1172922849655151\n",
      "Epoch: 242, Batch: 40, Training Loss: 0.6295155882835388\n",
      "Epoch: 242, Batch: 80, Training Loss: 0.6955370306968689\n",
      "Epoch: 242, Validation Loss: 1.0705538988113403\n",
      "Epoch: 243, Batch: 40, Training Loss: 0.7126660943031311\n",
      "Epoch: 243, Batch: 80, Training Loss: 0.683230996131897\n",
      "Epoch: 243, Validation Loss: 1.0690462589263916\n",
      "Epoch: 244, Batch: 40, Training Loss: 0.6298282146453857\n",
      "Epoch: 244, Batch: 80, Training Loss: 0.585884153842926\n",
      "Epoch: 244, Validation Loss: 1.1357585191726685\n",
      "Epoch: 245, Batch: 40, Training Loss: 0.6382211446762085\n",
      "Epoch: 245, Batch: 80, Training Loss: 0.6538666486740112\n",
      "Epoch: 245, Validation Loss: 1.1579067707061768\n",
      "Epoch: 246, Batch: 40, Training Loss: 0.6847091317176819\n",
      "Epoch: 246, Batch: 80, Training Loss: 0.6364943385124207\n",
      "Epoch: 246, Validation Loss: 0.9849222302436829\n",
      "Epoch: 247, Batch: 40, Training Loss: 0.6806245446205139\n",
      "Epoch: 247, Batch: 80, Training Loss: 0.6539984941482544\n",
      "Epoch: 247, Validation Loss: 1.089930534362793\n",
      "Epoch: 248, Batch: 40, Training Loss: 0.6899695992469788\n",
      "Epoch: 248, Batch: 80, Training Loss: 0.5696407556533813\n",
      "Epoch: 248, Validation Loss: 1.1615663766860962\n",
      "Epoch: 249, Batch: 40, Training Loss: 0.6931132674217224\n",
      "Epoch: 249, Batch: 80, Training Loss: 0.6584834456443787\n",
      "Epoch: 249, Validation Loss: 1.0803416967391968\n",
      "Epoch: 250, Batch: 40, Training Loss: 0.6244612336158752\n",
      "Epoch: 250, Batch: 80, Training Loss: 0.593718409538269\n",
      "Epoch: 250, Validation Loss: 1.0643268823623657\n",
      "Epoch: 251, Batch: 40, Training Loss: 0.6020959615707397\n",
      "Epoch: 251, Batch: 80, Training Loss: 0.660455584526062\n",
      "Epoch: 251, Validation Loss: 1.1775476932525635\n",
      "Epoch: 252, Batch: 40, Training Loss: 0.6280257701873779\n",
      "Epoch: 252, Batch: 80, Training Loss: 0.6415690779685974\n",
      "Epoch: 252, Validation Loss: 1.0107542276382446\n",
      "Epoch: 253, Batch: 40, Training Loss: 0.664277195930481\n",
      "Epoch: 253, Batch: 80, Training Loss: 0.6603670120239258\n",
      "Epoch: 253, Validation Loss: 1.0199155807495117\n",
      "Epoch: 254, Batch: 40, Training Loss: 0.5706607699394226\n",
      "Epoch: 254, Batch: 80, Training Loss: 0.6436510682106018\n",
      "Epoch: 254, Validation Loss: 1.0838717222213745\n",
      "Epoch: 255, Batch: 40, Training Loss: 0.5911766886711121\n",
      "Epoch: 255, Batch: 80, Training Loss: 0.7170954346656799\n",
      "Epoch: 255, Validation Loss: 1.111461877822876\n",
      "Epoch: 256, Batch: 40, Training Loss: 0.6330209374427795\n",
      "Epoch: 256, Batch: 80, Training Loss: 0.5741875171661377\n",
      "Epoch: 256, Validation Loss: 1.0457708835601807\n",
      "Epoch: 257, Batch: 40, Training Loss: 0.5422963500022888\n",
      "Epoch: 257, Batch: 80, Training Loss: 0.6741582155227661\n",
      "Epoch: 257, Validation Loss: 1.1088708639144897\n",
      "Epoch: 258, Batch: 40, Training Loss: 0.6365858912467957\n",
      "Epoch: 258, Batch: 80, Training Loss: 0.6541740298271179\n",
      "Epoch: 258, Validation Loss: 1.1296961307525635\n",
      "Epoch: 259, Batch: 40, Training Loss: 0.5098942518234253\n",
      "Epoch: 259, Batch: 80, Training Loss: 0.6233864426612854\n",
      "Epoch: 259, Validation Loss: 0.9752628207206726\n",
      "Epoch: 260, Batch: 40, Training Loss: 0.6563056707382202\n",
      "Epoch: 260, Batch: 80, Training Loss: 0.709708034992218\n",
      "Epoch: 260, Validation Loss: 0.9488423466682434\n",
      "Epoch: 261, Batch: 40, Training Loss: 0.5825958251953125\n",
      "Epoch: 261, Batch: 80, Training Loss: 0.5808600783348083\n",
      "Epoch: 261, Validation Loss: 1.1053225994110107\n",
      "Epoch: 262, Batch: 40, Training Loss: 0.6181604266166687\n",
      "Epoch: 262, Batch: 80, Training Loss: 0.7196528911590576\n",
      "Epoch: 262, Validation Loss: 1.0591384172439575\n",
      "Epoch: 263, Batch: 40, Training Loss: 0.6411409974098206\n",
      "Epoch: 263, Batch: 80, Training Loss: 0.6506502032279968\n",
      "Epoch: 263, Validation Loss: 1.0417003631591797\n",
      "Epoch: 264, Batch: 40, Training Loss: 0.6341589093208313\n",
      "Epoch: 264, Batch: 80, Training Loss: 0.6241750717163086\n",
      "Epoch: 264, Validation Loss: 1.0692678689956665\n",
      "Epoch: 265, Batch: 40, Training Loss: 0.6178094744682312\n",
      "Epoch: 265, Batch: 80, Training Loss: 0.6076136827468872\n",
      "Epoch: 265, Validation Loss: 1.1042245626449585\n",
      "Epoch: 266, Batch: 40, Training Loss: 0.6060084700584412\n",
      "Epoch: 266, Batch: 80, Training Loss: 0.6094688773155212\n",
      "Epoch: 266, Validation Loss: 1.190660834312439\n",
      "Epoch: 267, Batch: 40, Training Loss: 0.6616246700286865\n",
      "Epoch: 267, Batch: 80, Training Loss: 0.6017631888389587\n",
      "Epoch: 267, Validation Loss: 1.1156820058822632\n",
      "Epoch: 268, Batch: 40, Training Loss: 0.6959452629089355\n",
      "Epoch: 268, Batch: 80, Training Loss: 0.5637206435203552\n",
      "Epoch: 268, Validation Loss: 1.0316983461380005\n",
      "Epoch: 269, Batch: 40, Training Loss: 0.6522817611694336\n",
      "Epoch: 269, Batch: 80, Training Loss: 0.6972682476043701\n",
      "Epoch: 269, Validation Loss: 1.2305201292037964\n",
      "Epoch: 270, Batch: 40, Training Loss: 0.6737499833106995\n",
      "Epoch: 270, Batch: 80, Training Loss: 0.6108080148696899\n",
      "Epoch: 270, Validation Loss: 1.1481306552886963\n",
      "Epoch: 271, Batch: 40, Training Loss: 0.7554198503494263\n",
      "Epoch: 271, Batch: 80, Training Loss: 0.6140669584274292\n",
      "Epoch: 271, Validation Loss: 1.089903712272644\n",
      "Epoch: 272, Batch: 40, Training Loss: 0.618472695350647\n",
      "Epoch: 272, Batch: 80, Training Loss: 0.6549679636955261\n",
      "Epoch: 272, Validation Loss: 1.1703730821609497\n",
      "Epoch: 273, Batch: 40, Training Loss: 0.6995523571968079\n",
      "Epoch: 273, Batch: 80, Training Loss: 0.7233753204345703\n",
      "Epoch: 273, Validation Loss: 1.1097996234893799\n",
      "Epoch: 274, Batch: 40, Training Loss: 0.6566320657730103\n",
      "Epoch: 274, Batch: 80, Training Loss: 0.5977559089660645\n",
      "Epoch: 274, Validation Loss: 1.1211506128311157\n",
      "Epoch: 275, Batch: 40, Training Loss: 0.5846568942070007\n",
      "Epoch: 275, Batch: 80, Training Loss: 0.6231328248977661\n",
      "Epoch: 275, Validation Loss: 1.07305109500885\n",
      "Epoch: 276, Batch: 40, Training Loss: 0.5819553136825562\n",
      "Epoch: 276, Batch: 80, Training Loss: 0.643823504447937\n",
      "Epoch: 276, Validation Loss: 1.042479395866394\n",
      "Epoch: 277, Batch: 40, Training Loss: 0.6450648903846741\n",
      "Epoch: 277, Batch: 80, Training Loss: 0.5467383861541748\n",
      "Epoch: 277, Validation Loss: 1.025477409362793\n",
      "Epoch: 278, Batch: 40, Training Loss: 0.5890185832977295\n",
      "Epoch: 278, Batch: 80, Training Loss: 0.6755869388580322\n",
      "Epoch: 278, Validation Loss: 1.1838594675064087\n",
      "Epoch: 279, Batch: 40, Training Loss: 0.5876001119613647\n",
      "Epoch: 279, Batch: 80, Training Loss: 0.6535624861717224\n",
      "Epoch: 279, Validation Loss: 1.0523470640182495\n",
      "Epoch: 280, Batch: 40, Training Loss: 0.5710479021072388\n",
      "Epoch: 280, Batch: 80, Training Loss: 0.614595353603363\n",
      "Epoch: 280, Validation Loss: 1.0190962553024292\n",
      "Epoch: 281, Batch: 40, Training Loss: 0.5875262022018433\n",
      "Epoch: 281, Batch: 80, Training Loss: 0.6415910720825195\n",
      "Epoch: 281, Validation Loss: 1.143747329711914\n",
      "Epoch: 282, Batch: 40, Training Loss: 0.6447305083274841\n",
      "Epoch: 282, Batch: 80, Training Loss: 0.6477930545806885\n",
      "Epoch: 282, Validation Loss: 1.0127675533294678\n",
      "Epoch: 283, Batch: 40, Training Loss: 0.6418058276176453\n",
      "Epoch: 283, Batch: 80, Training Loss: 0.5382330417633057\n",
      "Epoch: 283, Validation Loss: 1.1422576904296875\n",
      "Epoch: 284, Batch: 40, Training Loss: 0.5993858575820923\n",
      "Epoch: 284, Batch: 80, Training Loss: 0.691027820110321\n",
      "Epoch: 284, Validation Loss: 1.120944857597351\n",
      "Epoch: 285, Batch: 40, Training Loss: 0.5863823890686035\n",
      "Epoch: 285, Batch: 80, Training Loss: 0.7093809247016907\n",
      "Epoch: 285, Validation Loss: 1.101418375968933\n",
      "Epoch: 286, Batch: 40, Training Loss: 0.5921682119369507\n",
      "Epoch: 286, Batch: 80, Training Loss: 0.6438291668891907\n",
      "Epoch: 286, Validation Loss: 1.0299296379089355\n",
      "Epoch: 287, Batch: 40, Training Loss: 0.614730954170227\n",
      "Epoch: 287, Batch: 80, Training Loss: 0.6416473388671875\n",
      "Epoch: 287, Validation Loss: 1.1582258939743042\n",
      "Epoch: 288, Batch: 40, Training Loss: 0.6020182967185974\n",
      "Epoch: 288, Batch: 80, Training Loss: 0.63767009973526\n",
      "Epoch: 288, Validation Loss: 0.9454004764556885\n",
      "Epoch: 289, Batch: 40, Training Loss: 0.6645730137825012\n",
      "Epoch: 289, Batch: 80, Training Loss: 0.6084651947021484\n",
      "Epoch: 289, Validation Loss: 1.0728554725646973\n",
      "Epoch: 290, Batch: 40, Training Loss: 0.5257026553153992\n",
      "Epoch: 290, Batch: 80, Training Loss: 0.519895613193512\n",
      "Epoch: 290, Validation Loss: 1.0835148096084595\n",
      "Epoch: 291, Batch: 40, Training Loss: 0.7630620002746582\n",
      "Epoch: 291, Batch: 80, Training Loss: 0.6363479495048523\n",
      "Epoch: 291, Validation Loss: 1.0920906066894531\n",
      "Epoch: 292, Batch: 40, Training Loss: 0.6352186799049377\n",
      "Epoch: 292, Batch: 80, Training Loss: 0.6238042116165161\n",
      "Epoch: 292, Validation Loss: 1.2370814085006714\n",
      "Epoch: 293, Batch: 40, Training Loss: 0.5964855551719666\n",
      "Epoch: 293, Batch: 80, Training Loss: 0.6542922258377075\n",
      "Epoch: 293, Validation Loss: 1.1511393785476685\n",
      "Epoch: 294, Batch: 40, Training Loss: 0.6534768342971802\n",
      "Epoch: 294, Batch: 80, Training Loss: 0.6801359057426453\n",
      "Epoch: 294, Validation Loss: 1.1858441829681396\n",
      "Epoch: 295, Batch: 40, Training Loss: 0.6068372130393982\n",
      "Epoch: 295, Batch: 80, Training Loss: 0.6459594368934631\n",
      "Epoch: 295, Validation Loss: 1.1161034107208252\n",
      "Epoch: 296, Batch: 40, Training Loss: 0.5412077903747559\n",
      "Epoch: 296, Batch: 80, Training Loss: 0.6344949007034302\n",
      "Epoch: 296, Validation Loss: 1.110787034034729\n",
      "Epoch: 297, Batch: 40, Training Loss: 0.7127278447151184\n",
      "Epoch: 297, Batch: 80, Training Loss: 0.6275393962860107\n",
      "Epoch: 297, Validation Loss: 0.9885755777359009\n",
      "Epoch: 298, Batch: 40, Training Loss: 0.5548456311225891\n",
      "Epoch: 298, Batch: 80, Training Loss: 0.6215306520462036\n",
      "Epoch: 298, Validation Loss: 1.1044801473617554\n",
      "Epoch: 299, Batch: 40, Training Loss: 0.5780823826789856\n",
      "Epoch: 299, Batch: 80, Training Loss: 0.644709587097168\n",
      "Epoch: 299, Validation Loss: 1.031707525253296\n",
      "Epoch: 300, Batch: 40, Training Loss: 0.5126674771308899\n",
      "Epoch: 300, Batch: 80, Training Loss: 0.642016589641571\n",
      "Epoch: 300, Validation Loss: 1.0470741987228394\n",
      "Epoch: 301, Batch: 40, Training Loss: 0.6202817559242249\n",
      "Epoch: 301, Batch: 80, Training Loss: 0.569951593875885\n",
      "Epoch: 301, Validation Loss: 1.0431679487228394\n",
      "Epoch: 302, Batch: 40, Training Loss: 0.6692783832550049\n",
      "Epoch: 302, Batch: 80, Training Loss: 0.6259458661079407\n",
      "Epoch: 302, Validation Loss: 1.0923818349838257\n",
      "Epoch: 303, Batch: 40, Training Loss: 0.6408625841140747\n",
      "Epoch: 303, Batch: 80, Training Loss: 0.6069772243499756\n",
      "Epoch: 303, Validation Loss: 1.29243004322052\n",
      "Epoch: 304, Batch: 40, Training Loss: 0.5683069229125977\n",
      "Epoch: 304, Batch: 80, Training Loss: 0.527904212474823\n",
      "Epoch: 304, Validation Loss: 1.0990961790084839\n",
      "Epoch: 305, Batch: 40, Training Loss: 0.6138637065887451\n",
      "Epoch: 305, Batch: 80, Training Loss: 0.6342813968658447\n",
      "Epoch: 305, Validation Loss: 1.1053297519683838\n",
      "Epoch: 306, Batch: 40, Training Loss: 0.6487213373184204\n",
      "Epoch: 306, Batch: 80, Training Loss: 0.6445547938346863\n",
      "Epoch: 306, Validation Loss: 1.123084545135498\n",
      "Epoch: 307, Batch: 40, Training Loss: 0.632161021232605\n",
      "Epoch: 307, Batch: 80, Training Loss: 0.6980401873588562\n",
      "Epoch: 307, Validation Loss: 1.139064908027649\n",
      "Epoch: 308, Batch: 40, Training Loss: 0.6951138973236084\n",
      "Epoch: 308, Batch: 80, Training Loss: 0.6026477813720703\n",
      "Epoch: 308, Validation Loss: 1.1430572271347046\n",
      "Epoch: 309, Batch: 40, Training Loss: 0.645250678062439\n",
      "Epoch: 309, Batch: 80, Training Loss: 0.6518648266792297\n",
      "Epoch: 309, Validation Loss: 1.2225338220596313\n",
      "Epoch: 310, Batch: 40, Training Loss: 0.7409501671791077\n",
      "Epoch: 310, Batch: 80, Training Loss: 0.5613094568252563\n",
      "Epoch: 310, Validation Loss: 1.0079479217529297\n",
      "Epoch: 311, Batch: 40, Training Loss: 0.6524600982666016\n",
      "Epoch: 311, Batch: 80, Training Loss: 0.5685104131698608\n",
      "Epoch: 311, Validation Loss: 1.1061129570007324\n",
      "Epoch: 312, Batch: 40, Training Loss: 0.5888665318489075\n",
      "Epoch: 312, Batch: 80, Training Loss: 0.6571046710014343\n",
      "Epoch: 312, Validation Loss: 1.0524951219558716\n",
      "Epoch: 313, Batch: 40, Training Loss: 0.5822752714157104\n",
      "Epoch: 313, Batch: 80, Training Loss: 0.6818498373031616\n",
      "Epoch: 313, Validation Loss: 1.1511857509613037\n",
      "Epoch: 314, Batch: 40, Training Loss: 0.5750776529312134\n",
      "Epoch: 314, Batch: 80, Training Loss: 0.6715944409370422\n",
      "Epoch: 314, Validation Loss: 1.0866420269012451\n",
      "Epoch: 315, Batch: 40, Training Loss: 0.5546647310256958\n",
      "Epoch: 315, Batch: 80, Training Loss: 0.6765891313552856\n",
      "Epoch: 315, Validation Loss: 1.1402486562728882\n",
      "Epoch: 316, Batch: 40, Training Loss: 0.5777638554573059\n",
      "Epoch: 316, Batch: 80, Training Loss: 0.6141507029533386\n",
      "Epoch: 316, Validation Loss: 1.0957145690917969\n",
      "Epoch: 317, Batch: 40, Training Loss: 0.5636398792266846\n",
      "Epoch: 317, Batch: 80, Training Loss: 0.6466457843780518\n",
      "Epoch: 317, Validation Loss: 0.984255850315094\n",
      "Epoch: 318, Batch: 40, Training Loss: 0.5812122225761414\n",
      "Epoch: 318, Batch: 80, Training Loss: 0.5605080127716064\n",
      "Epoch: 318, Validation Loss: 1.1670801639556885\n",
      "Epoch: 319, Batch: 40, Training Loss: 0.6444165110588074\n",
      "Epoch: 319, Batch: 80, Training Loss: 0.5734826922416687\n",
      "Epoch: 319, Validation Loss: 1.070993423461914\n",
      "Epoch: 320, Batch: 40, Training Loss: 0.6353051066398621\n",
      "Epoch: 320, Batch: 80, Training Loss: 0.6145984530448914\n",
      "Epoch: 320, Validation Loss: 1.081845760345459\n",
      "Epoch: 321, Batch: 40, Training Loss: 0.528723955154419\n",
      "Epoch: 321, Batch: 80, Training Loss: 0.6180570125579834\n",
      "Epoch: 321, Validation Loss: 0.9908666014671326\n",
      "Epoch: 322, Batch: 40, Training Loss: 0.5931259393692017\n",
      "Epoch: 322, Batch: 80, Training Loss: 0.5204737782478333\n",
      "Epoch: 322, Validation Loss: 1.0747419595718384\n",
      "Epoch: 323, Batch: 40, Training Loss: 0.5879423022270203\n",
      "Epoch: 323, Batch: 80, Training Loss: 0.6223877668380737\n",
      "Epoch: 323, Validation Loss: 0.9345807433128357\n",
      "Epoch: 324, Batch: 40, Training Loss: 0.5894358158111572\n",
      "Epoch: 324, Batch: 80, Training Loss: 0.6303930878639221\n",
      "Epoch: 324, Validation Loss: 1.1496939659118652\n",
      "Epoch: 325, Batch: 40, Training Loss: 0.6189996600151062\n",
      "Epoch: 325, Batch: 80, Training Loss: 0.6335577964782715\n",
      "Epoch: 325, Validation Loss: 1.1286234855651855\n",
      "Epoch: 326, Batch: 40, Training Loss: 0.5743996500968933\n",
      "Epoch: 326, Batch: 80, Training Loss: 0.615619957447052\n",
      "Epoch: 326, Validation Loss: 1.1665071249008179\n",
      "Epoch: 327, Batch: 40, Training Loss: 0.6669996380805969\n",
      "Epoch: 327, Batch: 80, Training Loss: 0.5961377620697021\n",
      "Epoch: 327, Validation Loss: 1.14291512966156\n",
      "Epoch: 328, Batch: 40, Training Loss: 0.5268280506134033\n",
      "Epoch: 328, Batch: 80, Training Loss: 0.6299448013305664\n",
      "Epoch: 328, Validation Loss: 1.1325790882110596\n",
      "Epoch: 329, Batch: 40, Training Loss: 0.5672743916511536\n",
      "Epoch: 329, Batch: 80, Training Loss: 0.5709819197654724\n",
      "Epoch: 329, Validation Loss: 1.1179322004318237\n",
      "Epoch: 330, Batch: 40, Training Loss: 0.5739263296127319\n",
      "Epoch: 330, Batch: 80, Training Loss: 0.6628750562667847\n",
      "Epoch: 330, Validation Loss: 1.023209810256958\n",
      "Epoch: 331, Batch: 40, Training Loss: 0.616934597492218\n",
      "Epoch: 331, Batch: 80, Training Loss: 0.7254281640052795\n",
      "Epoch: 331, Validation Loss: 1.1510310173034668\n",
      "Epoch: 332, Batch: 40, Training Loss: 0.5803915858268738\n",
      "Epoch: 332, Batch: 80, Training Loss: 0.5859705209732056\n",
      "Epoch: 332, Validation Loss: 1.3126142024993896\n",
      "Epoch: 333, Batch: 40, Training Loss: 0.5732167959213257\n",
      "Epoch: 333, Batch: 80, Training Loss: 0.5955067276954651\n",
      "Epoch: 333, Validation Loss: 1.1512823104858398\n",
      "Epoch: 334, Batch: 40, Training Loss: 0.5582761168479919\n",
      "Epoch: 334, Batch: 80, Training Loss: 0.681933581829071\n",
      "Epoch: 334, Validation Loss: 1.1309231519699097\n",
      "Epoch: 335, Batch: 40, Training Loss: 0.5853430032730103\n",
      "Epoch: 335, Batch: 80, Training Loss: 0.6221350431442261\n",
      "Epoch: 335, Validation Loss: 1.0209888219833374\n",
      "Epoch: 336, Batch: 40, Training Loss: 0.5875464677810669\n",
      "Epoch: 336, Batch: 80, Training Loss: 0.6753314137458801\n",
      "Epoch: 336, Validation Loss: 1.1649484634399414\n",
      "Epoch: 337, Batch: 40, Training Loss: 0.6000825762748718\n",
      "Epoch: 337, Batch: 80, Training Loss: 0.5914125442504883\n",
      "Epoch: 337, Validation Loss: 1.1240670680999756\n",
      "Epoch: 338, Batch: 40, Training Loss: 0.5463112592697144\n",
      "Epoch: 338, Batch: 80, Training Loss: 0.6413484811782837\n",
      "Epoch: 338, Validation Loss: 1.2318967580795288\n",
      "Epoch: 339, Batch: 40, Training Loss: 0.5628323554992676\n",
      "Epoch: 339, Batch: 80, Training Loss: 0.5867406129837036\n",
      "Epoch: 339, Validation Loss: 1.1043460369110107\n",
      "Epoch: 340, Batch: 40, Training Loss: 0.6000496745109558\n",
      "Epoch: 340, Batch: 80, Training Loss: 0.5924474596977234\n",
      "Epoch: 340, Validation Loss: 1.1774653196334839\n",
      "Epoch: 341, Batch: 40, Training Loss: 0.6372533440589905\n",
      "Epoch: 341, Batch: 80, Training Loss: 0.6054238677024841\n",
      "Epoch: 341, Validation Loss: 1.2452514171600342\n",
      "Epoch: 342, Batch: 40, Training Loss: 0.5965878963470459\n",
      "Epoch: 342, Batch: 80, Training Loss: 0.5597485303878784\n",
      "Epoch: 342, Validation Loss: 1.153584361076355\n",
      "Epoch: 343, Batch: 40, Training Loss: 0.5686522722244263\n",
      "Epoch: 343, Batch: 80, Training Loss: 0.5987003445625305\n",
      "Epoch: 343, Validation Loss: 1.195011019706726\n",
      "Epoch: 344, Batch: 40, Training Loss: 0.475149542093277\n",
      "Epoch: 344, Batch: 80, Training Loss: 0.5676259398460388\n",
      "Epoch: 344, Validation Loss: 1.0244932174682617\n",
      "Epoch: 345, Batch: 40, Training Loss: 0.5535574555397034\n",
      "Epoch: 345, Batch: 80, Training Loss: 0.6356138586997986\n",
      "Epoch: 345, Validation Loss: 1.1976815462112427\n",
      "Epoch: 346, Batch: 40, Training Loss: 0.6086877584457397\n",
      "Epoch: 346, Batch: 80, Training Loss: 0.5817717909812927\n",
      "Epoch: 346, Validation Loss: 1.1566907167434692\n",
      "Epoch: 347, Batch: 40, Training Loss: 0.620531439781189\n",
      "Epoch: 347, Batch: 80, Training Loss: 0.5406484603881836\n",
      "Epoch: 347, Validation Loss: 1.1293790340423584\n",
      "Epoch: 348, Batch: 40, Training Loss: 0.5460159778594971\n",
      "Epoch: 348, Batch: 80, Training Loss: 0.5875329375267029\n",
      "Epoch: 348, Validation Loss: 1.1411664485931396\n",
      "Epoch: 349, Batch: 40, Training Loss: 0.5960515141487122\n",
      "Epoch: 349, Batch: 80, Training Loss: 0.618906557559967\n",
      "Epoch: 349, Validation Loss: 1.128180980682373\n",
      "Epoch: 350, Batch: 40, Training Loss: 0.621743381023407\n",
      "Epoch: 350, Batch: 80, Training Loss: 0.5794386863708496\n",
      "Epoch: 350, Validation Loss: 1.2129625082015991\n",
      "Epoch: 351, Batch: 40, Training Loss: 0.6135467886924744\n",
      "Epoch: 351, Batch: 80, Training Loss: 0.6092773079872131\n",
      "Epoch: 351, Validation Loss: 1.1516128778457642\n",
      "Epoch: 352, Batch: 40, Training Loss: 0.5753642916679382\n",
      "Epoch: 352, Batch: 80, Training Loss: 0.5984758734703064\n",
      "Epoch: 352, Validation Loss: 1.1760375499725342\n",
      "Epoch: 353, Batch: 40, Training Loss: 0.6055178642272949\n",
      "Epoch: 353, Batch: 80, Training Loss: 0.6296765208244324\n",
      "Epoch: 353, Validation Loss: 1.0415459871292114\n",
      "Epoch: 354, Batch: 40, Training Loss: 0.5840252041816711\n",
      "Epoch: 354, Batch: 80, Training Loss: 0.6740859150886536\n",
      "Epoch: 354, Validation Loss: 1.0170502662658691\n",
      "Epoch: 355, Batch: 40, Training Loss: 0.5210970044136047\n",
      "Epoch: 355, Batch: 80, Training Loss: 0.6563968658447266\n",
      "Epoch: 355, Validation Loss: 1.116550326347351\n",
      "Epoch: 356, Batch: 40, Training Loss: 0.5893399119377136\n",
      "Epoch: 356, Batch: 80, Training Loss: 0.5693871378898621\n",
      "Epoch: 356, Validation Loss: 1.139327883720398\n",
      "Epoch: 357, Batch: 40, Training Loss: 0.5406641960144043\n",
      "Epoch: 357, Batch: 80, Training Loss: 0.6262248754501343\n",
      "Epoch: 357, Validation Loss: 1.179367184638977\n",
      "Epoch: 358, Batch: 40, Training Loss: 0.5290266871452332\n",
      "Epoch: 358, Batch: 80, Training Loss: 0.6373151540756226\n",
      "Epoch: 358, Validation Loss: 1.0736217498779297\n",
      "Epoch: 359, Batch: 40, Training Loss: 0.5191968679428101\n",
      "Epoch: 359, Batch: 80, Training Loss: 0.6136206388473511\n",
      "Epoch: 359, Validation Loss: 1.042072057723999\n",
      "Epoch: 360, Batch: 40, Training Loss: 0.6014688014984131\n",
      "Epoch: 360, Batch: 80, Training Loss: 0.4801178574562073\n",
      "Epoch: 360, Validation Loss: 0.9818691611289978\n",
      "Epoch: 361, Batch: 40, Training Loss: 0.5604232549667358\n",
      "Epoch: 361, Batch: 80, Training Loss: 0.5895024538040161\n",
      "Epoch: 361, Validation Loss: 1.1803929805755615\n",
      "Epoch: 362, Batch: 40, Training Loss: 0.6710716485977173\n",
      "Epoch: 362, Batch: 80, Training Loss: 0.5930801033973694\n",
      "Epoch: 362, Validation Loss: 1.1619175672531128\n",
      "Epoch: 363, Batch: 40, Training Loss: 0.584345281124115\n",
      "Epoch: 363, Batch: 80, Training Loss: 0.5707314610481262\n",
      "Epoch: 363, Validation Loss: 1.0674705505371094\n",
      "Epoch: 364, Batch: 40, Training Loss: 0.6144801378250122\n",
      "Epoch: 364, Batch: 80, Training Loss: 0.6480048298835754\n",
      "Epoch: 364, Validation Loss: 1.1661791801452637\n",
      "Epoch: 365, Batch: 40, Training Loss: 0.6018707156181335\n",
      "Epoch: 365, Batch: 80, Training Loss: 0.5400199294090271\n",
      "Epoch: 365, Validation Loss: 1.0086570978164673\n",
      "Epoch: 366, Batch: 40, Training Loss: 0.5988116264343262\n",
      "Epoch: 366, Batch: 80, Training Loss: 0.5640591382980347\n",
      "Epoch: 366, Validation Loss: 1.0521318912506104\n",
      "Epoch: 367, Batch: 40, Training Loss: 0.543537974357605\n",
      "Epoch: 367, Batch: 80, Training Loss: 0.6061683297157288\n",
      "Epoch: 367, Validation Loss: 1.0981864929199219\n",
      "Epoch: 368, Batch: 40, Training Loss: 0.5902136564254761\n",
      "Epoch: 368, Batch: 80, Training Loss: 0.6606912016868591\n",
      "Epoch: 368, Validation Loss: 1.0915617942810059\n",
      "Epoch: 369, Batch: 40, Training Loss: 0.5582916140556335\n",
      "Epoch: 369, Batch: 80, Training Loss: 0.6120973229408264\n",
      "Epoch: 369, Validation Loss: 1.1183847188949585\n",
      "Epoch: 370, Batch: 40, Training Loss: 0.7100412249565125\n",
      "Epoch: 370, Batch: 80, Training Loss: 0.6235181093215942\n",
      "Epoch: 370, Validation Loss: 1.0721800327301025\n",
      "Epoch: 371, Batch: 40, Training Loss: 0.5638391971588135\n",
      "Epoch: 371, Batch: 80, Training Loss: 0.6418271660804749\n",
      "Epoch: 371, Validation Loss: 0.9559232592582703\n",
      "Epoch: 372, Batch: 40, Training Loss: 0.5763006806373596\n",
      "Epoch: 372, Batch: 80, Training Loss: 0.5794484615325928\n",
      "Epoch: 372, Validation Loss: 0.9784042835235596\n",
      "Epoch: 373, Batch: 40, Training Loss: 0.5738732218742371\n",
      "Epoch: 373, Batch: 80, Training Loss: 0.576630711555481\n",
      "Epoch: 373, Validation Loss: 1.0970743894577026\n",
      "Epoch: 374, Batch: 40, Training Loss: 0.5623656511306763\n",
      "Epoch: 374, Batch: 80, Training Loss: 0.5916686058044434\n",
      "Epoch: 374, Validation Loss: 1.1432913541793823\n",
      "Epoch: 375, Batch: 40, Training Loss: 0.5456235408782959\n",
      "Epoch: 375, Batch: 80, Training Loss: 0.5957333445549011\n",
      "Epoch: 375, Validation Loss: 1.0652656555175781\n",
      "Epoch: 376, Batch: 40, Training Loss: 0.5586235523223877\n",
      "Epoch: 376, Batch: 80, Training Loss: 0.5894555449485779\n",
      "Epoch: 376, Validation Loss: 1.2911182641983032\n",
      "Epoch: 377, Batch: 40, Training Loss: 0.5360547304153442\n",
      "Epoch: 377, Batch: 80, Training Loss: 0.5669452548027039\n",
      "Epoch: 377, Validation Loss: 1.1273984909057617\n",
      "Epoch: 378, Batch: 40, Training Loss: 0.604744553565979\n",
      "Epoch: 378, Batch: 80, Training Loss: 0.5531213879585266\n",
      "Epoch: 378, Validation Loss: 1.2515677213668823\n",
      "Epoch: 379, Batch: 40, Training Loss: 0.5831556916236877\n",
      "Epoch: 379, Batch: 80, Training Loss: 0.651698648929596\n",
      "Epoch: 379, Validation Loss: 1.1822885274887085\n",
      "Epoch: 380, Batch: 40, Training Loss: 0.5998737215995789\n",
      "Epoch: 380, Batch: 80, Training Loss: 0.6808733940124512\n",
      "Epoch: 380, Validation Loss: 1.032843828201294\n",
      "Epoch: 381, Batch: 40, Training Loss: 0.5126296281814575\n",
      "Epoch: 381, Batch: 80, Training Loss: 0.6249077320098877\n",
      "Epoch: 381, Validation Loss: 1.2105283737182617\n",
      "Epoch: 382, Batch: 40, Training Loss: 0.6221941709518433\n",
      "Epoch: 382, Batch: 80, Training Loss: 0.5820124745368958\n",
      "Epoch: 382, Validation Loss: 1.2562519311904907\n",
      "Epoch: 383, Batch: 40, Training Loss: 0.5571888089179993\n",
      "Epoch: 383, Batch: 80, Training Loss: 0.6485874056816101\n",
      "Epoch: 383, Validation Loss: 1.1726585626602173\n",
      "Epoch: 384, Batch: 40, Training Loss: 0.544863224029541\n",
      "Epoch: 384, Batch: 80, Training Loss: 0.5555004477500916\n",
      "Epoch: 384, Validation Loss: 1.1249134540557861\n",
      "Epoch: 385, Batch: 40, Training Loss: 0.6166574954986572\n",
      "Epoch: 385, Batch: 80, Training Loss: 0.626517117023468\n",
      "Epoch: 385, Validation Loss: 1.2192888259887695\n",
      "Epoch: 386, Batch: 40, Training Loss: 0.5890148878097534\n",
      "Epoch: 386, Batch: 80, Training Loss: 0.5731838941574097\n",
      "Epoch: 386, Validation Loss: 1.122732162475586\n",
      "Epoch: 387, Batch: 40, Training Loss: 0.5581806302070618\n",
      "Epoch: 387, Batch: 80, Training Loss: 0.5591219067573547\n",
      "Epoch: 387, Validation Loss: 1.1209635734558105\n",
      "Epoch: 388, Batch: 40, Training Loss: 0.6649033427238464\n",
      "Epoch: 388, Batch: 80, Training Loss: 0.5983359217643738\n",
      "Epoch: 388, Validation Loss: 1.168846607208252\n",
      "Epoch: 389, Batch: 40, Training Loss: 0.5411447882652283\n",
      "Epoch: 389, Batch: 80, Training Loss: 0.6479100584983826\n",
      "Epoch: 389, Validation Loss: 1.1142001152038574\n",
      "Epoch: 390, Batch: 40, Training Loss: 0.5853297114372253\n",
      "Epoch: 390, Batch: 80, Training Loss: 0.5547382831573486\n",
      "Epoch: 390, Validation Loss: 0.9634125828742981\n",
      "Epoch: 391, Batch: 40, Training Loss: 0.6044137477874756\n",
      "Epoch: 391, Batch: 80, Training Loss: 0.6564995050430298\n",
      "Epoch: 391, Validation Loss: 1.1110663414001465\n",
      "Epoch: 392, Batch: 40, Training Loss: 0.5224382877349854\n",
      "Epoch: 392, Batch: 80, Training Loss: 0.6742627024650574\n",
      "Epoch: 392, Validation Loss: 1.029099464416504\n",
      "Epoch: 393, Batch: 40, Training Loss: 0.5638968348503113\n",
      "Epoch: 393, Batch: 80, Training Loss: 0.5272596478462219\n",
      "Epoch: 393, Validation Loss: 1.0910735130310059\n",
      "Epoch: 394, Batch: 40, Training Loss: 0.5861824750900269\n",
      "Epoch: 394, Batch: 80, Training Loss: 0.6239638924598694\n",
      "Epoch: 394, Validation Loss: 1.045486330986023\n",
      "Epoch: 395, Batch: 40, Training Loss: 0.6267213225364685\n",
      "Epoch: 395, Batch: 80, Training Loss: 0.5665536522865295\n",
      "Epoch: 395, Validation Loss: 1.164538860321045\n",
      "Epoch: 396, Batch: 40, Training Loss: 0.5688291192054749\n",
      "Epoch: 396, Batch: 80, Training Loss: 0.5372472405433655\n",
      "Epoch: 396, Validation Loss: 1.2181932926177979\n",
      "Epoch: 397, Batch: 40, Training Loss: 0.5645673274993896\n",
      "Epoch: 397, Batch: 80, Training Loss: 0.6076423525810242\n",
      "Epoch: 397, Validation Loss: 1.1550184488296509\n",
      "Epoch: 398, Batch: 40, Training Loss: 0.6513383984565735\n",
      "Epoch: 398, Batch: 80, Training Loss: 0.5920864939689636\n",
      "Epoch: 398, Validation Loss: 1.1179637908935547\n",
      "Epoch: 399, Batch: 40, Training Loss: 0.5950393676757812\n",
      "Epoch: 399, Batch: 80, Training Loss: 0.6285513043403625\n",
      "Epoch: 399, Validation Loss: 1.0498582124710083\n",
      "Epoch: 400, Batch: 40, Training Loss: 0.534903883934021\n",
      "Epoch: 400, Batch: 80, Training Loss: 0.5609681606292725\n",
      "Epoch: 400, Validation Loss: 1.1705434322357178\n",
      "Epoch: 401, Batch: 40, Training Loss: 0.5856781601905823\n",
      "Epoch: 401, Batch: 80, Training Loss: 0.6489453911781311\n",
      "Epoch: 401, Validation Loss: 1.1134320497512817\n",
      "Epoch: 402, Batch: 40, Training Loss: 0.49975448846817017\n",
      "Epoch: 402, Batch: 80, Training Loss: 0.6042308211326599\n",
      "Epoch: 402, Validation Loss: 1.314719796180725\n",
      "Epoch: 403, Batch: 40, Training Loss: 0.6383222937583923\n",
      "Epoch: 403, Batch: 80, Training Loss: 0.5559113621711731\n",
      "Epoch: 403, Validation Loss: 1.187994360923767\n",
      "Epoch: 404, Batch: 40, Training Loss: 0.6035481691360474\n",
      "Epoch: 404, Batch: 80, Training Loss: 0.5463889241218567\n",
      "Epoch: 404, Validation Loss: 1.213322401046753\n",
      "Epoch: 405, Batch: 40, Training Loss: 0.5250545144081116\n",
      "Epoch: 405, Batch: 80, Training Loss: 0.6225841641426086\n",
      "Epoch: 405, Validation Loss: 1.1293541193008423\n",
      "Epoch: 406, Batch: 40, Training Loss: 0.5803204774856567\n",
      "Epoch: 406, Batch: 80, Training Loss: 0.6799017786979675\n",
      "Epoch: 406, Validation Loss: 1.1262311935424805\n",
      "Epoch: 407, Batch: 40, Training Loss: 0.6445208787918091\n",
      "Epoch: 407, Batch: 80, Training Loss: 0.6186862587928772\n",
      "Epoch: 407, Validation Loss: 1.1177043914794922\n",
      "Epoch: 408, Batch: 40, Training Loss: 0.6951500177383423\n",
      "Epoch: 408, Batch: 80, Training Loss: 0.6285033226013184\n",
      "Epoch: 408, Validation Loss: 1.1162067651748657\n",
      "Epoch: 409, Batch: 40, Training Loss: 0.5376385450363159\n",
      "Epoch: 409, Batch: 80, Training Loss: 0.5275918245315552\n",
      "Epoch: 409, Validation Loss: 1.163123369216919\n",
      "Epoch: 410, Batch: 40, Training Loss: 0.6119644641876221\n",
      "Epoch: 410, Batch: 80, Training Loss: 0.6323871612548828\n",
      "Epoch: 410, Validation Loss: 1.207960844039917\n",
      "Epoch: 411, Batch: 40, Training Loss: 0.4993816912174225\n",
      "Epoch: 411, Batch: 80, Training Loss: 0.5815101265907288\n",
      "Epoch: 411, Validation Loss: 1.1081124544143677\n",
      "Epoch: 412, Batch: 40, Training Loss: 0.5353398323059082\n",
      "Epoch: 412, Batch: 80, Training Loss: 0.5388291478157043\n",
      "Epoch: 412, Validation Loss: 1.1188454627990723\n",
      "Epoch: 413, Batch: 40, Training Loss: 0.5487403273582458\n",
      "Epoch: 413, Batch: 80, Training Loss: 0.5731683373451233\n",
      "Epoch: 413, Validation Loss: 1.2935848236083984\n",
      "Epoch: 414, Batch: 40, Training Loss: 0.5188488960266113\n",
      "Epoch: 414, Batch: 80, Training Loss: 0.620131254196167\n",
      "Epoch: 414, Validation Loss: 1.2589143514633179\n",
      "Epoch: 415, Batch: 40, Training Loss: 0.5442682504653931\n",
      "Epoch: 415, Batch: 80, Training Loss: 0.5942416787147522\n",
      "Epoch: 415, Validation Loss: 1.088141679763794\n",
      "Epoch: 416, Batch: 40, Training Loss: 0.5799939036369324\n",
      "Epoch: 416, Batch: 80, Training Loss: 0.750109851360321\n",
      "Epoch: 416, Validation Loss: 1.103105068206787\n",
      "Epoch: 417, Batch: 40, Training Loss: 0.5730708837509155\n",
      "Epoch: 417, Batch: 80, Training Loss: 0.5935624241828918\n",
      "Epoch: 417, Validation Loss: 1.0319186449050903\n",
      "Epoch: 418, Batch: 40, Training Loss: 0.6030298471450806\n",
      "Epoch: 418, Batch: 80, Training Loss: 0.6089125275611877\n",
      "Epoch: 418, Validation Loss: 1.2158547639846802\n",
      "Epoch: 419, Batch: 40, Training Loss: 0.5957828164100647\n",
      "Epoch: 419, Batch: 80, Training Loss: 0.574740469455719\n",
      "Epoch: 419, Validation Loss: 1.2427098751068115\n",
      "Epoch: 420, Batch: 40, Training Loss: 0.5779185891151428\n",
      "Epoch: 420, Batch: 80, Training Loss: 0.5516188144683838\n",
      "Epoch: 420, Validation Loss: 1.1503069400787354\n",
      "Epoch: 421, Batch: 40, Training Loss: 0.6122652292251587\n",
      "Epoch: 421, Batch: 80, Training Loss: 0.590945839881897\n",
      "Epoch: 421, Validation Loss: 1.156626582145691\n",
      "Epoch: 422, Batch: 40, Training Loss: 0.6099237203598022\n",
      "Epoch: 422, Batch: 80, Training Loss: 0.6170368790626526\n",
      "Epoch: 422, Validation Loss: 1.1992113590240479\n",
      "Epoch: 423, Batch: 40, Training Loss: 0.6104080677032471\n",
      "Epoch: 423, Batch: 80, Training Loss: 0.5247900485992432\n",
      "Epoch: 423, Validation Loss: 1.1214786767959595\n",
      "Epoch: 424, Batch: 40, Training Loss: 0.5817570686340332\n",
      "Epoch: 424, Batch: 80, Training Loss: 0.5751492381095886\n",
      "Epoch: 424, Validation Loss: 1.0452322959899902\n",
      "Epoch: 425, Batch: 40, Training Loss: 0.5805690884590149\n",
      "Epoch: 425, Batch: 80, Training Loss: 0.55670166015625\n",
      "Epoch: 425, Validation Loss: 1.044311285018921\n",
      "Epoch: 426, Batch: 40, Training Loss: 0.597692608833313\n",
      "Epoch: 426, Batch: 80, Training Loss: 0.5381972193717957\n",
      "Epoch: 426, Validation Loss: 1.1652190685272217\n",
      "Epoch: 427, Batch: 40, Training Loss: 0.5048576593399048\n",
      "Epoch: 427, Batch: 80, Training Loss: 0.5319744944572449\n",
      "Epoch: 427, Validation Loss: 1.0028762817382812\n",
      "Epoch: 428, Batch: 40, Training Loss: 0.5568602085113525\n",
      "Epoch: 428, Batch: 80, Training Loss: 0.6198691129684448\n",
      "Epoch: 428, Validation Loss: 1.2265629768371582\n",
      "Epoch: 429, Batch: 40, Training Loss: 0.5539389252662659\n",
      "Epoch: 429, Batch: 80, Training Loss: 0.6331490874290466\n",
      "Epoch: 429, Validation Loss: 1.145231008529663\n",
      "Epoch: 430, Batch: 40, Training Loss: 0.6104552745819092\n",
      "Epoch: 430, Batch: 80, Training Loss: 0.6038480997085571\n",
      "Epoch: 430, Validation Loss: 1.1403484344482422\n",
      "Epoch: 431, Batch: 40, Training Loss: 0.5262757539749146\n",
      "Epoch: 431, Batch: 80, Training Loss: 0.5696413516998291\n",
      "Epoch: 431, Validation Loss: 1.1715941429138184\n",
      "Epoch: 432, Batch: 40, Training Loss: 0.5667898058891296\n",
      "Epoch: 432, Batch: 80, Training Loss: 0.7106876373291016\n",
      "Epoch: 432, Validation Loss: 1.1405185461044312\n",
      "Epoch: 433, Batch: 40, Training Loss: 0.53472900390625\n",
      "Epoch: 433, Batch: 80, Training Loss: 0.622897744178772\n",
      "Epoch: 433, Validation Loss: 1.2083228826522827\n",
      "Epoch: 434, Batch: 40, Training Loss: 0.5642573833465576\n",
      "Epoch: 434, Batch: 80, Training Loss: 0.5623698830604553\n",
      "Epoch: 434, Validation Loss: 1.248964548110962\n",
      "Epoch: 435, Batch: 40, Training Loss: 0.5572239756584167\n",
      "Epoch: 435, Batch: 80, Training Loss: 0.6427422165870667\n",
      "Epoch: 435, Validation Loss: 1.0565130710601807\n",
      "Epoch: 436, Batch: 40, Training Loss: 0.5279017686843872\n",
      "Epoch: 436, Batch: 80, Training Loss: 0.5445725917816162\n",
      "Epoch: 436, Validation Loss: 1.035167932510376\n",
      "Epoch: 437, Batch: 40, Training Loss: 0.5702825784683228\n",
      "Epoch: 437, Batch: 80, Training Loss: 0.5774328708648682\n",
      "Epoch: 437, Validation Loss: 1.299557089805603\n",
      "Epoch: 438, Batch: 40, Training Loss: 0.5439631938934326\n",
      "Epoch: 438, Batch: 80, Training Loss: 0.550881564617157\n",
      "Epoch: 438, Validation Loss: 1.1812448501586914\n",
      "Epoch: 439, Batch: 40, Training Loss: 0.618964433670044\n",
      "Epoch: 439, Batch: 80, Training Loss: 0.6263102293014526\n",
      "Epoch: 439, Validation Loss: 1.1194469928741455\n",
      "Epoch: 440, Batch: 40, Training Loss: 0.5461243391036987\n",
      "Epoch: 440, Batch: 80, Training Loss: 0.5201634764671326\n",
      "Epoch: 440, Validation Loss: 1.196969747543335\n",
      "Epoch: 441, Batch: 40, Training Loss: 0.531475305557251\n",
      "Epoch: 441, Batch: 80, Training Loss: 0.6278767585754395\n",
      "Epoch: 441, Validation Loss: 1.1161344051361084\n",
      "Epoch: 442, Batch: 40, Training Loss: 0.5503457188606262\n",
      "Epoch: 442, Batch: 80, Training Loss: 0.5779703259468079\n",
      "Epoch: 442, Validation Loss: 1.0689091682434082\n",
      "Epoch: 443, Batch: 40, Training Loss: 0.5922923684120178\n",
      "Epoch: 443, Batch: 80, Training Loss: 0.5760799646377563\n",
      "Epoch: 443, Validation Loss: 1.036947250366211\n",
      "Epoch: 444, Batch: 40, Training Loss: 0.4897519052028656\n",
      "Epoch: 444, Batch: 80, Training Loss: 0.5922414064407349\n",
      "Epoch: 444, Validation Loss: 1.0810695886611938\n",
      "Epoch: 445, Batch: 40, Training Loss: 0.5249001979827881\n",
      "Epoch: 445, Batch: 80, Training Loss: 0.6303697824478149\n",
      "Epoch: 445, Validation Loss: 1.182754635810852\n",
      "Epoch: 446, Batch: 40, Training Loss: 0.5195522308349609\n",
      "Epoch: 446, Batch: 80, Training Loss: 0.5776879787445068\n",
      "Epoch: 446, Validation Loss: 1.0258417129516602\n",
      "Epoch: 447, Batch: 40, Training Loss: 0.5298372507095337\n",
      "Epoch: 447, Batch: 80, Training Loss: 0.6286073923110962\n",
      "Epoch: 447, Validation Loss: 1.0694167613983154\n",
      "Epoch: 448, Batch: 40, Training Loss: 0.5733417272567749\n",
      "Epoch: 448, Batch: 80, Training Loss: 0.6489814519882202\n",
      "Epoch: 448, Validation Loss: 1.1744669675827026\n",
      "Epoch: 449, Batch: 40, Training Loss: 0.595273494720459\n",
      "Epoch: 449, Batch: 80, Training Loss: 0.5801591873168945\n",
      "Epoch: 449, Validation Loss: 1.2289592027664185\n",
      "Epoch: 450, Batch: 40, Training Loss: 0.5367238521575928\n",
      "Epoch: 450, Batch: 80, Training Loss: 0.5013640522956848\n",
      "Epoch: 450, Validation Loss: 1.1982685327529907\n",
      "Epoch: 451, Batch: 40, Training Loss: 0.5660389065742493\n",
      "Epoch: 451, Batch: 80, Training Loss: 0.5400523543357849\n",
      "Epoch: 451, Validation Loss: 1.2143739461898804\n",
      "Epoch: 452, Batch: 40, Training Loss: 0.5880324244499207\n",
      "Epoch: 452, Batch: 80, Training Loss: 0.5497679114341736\n",
      "Epoch: 452, Validation Loss: 1.14997398853302\n",
      "Epoch: 453, Batch: 40, Training Loss: 0.5031753182411194\n",
      "Epoch: 453, Batch: 80, Training Loss: 0.5594569444656372\n",
      "Epoch: 453, Validation Loss: 1.0336767435073853\n",
      "Epoch: 454, Batch: 40, Training Loss: 0.5333972573280334\n",
      "Epoch: 454, Batch: 80, Training Loss: 0.5943096876144409\n",
      "Epoch: 454, Validation Loss: 1.0962711572647095\n",
      "Epoch: 455, Batch: 40, Training Loss: 0.523000180721283\n",
      "Epoch: 455, Batch: 80, Training Loss: 0.5782192349433899\n",
      "Epoch: 455, Validation Loss: 1.2387124300003052\n",
      "Epoch: 456, Batch: 40, Training Loss: 0.5793939828872681\n",
      "Epoch: 456, Batch: 80, Training Loss: 0.6131563782691956\n",
      "Epoch: 456, Validation Loss: 1.1282589435577393\n",
      "Epoch: 457, Batch: 40, Training Loss: 0.5428144931793213\n",
      "Epoch: 457, Batch: 80, Training Loss: 0.585724413394928\n",
      "Epoch: 457, Validation Loss: 1.0734909772872925\n",
      "Epoch: 458, Batch: 40, Training Loss: 0.5645850300788879\n",
      "Epoch: 458, Batch: 80, Training Loss: 0.5635374188423157\n",
      "Epoch: 458, Validation Loss: 1.2682290077209473\n",
      "Epoch: 459, Batch: 40, Training Loss: 0.501937747001648\n",
      "Epoch: 459, Batch: 80, Training Loss: 0.5253273248672485\n",
      "Epoch: 459, Validation Loss: 1.1596218347549438\n",
      "Epoch: 460, Batch: 40, Training Loss: 0.5769146680831909\n",
      "Epoch: 460, Batch: 80, Training Loss: 0.603583574295044\n",
      "Epoch: 460, Validation Loss: 1.0714162588119507\n",
      "Epoch: 461, Batch: 40, Training Loss: 0.5876814126968384\n",
      "Epoch: 461, Batch: 80, Training Loss: 0.5127642750740051\n",
      "Epoch: 461, Validation Loss: 1.1970582008361816\n",
      "Epoch: 462, Batch: 40, Training Loss: 0.5124215483665466\n",
      "Epoch: 462, Batch: 80, Training Loss: 0.6304309964179993\n",
      "Epoch: 462, Validation Loss: 1.1636803150177002\n",
      "Epoch: 463, Batch: 40, Training Loss: 0.5313873887062073\n",
      "Epoch: 463, Batch: 80, Training Loss: 0.5536096692085266\n",
      "Epoch: 463, Validation Loss: 1.1216968297958374\n",
      "Epoch: 464, Batch: 40, Training Loss: 0.5406051874160767\n",
      "Epoch: 464, Batch: 80, Training Loss: 0.5508221983909607\n",
      "Epoch: 464, Validation Loss: 1.11664879322052\n",
      "Epoch: 465, Batch: 40, Training Loss: 0.562113881111145\n",
      "Epoch: 465, Batch: 80, Training Loss: 0.5812968611717224\n",
      "Epoch: 465, Validation Loss: 1.3192232847213745\n",
      "Epoch: 466, Batch: 40, Training Loss: 0.5728991031646729\n",
      "Epoch: 466, Batch: 80, Training Loss: 0.5096996426582336\n",
      "Epoch: 466, Validation Loss: 1.2060126066207886\n",
      "Epoch: 467, Batch: 40, Training Loss: 0.5922156572341919\n",
      "Epoch: 467, Batch: 80, Training Loss: 0.5678334832191467\n",
      "Epoch: 467, Validation Loss: 1.2182552814483643\n",
      "Epoch: 468, Batch: 40, Training Loss: 0.6339088082313538\n",
      "Epoch: 468, Batch: 80, Training Loss: 0.5876643061637878\n",
      "Epoch: 468, Validation Loss: 1.1072262525558472\n",
      "Epoch: 469, Batch: 40, Training Loss: 0.4943290948867798\n",
      "Epoch: 469, Batch: 80, Training Loss: 0.5674359798431396\n",
      "Epoch: 469, Validation Loss: 1.2418885231018066\n",
      "Epoch: 470, Batch: 40, Training Loss: 0.5816013216972351\n",
      "Epoch: 470, Batch: 80, Training Loss: 0.6359336972236633\n",
      "Epoch: 470, Validation Loss: 1.2098114490509033\n",
      "Epoch: 471, Batch: 40, Training Loss: 0.5450708866119385\n",
      "Epoch: 471, Batch: 80, Training Loss: 0.5780763030052185\n",
      "Epoch: 471, Validation Loss: 1.239059329032898\n",
      "Epoch: 472, Batch: 40, Training Loss: 0.541388750076294\n",
      "Epoch: 472, Batch: 80, Training Loss: 0.5470878481864929\n",
      "Epoch: 472, Validation Loss: 1.1849526166915894\n",
      "Epoch: 473, Batch: 40, Training Loss: 0.6115278005599976\n",
      "Epoch: 473, Batch: 80, Training Loss: 0.5537151098251343\n",
      "Epoch: 473, Validation Loss: 1.1731170415878296\n",
      "Epoch: 474, Batch: 40, Training Loss: 0.6323708295822144\n",
      "Epoch: 474, Batch: 80, Training Loss: 0.606484591960907\n",
      "Epoch: 474, Validation Loss: 1.1804749965667725\n",
      "Epoch: 475, Batch: 40, Training Loss: 0.6351608633995056\n",
      "Epoch: 475, Batch: 80, Training Loss: 0.6156964302062988\n",
      "Epoch: 475, Validation Loss: 1.206380009651184\n",
      "Epoch: 476, Batch: 40, Training Loss: 0.5630784034729004\n",
      "Epoch: 476, Batch: 80, Training Loss: 0.5656703114509583\n",
      "Epoch: 476, Validation Loss: 1.0862723588943481\n",
      "Epoch: 477, Batch: 40, Training Loss: 0.6215886473655701\n",
      "Epoch: 477, Batch: 80, Training Loss: 0.5941296219825745\n",
      "Epoch: 477, Validation Loss: 1.1429932117462158\n",
      "Epoch: 478, Batch: 40, Training Loss: 0.5449417233467102\n",
      "Epoch: 478, Batch: 80, Training Loss: 0.5628073215484619\n",
      "Epoch: 478, Validation Loss: 1.2894493341445923\n",
      "Epoch: 479, Batch: 40, Training Loss: 0.5313566327095032\n",
      "Epoch: 479, Batch: 80, Training Loss: 0.6070722341537476\n",
      "Epoch: 479, Validation Loss: 1.2300158739089966\n",
      "Epoch: 480, Batch: 40, Training Loss: 0.5483361482620239\n",
      "Epoch: 480, Batch: 80, Training Loss: 0.555227518081665\n",
      "Epoch: 480, Validation Loss: 1.1941345930099487\n",
      "Epoch: 481, Batch: 40, Training Loss: 0.5268722176551819\n",
      "Epoch: 481, Batch: 80, Training Loss: 0.5749166011810303\n",
      "Epoch: 481, Validation Loss: 1.115952730178833\n",
      "Epoch: 482, Batch: 40, Training Loss: 0.6285375356674194\n",
      "Epoch: 482, Batch: 80, Training Loss: 0.6199215650558472\n",
      "Epoch: 482, Validation Loss: 1.2614445686340332\n",
      "Epoch: 483, Batch: 40, Training Loss: 0.6008108258247375\n",
      "Epoch: 483, Batch: 80, Training Loss: 0.5523281693458557\n",
      "Epoch: 483, Validation Loss: 1.2596930265426636\n",
      "Epoch: 484, Batch: 40, Training Loss: 0.5024266839027405\n",
      "Epoch: 484, Batch: 80, Training Loss: 0.6119444370269775\n",
      "Epoch: 484, Validation Loss: 1.2265894412994385\n",
      "Epoch: 485, Batch: 40, Training Loss: 0.599718451499939\n",
      "Epoch: 485, Batch: 80, Training Loss: 0.49391406774520874\n",
      "Epoch: 485, Validation Loss: 1.265832543373108\n",
      "Epoch: 486, Batch: 40, Training Loss: 0.5901077389717102\n",
      "Epoch: 486, Batch: 80, Training Loss: 0.527599036693573\n",
      "Epoch: 486, Validation Loss: 1.2146174907684326\n",
      "Epoch: 487, Batch: 40, Training Loss: 0.5027860403060913\n",
      "Epoch: 487, Batch: 80, Training Loss: 0.5769700407981873\n",
      "Epoch: 487, Validation Loss: 1.1659650802612305\n",
      "Epoch: 488, Batch: 40, Training Loss: 0.5428152680397034\n",
      "Epoch: 488, Batch: 80, Training Loss: 0.5648415088653564\n",
      "Epoch: 488, Validation Loss: 1.1998151540756226\n",
      "Epoch: 489, Batch: 40, Training Loss: 0.5588071942329407\n",
      "Epoch: 489, Batch: 80, Training Loss: 0.5927852988243103\n",
      "Epoch: 489, Validation Loss: 1.193833351135254\n",
      "Epoch: 490, Batch: 40, Training Loss: 0.5447168350219727\n",
      "Epoch: 490, Batch: 80, Training Loss: 0.549468994140625\n",
      "Epoch: 490, Validation Loss: 1.0984749794006348\n",
      "Epoch: 491, Batch: 40, Training Loss: 0.574643075466156\n",
      "Epoch: 491, Batch: 80, Training Loss: 0.5286093950271606\n",
      "Epoch: 491, Validation Loss: 1.0735430717468262\n",
      "Epoch: 492, Batch: 40, Training Loss: 0.5579835176467896\n",
      "Epoch: 492, Batch: 80, Training Loss: 0.5845592617988586\n",
      "Epoch: 492, Validation Loss: 1.1593027114868164\n",
      "Epoch: 493, Batch: 40, Training Loss: 0.5795673131942749\n",
      "Epoch: 493, Batch: 80, Training Loss: 0.654763400554657\n",
      "Epoch: 493, Validation Loss: 1.0423527956008911\n",
      "Epoch: 494, Batch: 40, Training Loss: 0.5577757954597473\n",
      "Epoch: 494, Batch: 80, Training Loss: 0.5678854584693909\n",
      "Epoch: 494, Validation Loss: 1.1526700258255005\n",
      "Epoch: 495, Batch: 40, Training Loss: 0.5302714705467224\n",
      "Epoch: 495, Batch: 80, Training Loss: 0.5149072408676147\n",
      "Epoch: 495, Validation Loss: 1.266099214553833\n",
      "Epoch: 496, Batch: 40, Training Loss: 0.5918421745300293\n",
      "Epoch: 496, Batch: 80, Training Loss: 0.5130906105041504\n",
      "Epoch: 496, Validation Loss: 1.1305766105651855\n",
      "Epoch: 497, Batch: 40, Training Loss: 0.5650836825370789\n",
      "Epoch: 497, Batch: 80, Training Loss: 0.557253897190094\n",
      "Epoch: 497, Validation Loss: 1.0602467060089111\n",
      "Epoch: 498, Batch: 40, Training Loss: 0.6474937200546265\n",
      "Epoch: 498, Batch: 80, Training Loss: 0.6206095814704895\n",
      "Epoch: 498, Validation Loss: 1.3185734748840332\n",
      "Epoch: 499, Batch: 40, Training Loss: 0.5397917032241821\n",
      "Epoch: 499, Batch: 80, Training Loss: 0.5670391917228699\n",
      "Epoch: 499, Validation Loss: 1.1265932321548462\n",
      "Epoch: 500, Batch: 40, Training Loss: 0.5810250639915466\n",
      "Epoch: 500, Batch: 80, Training Loss: 0.5017479062080383\n",
      "Epoch: 500, Validation Loss: 1.2947907447814941\n",
      "Epoch: 501, Batch: 40, Training Loss: 0.6736418604850769\n",
      "Epoch: 501, Batch: 80, Training Loss: 0.5034355521202087\n",
      "Epoch: 501, Validation Loss: 1.360659122467041\n",
      "Epoch: 502, Batch: 40, Training Loss: 0.5412776470184326\n",
      "Epoch: 502, Batch: 80, Training Loss: 0.5546472668647766\n",
      "Epoch: 502, Validation Loss: 1.2408850193023682\n",
      "Epoch: 503, Batch: 40, Training Loss: 0.5289314985275269\n",
      "Epoch: 503, Batch: 80, Training Loss: 0.6089831590652466\n",
      "Epoch: 503, Validation Loss: 1.0020465850830078\n",
      "Epoch: 504, Batch: 40, Training Loss: 0.5849816799163818\n",
      "Epoch: 504, Batch: 80, Training Loss: 0.5845518112182617\n",
      "Epoch: 504, Validation Loss: 1.1241542100906372\n",
      "Epoch: 505, Batch: 40, Training Loss: 0.6176370978355408\n",
      "Epoch: 505, Batch: 80, Training Loss: 0.6063122153282166\n",
      "Epoch: 505, Validation Loss: 1.0678280591964722\n",
      "Epoch: 506, Batch: 40, Training Loss: 0.544488787651062\n",
      "Epoch: 506, Batch: 80, Training Loss: 0.6478708386421204\n",
      "Epoch: 506, Validation Loss: 1.2491304874420166\n",
      "Epoch: 507, Batch: 40, Training Loss: 0.5087934136390686\n",
      "Epoch: 507, Batch: 80, Training Loss: 0.5110074877738953\n",
      "Epoch: 507, Validation Loss: 1.2580516338348389\n",
      "Epoch: 508, Batch: 40, Training Loss: 0.47320353984832764\n",
      "Epoch: 508, Batch: 80, Training Loss: 0.5890243649482727\n",
      "Epoch: 508, Validation Loss: 1.1202753782272339\n",
      "Epoch: 509, Batch: 40, Training Loss: 0.576978325843811\n",
      "Epoch: 509, Batch: 80, Training Loss: 0.5508822798728943\n",
      "Epoch: 509, Validation Loss: 1.2218282222747803\n",
      "Epoch: 510, Batch: 40, Training Loss: 0.5883257985115051\n",
      "Epoch: 510, Batch: 80, Training Loss: 0.5397452116012573\n",
      "Epoch: 510, Validation Loss: 1.0364881753921509\n",
      "Epoch: 511, Batch: 40, Training Loss: 0.5356993675231934\n",
      "Epoch: 511, Batch: 80, Training Loss: 0.5488138794898987\n",
      "Epoch: 511, Validation Loss: 1.075998067855835\n",
      "Epoch: 512, Batch: 40, Training Loss: 0.5444456934928894\n",
      "Epoch: 512, Batch: 80, Training Loss: 0.5164714455604553\n",
      "Epoch: 512, Validation Loss: 1.2510409355163574\n",
      "Epoch: 513, Batch: 40, Training Loss: 0.5145367383956909\n",
      "Epoch: 513, Batch: 80, Training Loss: 0.5749605894088745\n",
      "Epoch: 513, Validation Loss: 1.1499953269958496\n",
      "Epoch: 514, Batch: 40, Training Loss: 0.5455881357192993\n",
      "Epoch: 514, Batch: 80, Training Loss: 0.5929207801818848\n",
      "Epoch: 514, Validation Loss: 1.2735278606414795\n",
      "Epoch: 515, Batch: 40, Training Loss: 0.5092315673828125\n",
      "Epoch: 515, Batch: 80, Training Loss: 0.616233766078949\n",
      "Epoch: 515, Validation Loss: 1.1118372678756714\n",
      "Epoch: 516, Batch: 40, Training Loss: 0.5137873291969299\n",
      "Epoch: 516, Batch: 80, Training Loss: 0.49696531891822815\n",
      "Epoch: 516, Validation Loss: 1.009614109992981\n",
      "Epoch: 517, Batch: 40, Training Loss: 0.5317250490188599\n",
      "Epoch: 517, Batch: 80, Training Loss: 0.5630165934562683\n",
      "Epoch: 517, Validation Loss: 1.143214225769043\n",
      "Epoch: 518, Batch: 40, Training Loss: 0.4447079598903656\n",
      "Epoch: 518, Batch: 80, Training Loss: 0.5814157128334045\n",
      "Epoch: 518, Validation Loss: 1.060814619064331\n",
      "Epoch: 519, Batch: 40, Training Loss: 0.5668453574180603\n",
      "Epoch: 519, Batch: 80, Training Loss: 0.5405356884002686\n",
      "Epoch: 519, Validation Loss: 1.1305376291275024\n",
      "Epoch: 520, Batch: 40, Training Loss: 0.48903796076774597\n",
      "Epoch: 520, Batch: 80, Training Loss: 0.5484415888786316\n",
      "Epoch: 520, Validation Loss: 1.12096107006073\n",
      "Epoch: 521, Batch: 40, Training Loss: 0.597235918045044\n",
      "Epoch: 521, Batch: 80, Training Loss: 0.4581771194934845\n",
      "Epoch: 521, Validation Loss: 1.1926121711730957\n",
      "Epoch: 522, Batch: 40, Training Loss: 0.5558919906616211\n",
      "Epoch: 522, Batch: 80, Training Loss: 0.5450785160064697\n",
      "Epoch: 522, Validation Loss: 1.2004680633544922\n",
      "Epoch: 523, Batch: 40, Training Loss: 0.4906642436981201\n",
      "Epoch: 523, Batch: 80, Training Loss: 0.5575937032699585\n",
      "Epoch: 523, Validation Loss: 1.2493011951446533\n",
      "Epoch: 524, Batch: 40, Training Loss: 0.49634304642677307\n",
      "Epoch: 524, Batch: 80, Training Loss: 0.614662766456604\n",
      "Epoch: 524, Validation Loss: 1.0955203771591187\n",
      "Epoch: 525, Batch: 40, Training Loss: 0.49341949820518494\n",
      "Epoch: 525, Batch: 80, Training Loss: 0.5454309582710266\n",
      "Epoch: 525, Validation Loss: 1.239343285560608\n",
      "Epoch: 526, Batch: 40, Training Loss: 0.595370352268219\n",
      "Epoch: 526, Batch: 80, Training Loss: 0.5461776256561279\n",
      "Epoch: 526, Validation Loss: 1.0916154384613037\n",
      "Epoch: 527, Batch: 40, Training Loss: 0.4843319058418274\n",
      "Epoch: 527, Batch: 80, Training Loss: 0.5699179768562317\n",
      "Epoch: 527, Validation Loss: 1.357263445854187\n",
      "Epoch: 528, Batch: 40, Training Loss: 0.5611520409584045\n",
      "Epoch: 528, Batch: 80, Training Loss: 0.5150771141052246\n",
      "Epoch: 528, Validation Loss: 1.2335845232009888\n",
      "Epoch: 529, Batch: 40, Training Loss: 0.4891234040260315\n",
      "Epoch: 529, Batch: 80, Training Loss: 0.5718401670455933\n",
      "Epoch: 529, Validation Loss: 1.0528595447540283\n",
      "Epoch: 530, Batch: 40, Training Loss: 0.5451563000679016\n",
      "Epoch: 530, Batch: 80, Training Loss: 0.582871675491333\n",
      "Epoch: 530, Validation Loss: 1.265047550201416\n",
      "Epoch: 531, Batch: 40, Training Loss: 0.48703569173812866\n",
      "Epoch: 531, Batch: 80, Training Loss: 0.5913697481155396\n",
      "Epoch: 531, Validation Loss: 1.2276856899261475\n",
      "Epoch: 532, Batch: 40, Training Loss: 0.5111439228057861\n",
      "Epoch: 532, Batch: 80, Training Loss: 0.4764065742492676\n",
      "Epoch: 532, Validation Loss: 1.0921344757080078\n",
      "Epoch: 533, Batch: 40, Training Loss: 0.6667371988296509\n",
      "Epoch: 533, Batch: 80, Training Loss: 0.6032996773719788\n",
      "Epoch: 533, Validation Loss: 1.1050903797149658\n",
      "Epoch: 534, Batch: 40, Training Loss: 0.5334707498550415\n",
      "Epoch: 534, Batch: 80, Training Loss: 0.5653032064437866\n",
      "Epoch: 534, Validation Loss: 1.0443625450134277\n",
      "Epoch: 535, Batch: 40, Training Loss: 0.5254644155502319\n",
      "Epoch: 535, Batch: 80, Training Loss: 0.5633876919746399\n",
      "Epoch: 535, Validation Loss: 1.24626886844635\n",
      "Epoch: 536, Batch: 40, Training Loss: 0.5128732323646545\n",
      "Epoch: 536, Batch: 80, Training Loss: 0.5004366040229797\n",
      "Epoch: 536, Validation Loss: 1.2481019496917725\n",
      "Epoch: 537, Batch: 40, Training Loss: 0.5619104504585266\n",
      "Epoch: 537, Batch: 80, Training Loss: 0.5816418528556824\n",
      "Epoch: 537, Validation Loss: 1.1739619970321655\n",
      "Epoch: 538, Batch: 40, Training Loss: 0.559062659740448\n",
      "Epoch: 538, Batch: 80, Training Loss: 0.5779096484184265\n",
      "Epoch: 538, Validation Loss: 1.1341897249221802\n",
      "Epoch: 539, Batch: 40, Training Loss: 0.47036248445510864\n",
      "Epoch: 539, Batch: 80, Training Loss: 0.5102828145027161\n",
      "Epoch: 539, Validation Loss: 1.1050703525543213\n",
      "Epoch: 540, Batch: 40, Training Loss: 0.590053379535675\n",
      "Epoch: 540, Batch: 80, Training Loss: 0.6797974705696106\n",
      "Epoch: 540, Validation Loss: 1.1802507638931274\n",
      "Epoch: 541, Batch: 40, Training Loss: 0.5299329161643982\n",
      "Epoch: 541, Batch: 80, Training Loss: 0.5509305596351624\n",
      "Epoch: 541, Validation Loss: 1.1722970008850098\n",
      "Epoch: 542, Batch: 40, Training Loss: 0.5033663511276245\n",
      "Epoch: 542, Batch: 80, Training Loss: 0.5493210554122925\n",
      "Epoch: 542, Validation Loss: 1.3267408609390259\n",
      "Epoch: 543, Batch: 40, Training Loss: 0.5338011384010315\n",
      "Epoch: 543, Batch: 80, Training Loss: 0.6029534339904785\n",
      "Epoch: 543, Validation Loss: 1.148764729499817\n",
      "Epoch: 544, Batch: 40, Training Loss: 0.6426854133605957\n",
      "Epoch: 544, Batch: 80, Training Loss: 0.568998396396637\n",
      "Epoch: 544, Validation Loss: 1.1193315982818604\n",
      "Epoch: 545, Batch: 40, Training Loss: 0.5891671180725098\n",
      "Epoch: 545, Batch: 80, Training Loss: 0.5556017160415649\n",
      "Epoch: 545, Validation Loss: 1.2442930936813354\n",
      "Epoch: 546, Batch: 40, Training Loss: 0.5716235637664795\n",
      "Epoch: 546, Batch: 80, Training Loss: 0.5177860260009766\n",
      "Epoch: 546, Validation Loss: 1.2500522136688232\n",
      "Epoch: 547, Batch: 40, Training Loss: 0.5437228679656982\n",
      "Epoch: 547, Batch: 80, Training Loss: 0.5489560961723328\n",
      "Epoch: 547, Validation Loss: 1.1914372444152832\n",
      "Epoch: 548, Batch: 40, Training Loss: 0.5677626729011536\n",
      "Epoch: 548, Batch: 80, Training Loss: 0.5396857857704163\n",
      "Epoch: 548, Validation Loss: 1.0803786516189575\n",
      "Epoch: 549, Batch: 40, Training Loss: 0.6060859560966492\n",
      "Epoch: 549, Batch: 80, Training Loss: 0.5574055314064026\n",
      "Epoch: 549, Validation Loss: 1.2332075834274292\n",
      "Epoch: 550, Batch: 40, Training Loss: 0.5729047656059265\n",
      "Epoch: 550, Batch: 80, Training Loss: 0.5589615106582642\n",
      "Epoch: 550, Validation Loss: 0.9919532537460327\n",
      "Epoch: 551, Batch: 40, Training Loss: 0.4848908483982086\n",
      "Epoch: 551, Batch: 80, Training Loss: 0.53009033203125\n",
      "Epoch: 551, Validation Loss: 1.1034860610961914\n",
      "Epoch: 552, Batch: 40, Training Loss: 0.5642164349555969\n",
      "Epoch: 552, Batch: 80, Training Loss: 0.5481740832328796\n",
      "Epoch: 552, Validation Loss: 1.0726171731948853\n",
      "Epoch: 553, Batch: 40, Training Loss: 0.5750647187232971\n",
      "Epoch: 553, Batch: 80, Training Loss: 0.4925352931022644\n",
      "Epoch: 553, Validation Loss: 1.023059368133545\n",
      "Epoch: 554, Batch: 40, Training Loss: 0.5479635000228882\n",
      "Epoch: 554, Batch: 80, Training Loss: 0.5972749590873718\n",
      "Epoch: 554, Validation Loss: 1.3107903003692627\n",
      "Epoch: 555, Batch: 40, Training Loss: 0.49108102917671204\n",
      "Epoch: 555, Batch: 80, Training Loss: 0.5431950688362122\n",
      "Epoch: 555, Validation Loss: 1.086103916168213\n",
      "Epoch: 556, Batch: 40, Training Loss: 0.5642842650413513\n",
      "Epoch: 556, Batch: 80, Training Loss: 0.530754566192627\n",
      "Epoch: 556, Validation Loss: 1.1078457832336426\n",
      "Epoch: 557, Batch: 40, Training Loss: 0.5406839847564697\n",
      "Epoch: 557, Batch: 80, Training Loss: 0.5508952736854553\n",
      "Epoch: 557, Validation Loss: 1.1528370380401611\n",
      "Epoch: 558, Batch: 40, Training Loss: 0.6096674203872681\n",
      "Epoch: 558, Batch: 80, Training Loss: 0.6052111387252808\n",
      "Epoch: 558, Validation Loss: 1.2218315601348877\n",
      "Epoch: 559, Batch: 40, Training Loss: 0.5563441514968872\n",
      "Epoch: 559, Batch: 80, Training Loss: 0.5373812913894653\n",
      "Epoch: 559, Validation Loss: 1.218461513519287\n",
      "Epoch: 560, Batch: 40, Training Loss: 0.6069324016571045\n",
      "Epoch: 560, Batch: 80, Training Loss: 0.5281962752342224\n",
      "Epoch: 560, Validation Loss: 1.2351301908493042\n",
      "Epoch: 561, Batch: 40, Training Loss: 0.48383504152297974\n",
      "Epoch: 561, Batch: 80, Training Loss: 0.6273454427719116\n",
      "Epoch: 561, Validation Loss: 1.1430248022079468\n",
      "Epoch: 562, Batch: 40, Training Loss: 0.5334417819976807\n",
      "Epoch: 562, Batch: 80, Training Loss: 0.5875979065895081\n",
      "Epoch: 562, Validation Loss: 1.0824263095855713\n",
      "Epoch: 563, Batch: 40, Training Loss: 0.49445807933807373\n",
      "Epoch: 563, Batch: 80, Training Loss: 0.5644751787185669\n",
      "Epoch: 563, Validation Loss: 1.1394896507263184\n",
      "Epoch: 564, Batch: 40, Training Loss: 0.5715486407279968\n",
      "Epoch: 564, Batch: 80, Training Loss: 0.5971736311912537\n",
      "Epoch: 564, Validation Loss: 1.0869495868682861\n",
      "Epoch: 565, Batch: 40, Training Loss: 0.5639328360557556\n",
      "Epoch: 565, Batch: 80, Training Loss: 0.5983461737632751\n",
      "Epoch: 565, Validation Loss: 1.2256889343261719\n",
      "Epoch: 566, Batch: 40, Training Loss: 0.4708457589149475\n",
      "Epoch: 566, Batch: 80, Training Loss: 0.6133503317832947\n",
      "Epoch: 566, Validation Loss: 1.1606839895248413\n",
      "Epoch: 567, Batch: 40, Training Loss: 0.5850803852081299\n",
      "Epoch: 567, Batch: 80, Training Loss: 0.5279281139373779\n",
      "Epoch: 567, Validation Loss: 1.1400939226150513\n",
      "Epoch: 568, Batch: 40, Training Loss: 0.5630171298980713\n",
      "Epoch: 568, Batch: 80, Training Loss: 0.604274570941925\n",
      "Epoch: 568, Validation Loss: 1.1541389226913452\n",
      "Epoch: 569, Batch: 40, Training Loss: 0.497152715921402\n",
      "Epoch: 569, Batch: 80, Training Loss: 0.5896763205528259\n",
      "Epoch: 569, Validation Loss: 1.1948304176330566\n",
      "Epoch: 570, Batch: 40, Training Loss: 0.4426049590110779\n",
      "Epoch: 570, Batch: 80, Training Loss: 0.5590074062347412\n",
      "Epoch: 570, Validation Loss: 1.1234123706817627\n",
      "Epoch: 571, Batch: 40, Training Loss: 0.5964226722717285\n",
      "Epoch: 571, Batch: 80, Training Loss: 0.574664831161499\n",
      "Epoch: 571, Validation Loss: 1.1726288795471191\n",
      "Epoch: 572, Batch: 40, Training Loss: 0.5627722144126892\n",
      "Epoch: 572, Batch: 80, Training Loss: 0.5910120606422424\n",
      "Epoch: 572, Validation Loss: 1.1036310195922852\n",
      "Epoch: 573, Batch: 40, Training Loss: 0.5302011370658875\n",
      "Epoch: 573, Batch: 80, Training Loss: 0.47847914695739746\n",
      "Epoch: 573, Validation Loss: 1.0783865451812744\n",
      "Epoch: 574, Batch: 40, Training Loss: 0.5456356406211853\n",
      "Epoch: 574, Batch: 80, Training Loss: 0.4907549023628235\n",
      "Epoch: 574, Validation Loss: 1.273470401763916\n",
      "Epoch: 575, Batch: 40, Training Loss: 0.5778721570968628\n",
      "Epoch: 575, Batch: 80, Training Loss: 0.5783463716506958\n",
      "Epoch: 575, Validation Loss: 1.1023207902908325\n",
      "Epoch: 576, Batch: 40, Training Loss: 0.6173824071884155\n",
      "Epoch: 576, Batch: 80, Training Loss: 0.577771782875061\n",
      "Epoch: 576, Validation Loss: 1.2381953001022339\n",
      "Epoch: 577, Batch: 40, Training Loss: 0.5224696397781372\n",
      "Epoch: 577, Batch: 80, Training Loss: 0.548659086227417\n",
      "Epoch: 577, Validation Loss: 1.318493366241455\n",
      "Epoch: 578, Batch: 40, Training Loss: 0.5358536243438721\n",
      "Epoch: 578, Batch: 80, Training Loss: 0.5543791055679321\n",
      "Epoch: 578, Validation Loss: 1.2578126192092896\n",
      "Epoch: 579, Batch: 40, Training Loss: 0.5689393281936646\n",
      "Epoch: 579, Batch: 80, Training Loss: 0.5458031892776489\n",
      "Epoch: 579, Validation Loss: 1.1689718961715698\n",
      "Epoch: 580, Batch: 40, Training Loss: 0.5546749234199524\n",
      "Epoch: 580, Batch: 80, Training Loss: 0.5269918441772461\n",
      "Epoch: 580, Validation Loss: 1.246138334274292\n",
      "Epoch: 581, Batch: 40, Training Loss: 0.46314722299575806\n",
      "Epoch: 581, Batch: 80, Training Loss: 0.5544837713241577\n",
      "Epoch: 581, Validation Loss: 1.2096184492111206\n",
      "Epoch: 582, Batch: 40, Training Loss: 0.5378187298774719\n",
      "Epoch: 582, Batch: 80, Training Loss: 0.5878205299377441\n",
      "Epoch: 582, Validation Loss: 1.1544280052185059\n",
      "Epoch: 583, Batch: 40, Training Loss: 0.5679605007171631\n",
      "Epoch: 583, Batch: 80, Training Loss: 0.5309373736381531\n",
      "Epoch: 583, Validation Loss: 1.099526286125183\n",
      "Epoch: 584, Batch: 40, Training Loss: 0.4926953911781311\n",
      "Epoch: 584, Batch: 80, Training Loss: 0.5487288236618042\n",
      "Epoch: 584, Validation Loss: 1.1765378713607788\n",
      "Epoch: 585, Batch: 40, Training Loss: 0.5669058561325073\n",
      "Epoch: 585, Batch: 80, Training Loss: 0.5596176981925964\n",
      "Epoch: 585, Validation Loss: 1.3062037229537964\n",
      "Epoch: 586, Batch: 40, Training Loss: 0.5634368658065796\n",
      "Epoch: 586, Batch: 80, Training Loss: 0.5395467281341553\n",
      "Epoch: 586, Validation Loss: 1.211333155632019\n",
      "Epoch: 587, Batch: 40, Training Loss: 0.5781652927398682\n",
      "Epoch: 587, Batch: 80, Training Loss: 0.5152201652526855\n",
      "Epoch: 587, Validation Loss: 1.234893560409546\n",
      "Epoch: 588, Batch: 40, Training Loss: 0.5630288124084473\n",
      "Epoch: 588, Batch: 80, Training Loss: 0.5243614912033081\n",
      "Epoch: 588, Validation Loss: 1.0924832820892334\n",
      "Epoch: 589, Batch: 40, Training Loss: 0.5076704025268555\n",
      "Epoch: 589, Batch: 80, Training Loss: 0.5830940008163452\n",
      "Epoch: 589, Validation Loss: 1.1192013025283813\n",
      "Epoch: 590, Batch: 40, Training Loss: 0.6086450219154358\n",
      "Epoch: 590, Batch: 80, Training Loss: 0.5717810988426208\n",
      "Epoch: 590, Validation Loss: 1.100615382194519\n",
      "Epoch: 591, Batch: 40, Training Loss: 0.6063538789749146\n",
      "Epoch: 591, Batch: 80, Training Loss: 0.5848008394241333\n",
      "Epoch: 591, Validation Loss: 1.2232112884521484\n",
      "Epoch: 592, Batch: 40, Training Loss: 0.5244935750961304\n",
      "Epoch: 592, Batch: 80, Training Loss: 0.566767692565918\n",
      "Epoch: 592, Validation Loss: 1.302116870880127\n",
      "Epoch: 593, Batch: 40, Training Loss: 0.5035703778266907\n",
      "Epoch: 593, Batch: 80, Training Loss: 0.5012144446372986\n",
      "Epoch: 593, Validation Loss: 1.1085110902786255\n",
      "Epoch: 594, Batch: 40, Training Loss: 0.48932206630706787\n",
      "Epoch: 594, Batch: 80, Training Loss: 0.504201352596283\n",
      "Epoch: 594, Validation Loss: 1.2866398096084595\n",
      "Epoch: 595, Batch: 40, Training Loss: 0.5773268938064575\n",
      "Epoch: 595, Batch: 80, Training Loss: 0.5510041117668152\n",
      "Epoch: 595, Validation Loss: 1.3708243370056152\n",
      "Epoch: 596, Batch: 40, Training Loss: 0.5063433051109314\n",
      "Epoch: 596, Batch: 80, Training Loss: 0.49003443121910095\n",
      "Epoch: 596, Validation Loss: 1.1473972797393799\n",
      "Epoch: 597, Batch: 40, Training Loss: 0.5311477780342102\n",
      "Epoch: 597, Batch: 80, Training Loss: 0.6819890737533569\n",
      "Epoch: 597, Validation Loss: 1.0815794467926025\n",
      "Epoch: 598, Batch: 40, Training Loss: 0.5191192030906677\n",
      "Epoch: 598, Batch: 80, Training Loss: 0.5225449204444885\n",
      "Epoch: 598, Validation Loss: 1.1251314878463745\n",
      "Epoch: 599, Batch: 40, Training Loss: 0.49702349305152893\n",
      "Epoch: 599, Batch: 80, Training Loss: 0.5255092978477478\n",
      "Epoch: 599, Validation Loss: 1.1273881196975708\n",
      "Epoch: 600, Batch: 40, Training Loss: 0.5920705199241638\n",
      "Epoch: 600, Batch: 80, Training Loss: 0.47997578978538513\n",
      "Epoch: 600, Validation Loss: 1.42232084274292\n",
      "Epoch: 601, Batch: 40, Training Loss: 0.5085710883140564\n",
      "Epoch: 601, Batch: 80, Training Loss: 0.6121504306793213\n",
      "Epoch: 601, Validation Loss: 1.2257845401763916\n",
      "Epoch: 602, Batch: 40, Training Loss: 0.5766803026199341\n",
      "Epoch: 602, Batch: 80, Training Loss: 0.5225823521614075\n",
      "Epoch: 602, Validation Loss: 1.2271283864974976\n",
      "Epoch: 603, Batch: 40, Training Loss: 0.5098831653594971\n",
      "Epoch: 603, Batch: 80, Training Loss: 0.49796822667121887\n",
      "Epoch: 603, Validation Loss: 1.2796998023986816\n",
      "Epoch: 604, Batch: 40, Training Loss: 0.5247933268547058\n",
      "Epoch: 604, Batch: 80, Training Loss: 0.5704532265663147\n",
      "Epoch: 604, Validation Loss: 1.1636420488357544\n",
      "Epoch: 605, Batch: 40, Training Loss: 0.5351691842079163\n",
      "Epoch: 605, Batch: 80, Training Loss: 0.5243548154830933\n",
      "Epoch: 605, Validation Loss: 1.2273997068405151\n",
      "Epoch: 606, Batch: 40, Training Loss: 0.5388259887695312\n",
      "Epoch: 606, Batch: 80, Training Loss: 0.5294506549835205\n",
      "Epoch: 606, Validation Loss: 1.1949979066848755\n",
      "Epoch: 607, Batch: 40, Training Loss: 0.5401082038879395\n",
      "Epoch: 607, Batch: 80, Training Loss: 0.5110594630241394\n",
      "Epoch: 607, Validation Loss: 1.1018115282058716\n",
      "Epoch: 608, Batch: 40, Training Loss: 0.5063794851303101\n",
      "Epoch: 608, Batch: 80, Training Loss: 0.6101568341255188\n",
      "Epoch: 608, Validation Loss: 1.1911085844039917\n",
      "Epoch: 609, Batch: 40, Training Loss: 0.5368596911430359\n",
      "Epoch: 609, Batch: 80, Training Loss: 0.5621761083602905\n",
      "Epoch: 609, Validation Loss: 1.2130647897720337\n",
      "Epoch: 610, Batch: 40, Training Loss: 0.5727391242980957\n",
      "Epoch: 610, Batch: 80, Training Loss: 0.483581006526947\n",
      "Epoch: 610, Validation Loss: 1.1125370264053345\n",
      "Epoch: 611, Batch: 40, Training Loss: 0.5320075750350952\n",
      "Epoch: 611, Batch: 80, Training Loss: 0.5833600759506226\n",
      "Epoch: 611, Validation Loss: 1.256994605064392\n",
      "Epoch: 612, Batch: 40, Training Loss: 0.4938737750053406\n",
      "Epoch: 612, Batch: 80, Training Loss: 0.5751829743385315\n",
      "Epoch: 612, Validation Loss: 1.256896734237671\n",
      "Epoch: 613, Batch: 40, Training Loss: 0.5214765071868896\n",
      "Epoch: 613, Batch: 80, Training Loss: 0.5423734784126282\n",
      "Epoch: 613, Validation Loss: 1.0924862623214722\n",
      "Epoch: 614, Batch: 40, Training Loss: 0.537179172039032\n",
      "Epoch: 614, Batch: 80, Training Loss: 0.5894760489463806\n",
      "Epoch: 614, Validation Loss: 1.0228092670440674\n",
      "Epoch: 615, Batch: 40, Training Loss: 0.5356124043464661\n",
      "Epoch: 615, Batch: 80, Training Loss: 0.5635679364204407\n",
      "Epoch: 615, Validation Loss: 1.2570725679397583\n",
      "Epoch: 616, Batch: 40, Training Loss: 0.46581801772117615\n",
      "Epoch: 616, Batch: 80, Training Loss: 0.5813519358634949\n",
      "Epoch: 616, Validation Loss: 1.2263882160186768\n",
      "Epoch: 617, Batch: 40, Training Loss: 0.5182584524154663\n",
      "Epoch: 617, Batch: 80, Training Loss: 0.5236274003982544\n",
      "Epoch: 617, Validation Loss: 1.213756799697876\n",
      "Epoch: 618, Batch: 40, Training Loss: 0.5155473351478577\n",
      "Epoch: 618, Batch: 80, Training Loss: 0.5292945504188538\n",
      "Epoch: 618, Validation Loss: 1.098382592201233\n",
      "Epoch: 619, Batch: 40, Training Loss: 0.5339060425758362\n",
      "Epoch: 619, Batch: 80, Training Loss: 0.5656894445419312\n",
      "Epoch: 619, Validation Loss: 1.21978759765625\n",
      "Epoch: 620, Batch: 40, Training Loss: 0.5340955853462219\n",
      "Epoch: 620, Batch: 80, Training Loss: 0.531324565410614\n",
      "Epoch: 620, Validation Loss: 1.263228416442871\n",
      "Epoch: 621, Batch: 40, Training Loss: 0.5287346243858337\n",
      "Epoch: 621, Batch: 80, Training Loss: 0.5025542974472046\n",
      "Epoch: 621, Validation Loss: 1.2984346151351929\n",
      "Epoch: 622, Batch: 40, Training Loss: 0.5585520267486572\n",
      "Epoch: 622, Batch: 80, Training Loss: 0.5377227067947388\n",
      "Epoch: 622, Validation Loss: 1.32952880859375\n",
      "Epoch: 623, Batch: 40, Training Loss: 0.5495748519897461\n",
      "Epoch: 623, Batch: 80, Training Loss: 0.5304762721061707\n",
      "Epoch: 623, Validation Loss: 1.2687079906463623\n",
      "Epoch: 624, Batch: 40, Training Loss: 0.511860728263855\n",
      "Epoch: 624, Batch: 80, Training Loss: 0.6520336270332336\n",
      "Epoch: 624, Validation Loss: 1.213302731513977\n",
      "Epoch: 625, Batch: 40, Training Loss: 0.5346251130104065\n",
      "Epoch: 625, Batch: 80, Training Loss: 0.5487497448921204\n",
      "Epoch: 625, Validation Loss: 1.2117784023284912\n",
      "Epoch: 626, Batch: 40, Training Loss: 0.5551537871360779\n",
      "Epoch: 626, Batch: 80, Training Loss: 0.525236189365387\n",
      "Epoch: 626, Validation Loss: 1.1847106218338013\n",
      "Epoch: 627, Batch: 40, Training Loss: 0.5540525913238525\n",
      "Epoch: 627, Batch: 80, Training Loss: 0.4677073359489441\n",
      "Epoch: 627, Validation Loss: 1.1080904006958008\n",
      "Epoch: 628, Batch: 40, Training Loss: 0.4848898649215698\n",
      "Epoch: 628, Batch: 80, Training Loss: 0.5160072445869446\n",
      "Epoch: 628, Validation Loss: 1.0678631067276\n",
      "Epoch: 629, Batch: 40, Training Loss: 0.4772161841392517\n",
      "Epoch: 629, Batch: 80, Training Loss: 0.49826037883758545\n",
      "Epoch: 629, Validation Loss: 1.1482844352722168\n",
      "Epoch: 630, Batch: 40, Training Loss: 0.5104652047157288\n",
      "Epoch: 630, Batch: 80, Training Loss: 0.48876550793647766\n",
      "Epoch: 630, Validation Loss: 1.2147181034088135\n",
      "Epoch: 631, Batch: 40, Training Loss: 0.5556123852729797\n",
      "Epoch: 631, Batch: 80, Training Loss: 0.5529522895812988\n",
      "Epoch: 631, Validation Loss: 1.0428043603897095\n",
      "Epoch: 632, Batch: 40, Training Loss: 0.4840637445449829\n",
      "Epoch: 632, Batch: 80, Training Loss: 0.5143385529518127\n",
      "Epoch: 632, Validation Loss: 1.3545081615447998\n",
      "Epoch: 633, Batch: 40, Training Loss: 0.5417499542236328\n",
      "Epoch: 633, Batch: 80, Training Loss: 0.5502857565879822\n",
      "Epoch: 633, Validation Loss: 1.2461824417114258\n",
      "Epoch: 634, Batch: 40, Training Loss: 0.513954222202301\n",
      "Epoch: 634, Batch: 80, Training Loss: 0.5243660807609558\n",
      "Epoch: 634, Validation Loss: 1.1286622285842896\n",
      "Epoch: 635, Batch: 40, Training Loss: 0.5604857802391052\n",
      "Epoch: 635, Batch: 80, Training Loss: 0.5365431904792786\n",
      "Epoch: 635, Validation Loss: 1.2986501455307007\n",
      "Epoch: 636, Batch: 40, Training Loss: 0.5770069360733032\n",
      "Epoch: 636, Batch: 80, Training Loss: 0.5880156755447388\n",
      "Epoch: 636, Validation Loss: 1.1786452531814575\n",
      "Epoch: 637, Batch: 40, Training Loss: 0.5132729411125183\n",
      "Epoch: 637, Batch: 80, Training Loss: 0.48165076971054077\n",
      "Epoch: 637, Validation Loss: 1.2236926555633545\n",
      "Epoch: 638, Batch: 40, Training Loss: 0.5333027839660645\n",
      "Epoch: 638, Batch: 80, Training Loss: 0.599901556968689\n",
      "Epoch: 638, Validation Loss: 1.1500571966171265\n",
      "Epoch: 639, Batch: 40, Training Loss: 0.5701467990875244\n",
      "Epoch: 639, Batch: 80, Training Loss: 0.4603724181652069\n",
      "Epoch: 639, Validation Loss: 1.1996982097625732\n",
      "Epoch: 640, Batch: 40, Training Loss: 0.43447205424308777\n",
      "Epoch: 640, Batch: 80, Training Loss: 0.545728325843811\n",
      "Epoch: 640, Validation Loss: 1.2497721910476685\n",
      "Epoch: 641, Batch: 40, Training Loss: 0.6139749884605408\n",
      "Epoch: 641, Batch: 80, Training Loss: 0.5017619729042053\n",
      "Epoch: 641, Validation Loss: 1.1595697402954102\n",
      "Epoch: 642, Batch: 40, Training Loss: 0.5929934978485107\n",
      "Epoch: 642, Batch: 80, Training Loss: 0.5389359593391418\n",
      "Epoch: 642, Validation Loss: 1.1998050212860107\n",
      "Epoch: 643, Batch: 40, Training Loss: 0.5235775113105774\n",
      "Epoch: 643, Batch: 80, Training Loss: 0.5453696846961975\n",
      "Epoch: 643, Validation Loss: 1.1439634561538696\n",
      "Epoch: 644, Batch: 40, Training Loss: 0.4945816695690155\n",
      "Epoch: 644, Batch: 80, Training Loss: 0.5859742760658264\n",
      "Epoch: 644, Validation Loss: 1.2325620651245117\n",
      "Epoch: 645, Batch: 40, Training Loss: 0.5640044212341309\n",
      "Epoch: 645, Batch: 80, Training Loss: 0.5072612166404724\n",
      "Epoch: 645, Validation Loss: 1.2337430715560913\n",
      "Epoch: 646, Batch: 40, Training Loss: 0.5308404564857483\n",
      "Epoch: 646, Batch: 80, Training Loss: 0.5625945329666138\n",
      "Epoch: 646, Validation Loss: 1.110746145248413\n",
      "Epoch: 647, Batch: 40, Training Loss: 0.6331409811973572\n",
      "Epoch: 647, Batch: 80, Training Loss: 0.5503478646278381\n",
      "Epoch: 647, Validation Loss: 1.2803082466125488\n",
      "Epoch: 648, Batch: 40, Training Loss: 0.5478684902191162\n",
      "Epoch: 648, Batch: 80, Training Loss: 0.6139536499977112\n",
      "Epoch: 648, Validation Loss: 1.1910369396209717\n",
      "Epoch: 649, Batch: 40, Training Loss: 0.47946009039878845\n",
      "Epoch: 649, Batch: 80, Training Loss: 0.5769131183624268\n",
      "Epoch: 649, Validation Loss: 1.3669544458389282\n",
      "Epoch: 650, Batch: 40, Training Loss: 0.4779791235923767\n",
      "Epoch: 650, Batch: 80, Training Loss: 0.6161817312240601\n",
      "Epoch: 650, Validation Loss: 1.1706963777542114\n",
      "Epoch: 651, Batch: 40, Training Loss: 0.5015934109687805\n",
      "Epoch: 651, Batch: 80, Training Loss: 0.5261479020118713\n",
      "Epoch: 651, Validation Loss: 1.3015179634094238\n",
      "Epoch: 652, Batch: 40, Training Loss: 0.5543985366821289\n",
      "Epoch: 652, Batch: 80, Training Loss: 0.5126445889472961\n",
      "Epoch: 652, Validation Loss: 1.2790533304214478\n",
      "Epoch: 653, Batch: 40, Training Loss: 0.5430210828781128\n",
      "Epoch: 653, Batch: 80, Training Loss: 0.510969340801239\n",
      "Epoch: 653, Validation Loss: 1.2317569255828857\n",
      "Epoch: 654, Batch: 40, Training Loss: 0.5535776615142822\n",
      "Epoch: 654, Batch: 80, Training Loss: 0.5894140601158142\n",
      "Epoch: 654, Validation Loss: 1.1320539712905884\n",
      "Epoch: 655, Batch: 40, Training Loss: 0.5128769874572754\n",
      "Epoch: 655, Batch: 80, Training Loss: 0.4595981538295746\n",
      "Epoch: 655, Validation Loss: 1.2363146543502808\n",
      "Epoch: 656, Batch: 40, Training Loss: 0.4974330961704254\n",
      "Epoch: 656, Batch: 80, Training Loss: 0.5712440609931946\n",
      "Epoch: 656, Validation Loss: 1.2267366647720337\n",
      "Epoch: 657, Batch: 40, Training Loss: 0.5553504228591919\n",
      "Epoch: 657, Batch: 80, Training Loss: 0.6070222854614258\n",
      "Epoch: 657, Validation Loss: 1.224741816520691\n",
      "Epoch: 658, Batch: 40, Training Loss: 0.5200624465942383\n",
      "Epoch: 658, Batch: 80, Training Loss: 0.5463851094245911\n",
      "Epoch: 658, Validation Loss: 1.3291733264923096\n",
      "Epoch: 659, Batch: 40, Training Loss: 0.486495703458786\n",
      "Epoch: 659, Batch: 80, Training Loss: 0.5938172340393066\n",
      "Epoch: 659, Validation Loss: 1.1735881567001343\n",
      "Epoch: 660, Batch: 40, Training Loss: 0.45855677127838135\n",
      "Epoch: 660, Batch: 80, Training Loss: 0.5691410303115845\n",
      "Epoch: 660, Validation Loss: 1.2291136980056763\n",
      "Epoch: 661, Batch: 40, Training Loss: 0.5544692873954773\n",
      "Epoch: 661, Batch: 80, Training Loss: 0.5417094230651855\n",
      "Epoch: 661, Validation Loss: 1.2169573307037354\n",
      "Epoch: 662, Batch: 40, Training Loss: 0.5176397562026978\n",
      "Epoch: 662, Batch: 80, Training Loss: 0.5173788070678711\n",
      "Epoch: 662, Validation Loss: 1.2428033351898193\n",
      "Epoch: 663, Batch: 40, Training Loss: 0.5348362326622009\n",
      "Epoch: 663, Batch: 80, Training Loss: 0.6039674282073975\n",
      "Epoch: 663, Validation Loss: 1.1792652606964111\n",
      "Epoch: 664, Batch: 40, Training Loss: 0.5810962915420532\n",
      "Epoch: 664, Batch: 80, Training Loss: 0.4696568250656128\n",
      "Epoch: 664, Validation Loss: 1.0186898708343506\n",
      "Epoch: 665, Batch: 40, Training Loss: 0.5197177529335022\n",
      "Epoch: 665, Batch: 80, Training Loss: 0.5405938625335693\n",
      "Epoch: 665, Validation Loss: 1.3004367351531982\n",
      "Epoch: 666, Batch: 40, Training Loss: 0.44106724858283997\n",
      "Epoch: 666, Batch: 80, Training Loss: 0.5168552398681641\n",
      "Epoch: 666, Validation Loss: 1.156886100769043\n",
      "Epoch: 667, Batch: 40, Training Loss: 0.5249267816543579\n",
      "Epoch: 667, Batch: 80, Training Loss: 0.47525206208229065\n",
      "Epoch: 667, Validation Loss: 1.1392133235931396\n",
      "Epoch: 668, Batch: 40, Training Loss: 0.4740586280822754\n",
      "Epoch: 668, Batch: 80, Training Loss: 0.5372707843780518\n",
      "Epoch: 668, Validation Loss: 1.2510123252868652\n",
      "Epoch: 669, Batch: 40, Training Loss: 0.5573690533638\n",
      "Epoch: 669, Batch: 80, Training Loss: 0.47735077142715454\n",
      "Epoch: 669, Validation Loss: 1.2947354316711426\n",
      "Epoch: 670, Batch: 40, Training Loss: 0.5272353291511536\n",
      "Epoch: 670, Batch: 80, Training Loss: 0.5625212788581848\n",
      "Epoch: 670, Validation Loss: 1.1856019496917725\n",
      "Epoch: 671, Batch: 40, Training Loss: 0.5698915719985962\n",
      "Epoch: 671, Batch: 80, Training Loss: 0.5321743488311768\n",
      "Epoch: 671, Validation Loss: 1.3491332530975342\n",
      "Epoch: 672, Batch: 40, Training Loss: 0.532151460647583\n",
      "Epoch: 672, Batch: 80, Training Loss: 0.5311604738235474\n",
      "Epoch: 672, Validation Loss: 1.1822513341903687\n",
      "Epoch: 673, Batch: 40, Training Loss: 0.5135629177093506\n",
      "Epoch: 673, Batch: 80, Training Loss: 0.6437445282936096\n",
      "Epoch: 673, Validation Loss: 1.155673623085022\n",
      "Epoch: 674, Batch: 40, Training Loss: 0.5411140322685242\n",
      "Epoch: 674, Batch: 80, Training Loss: 0.5312185287475586\n",
      "Epoch: 674, Validation Loss: 1.1187325716018677\n",
      "Epoch: 675, Batch: 40, Training Loss: 0.5014801621437073\n",
      "Epoch: 675, Batch: 80, Training Loss: 0.6055526733398438\n",
      "Epoch: 675, Validation Loss: 1.1815848350524902\n",
      "Epoch: 676, Batch: 40, Training Loss: 0.5535389184951782\n",
      "Epoch: 676, Batch: 80, Training Loss: 0.4624514579772949\n",
      "Epoch: 676, Validation Loss: 1.2074716091156006\n",
      "Epoch: 677, Batch: 40, Training Loss: 0.5107279419898987\n",
      "Epoch: 677, Batch: 80, Training Loss: 0.5751067996025085\n",
      "Epoch: 677, Validation Loss: 1.2254705429077148\n",
      "Epoch: 678, Batch: 40, Training Loss: 0.49652406573295593\n",
      "Epoch: 678, Batch: 80, Training Loss: 0.5930770635604858\n",
      "Epoch: 678, Validation Loss: 1.2859399318695068\n",
      "Epoch: 679, Batch: 40, Training Loss: 0.5551618933677673\n",
      "Epoch: 679, Batch: 80, Training Loss: 0.4635055363178253\n",
      "Epoch: 679, Validation Loss: 1.2856248617172241\n",
      "Epoch: 680, Batch: 40, Training Loss: 0.5727221965789795\n",
      "Epoch: 680, Batch: 80, Training Loss: 0.5200787782669067\n",
      "Epoch: 680, Validation Loss: 1.1988823413848877\n",
      "Epoch: 681, Batch: 40, Training Loss: 0.4548300802707672\n",
      "Epoch: 681, Batch: 80, Training Loss: 0.5268352031707764\n",
      "Epoch: 681, Validation Loss: 1.2341748476028442\n",
      "Epoch: 682, Batch: 40, Training Loss: 0.5220667123794556\n",
      "Epoch: 682, Batch: 80, Training Loss: 0.5362580418586731\n",
      "Epoch: 682, Validation Loss: 1.1751859188079834\n",
      "Epoch: 683, Batch: 40, Training Loss: 0.5265079140663147\n",
      "Epoch: 683, Batch: 80, Training Loss: 0.5290189385414124\n",
      "Epoch: 683, Validation Loss: 1.2884347438812256\n",
      "Epoch: 684, Batch: 40, Training Loss: 0.535624623298645\n",
      "Epoch: 684, Batch: 80, Training Loss: 0.5665915012359619\n",
      "Epoch: 684, Validation Loss: 1.2959283590316772\n",
      "Epoch: 685, Batch: 40, Training Loss: 0.5778005719184875\n",
      "Epoch: 685, Batch: 80, Training Loss: 0.48998159170150757\n",
      "Epoch: 685, Validation Loss: 1.2661808729171753\n",
      "Epoch: 686, Batch: 40, Training Loss: 0.5142456293106079\n",
      "Epoch: 686, Batch: 80, Training Loss: 0.5745041966438293\n",
      "Epoch: 686, Validation Loss: 1.2291679382324219\n",
      "Epoch: 687, Batch: 40, Training Loss: 0.48826834559440613\n",
      "Epoch: 687, Batch: 80, Training Loss: 0.5767408609390259\n",
      "Epoch: 687, Validation Loss: 1.3422942161560059\n",
      "Epoch: 688, Batch: 40, Training Loss: 0.5140640735626221\n",
      "Epoch: 688, Batch: 80, Training Loss: 0.5496551990509033\n",
      "Epoch: 688, Validation Loss: 1.2225357294082642\n",
      "Epoch: 689, Batch: 40, Training Loss: 0.5538983941078186\n",
      "Epoch: 689, Batch: 80, Training Loss: 0.5262181162834167\n",
      "Epoch: 689, Validation Loss: 1.2055784463882446\n",
      "Epoch: 690, Batch: 40, Training Loss: 0.4122125506401062\n",
      "Epoch: 690, Batch: 80, Training Loss: 0.5334194898605347\n",
      "Epoch: 690, Validation Loss: 1.38173508644104\n",
      "Epoch: 691, Batch: 40, Training Loss: 0.5248438715934753\n",
      "Epoch: 691, Batch: 80, Training Loss: 0.5388109087944031\n",
      "Epoch: 691, Validation Loss: 1.2563105821609497\n",
      "Epoch: 692, Batch: 40, Training Loss: 0.5209804177284241\n",
      "Epoch: 692, Batch: 80, Training Loss: 0.5325614213943481\n",
      "Epoch: 692, Validation Loss: 1.2346656322479248\n",
      "Epoch: 693, Batch: 40, Training Loss: 0.49981430172920227\n",
      "Epoch: 693, Batch: 80, Training Loss: 0.5466475486755371\n",
      "Epoch: 693, Validation Loss: 1.274025559425354\n",
      "Epoch: 694, Batch: 40, Training Loss: 0.49445998668670654\n",
      "Epoch: 694, Batch: 80, Training Loss: 0.5055139660835266\n",
      "Epoch: 694, Validation Loss: 1.1319172382354736\n",
      "Epoch: 695, Batch: 40, Training Loss: 0.5722989439964294\n",
      "Epoch: 695, Batch: 80, Training Loss: 0.4613899290561676\n",
      "Epoch: 695, Validation Loss: 1.2500425577163696\n",
      "Epoch: 696, Batch: 40, Training Loss: 0.4736182987689972\n",
      "Epoch: 696, Batch: 80, Training Loss: 0.4876977801322937\n",
      "Epoch: 696, Validation Loss: 1.0642167329788208\n",
      "Epoch: 697, Batch: 40, Training Loss: 0.5441821217536926\n",
      "Epoch: 697, Batch: 80, Training Loss: 0.5976330041885376\n",
      "Epoch: 697, Validation Loss: 1.138631820678711\n",
      "Epoch: 698, Batch: 40, Training Loss: 0.46697762608528137\n",
      "Epoch: 698, Batch: 80, Training Loss: 0.5646505355834961\n",
      "Epoch: 698, Validation Loss: 1.180723786354065\n",
      "Epoch: 699, Batch: 40, Training Loss: 0.5235590934753418\n",
      "Epoch: 699, Batch: 80, Training Loss: 0.5201501846313477\n",
      "Epoch: 699, Validation Loss: 1.3521286249160767\n",
      "Epoch: 700, Batch: 40, Training Loss: 0.5398823618888855\n",
      "Epoch: 700, Batch: 80, Training Loss: 0.5291474461555481\n",
      "Epoch: 700, Validation Loss: 1.2946857213974\n",
      "Epoch: 701, Batch: 40, Training Loss: 0.5113651156425476\n",
      "Epoch: 701, Batch: 80, Training Loss: 0.5362700819969177\n",
      "Epoch: 701, Validation Loss: 1.154258131980896\n",
      "Epoch: 702, Batch: 40, Training Loss: 0.5502831339836121\n",
      "Epoch: 702, Batch: 80, Training Loss: 0.5846776962280273\n",
      "Epoch: 702, Validation Loss: 1.0973488092422485\n",
      "Epoch: 703, Batch: 40, Training Loss: 0.6159107685089111\n",
      "Epoch: 703, Batch: 80, Training Loss: 0.5311927199363708\n",
      "Epoch: 703, Validation Loss: 1.3200381994247437\n",
      "Epoch: 704, Batch: 40, Training Loss: 0.5928022265434265\n",
      "Epoch: 704, Batch: 80, Training Loss: 0.5918325781822205\n",
      "Epoch: 704, Validation Loss: 1.1810243129730225\n",
      "Epoch: 705, Batch: 40, Training Loss: 0.5082307457923889\n",
      "Epoch: 705, Batch: 80, Training Loss: 0.4978909194469452\n",
      "Epoch: 705, Validation Loss: 1.0375183820724487\n",
      "Epoch: 706, Batch: 40, Training Loss: 0.5160379409790039\n",
      "Epoch: 706, Batch: 80, Training Loss: 0.5176182985305786\n",
      "Epoch: 706, Validation Loss: 1.3874059915542603\n",
      "Epoch: 707, Batch: 40, Training Loss: 0.5615493059158325\n",
      "Epoch: 707, Batch: 80, Training Loss: 0.534246027469635\n",
      "Epoch: 707, Validation Loss: 1.121391773223877\n",
      "Epoch: 708, Batch: 40, Training Loss: 0.5125198364257812\n",
      "Epoch: 708, Batch: 80, Training Loss: 0.5522508025169373\n",
      "Epoch: 708, Validation Loss: 1.0713188648223877\n",
      "Epoch: 709, Batch: 40, Training Loss: 0.5530365705490112\n",
      "Epoch: 709, Batch: 80, Training Loss: 0.5353785753250122\n",
      "Epoch: 709, Validation Loss: 1.1571807861328125\n",
      "Epoch: 710, Batch: 40, Training Loss: 0.5165567398071289\n",
      "Epoch: 710, Batch: 80, Training Loss: 0.5275694131851196\n",
      "Epoch: 710, Validation Loss: 1.15021550655365\n",
      "Epoch: 711, Batch: 40, Training Loss: 0.5272554755210876\n",
      "Epoch: 711, Batch: 80, Training Loss: 0.5199666619300842\n",
      "Epoch: 711, Validation Loss: 1.1472423076629639\n",
      "Epoch: 712, Batch: 40, Training Loss: 0.5363759398460388\n",
      "Epoch: 712, Batch: 80, Training Loss: 0.5605850219726562\n",
      "Epoch: 712, Validation Loss: 1.1173462867736816\n",
      "Epoch: 713, Batch: 40, Training Loss: 0.509605884552002\n",
      "Epoch: 713, Batch: 80, Training Loss: 0.5087053775787354\n",
      "Epoch: 713, Validation Loss: 0.9905872941017151\n",
      "Epoch: 714, Batch: 40, Training Loss: 0.5277770757675171\n",
      "Epoch: 714, Batch: 80, Training Loss: 0.5489888191223145\n",
      "Epoch: 714, Validation Loss: 1.3015961647033691\n",
      "Epoch: 715, Batch: 40, Training Loss: 0.5137425661087036\n",
      "Epoch: 715, Batch: 80, Training Loss: 0.569830060005188\n",
      "Epoch: 715, Validation Loss: 1.131187081336975\n",
      "Epoch: 716, Batch: 40, Training Loss: 0.44823890924453735\n",
      "Epoch: 716, Batch: 80, Training Loss: 0.5234283804893494\n",
      "Epoch: 716, Validation Loss: 1.1005903482437134\n",
      "Epoch: 717, Batch: 40, Training Loss: 0.508486807346344\n",
      "Epoch: 717, Batch: 80, Training Loss: 0.5583312511444092\n",
      "Epoch: 717, Validation Loss: 1.2342665195465088\n",
      "Epoch: 718, Batch: 40, Training Loss: 0.4987317621707916\n",
      "Epoch: 718, Batch: 80, Training Loss: 0.5345267653465271\n",
      "Epoch: 718, Validation Loss: 1.2672549486160278\n",
      "Epoch: 719, Batch: 40, Training Loss: 0.5346155762672424\n",
      "Epoch: 719, Batch: 80, Training Loss: 0.5832981467247009\n",
      "Epoch: 719, Validation Loss: 1.0536541938781738\n",
      "Epoch: 720, Batch: 40, Training Loss: 0.5619893074035645\n",
      "Epoch: 720, Batch: 80, Training Loss: 0.5413251519203186\n",
      "Epoch: 720, Validation Loss: 1.2955973148345947\n",
      "Epoch: 721, Batch: 40, Training Loss: 0.4732840657234192\n",
      "Epoch: 721, Batch: 80, Training Loss: 0.4842812418937683\n",
      "Epoch: 721, Validation Loss: 1.105722427368164\n",
      "Epoch: 722, Batch: 40, Training Loss: 0.5285679697990417\n",
      "Epoch: 722, Batch: 80, Training Loss: 0.6019548773765564\n",
      "Epoch: 722, Validation Loss: 1.2485558986663818\n",
      "Epoch: 723, Batch: 40, Training Loss: 0.5510755181312561\n",
      "Epoch: 723, Batch: 80, Training Loss: 0.598277747631073\n",
      "Epoch: 723, Validation Loss: 1.2378838062286377\n",
      "Epoch: 724, Batch: 40, Training Loss: 0.4839803874492645\n",
      "Epoch: 724, Batch: 80, Training Loss: 0.5402363538742065\n",
      "Epoch: 724, Validation Loss: 1.268703579902649\n",
      "Epoch: 725, Batch: 40, Training Loss: 0.5191299319267273\n",
      "Epoch: 725, Batch: 80, Training Loss: 0.46932345628738403\n",
      "Epoch: 725, Validation Loss: 1.0867655277252197\n",
      "Epoch: 726, Batch: 40, Training Loss: 0.48354676365852356\n",
      "Epoch: 726, Batch: 80, Training Loss: 0.560038149356842\n",
      "Epoch: 726, Validation Loss: 1.174022912979126\n",
      "Epoch: 727, Batch: 40, Training Loss: 0.5600190758705139\n",
      "Epoch: 727, Batch: 80, Training Loss: 0.5298447012901306\n",
      "Epoch: 727, Validation Loss: 1.1088554859161377\n",
      "Epoch: 728, Batch: 40, Training Loss: 0.5499355792999268\n",
      "Epoch: 728, Batch: 80, Training Loss: 0.5181654691696167\n",
      "Epoch: 728, Validation Loss: 1.1656789779663086\n",
      "Epoch: 729, Batch: 40, Training Loss: 0.5512993931770325\n",
      "Epoch: 729, Batch: 80, Training Loss: 0.514175534248352\n",
      "Epoch: 729, Validation Loss: 1.0733277797698975\n",
      "Epoch: 730, Batch: 40, Training Loss: 0.48936814069747925\n",
      "Epoch: 730, Batch: 80, Training Loss: 0.48718103766441345\n",
      "Epoch: 730, Validation Loss: 1.2055015563964844\n",
      "Epoch: 731, Batch: 40, Training Loss: 0.5447651743888855\n",
      "Epoch: 731, Batch: 80, Training Loss: 0.4980633854866028\n",
      "Epoch: 731, Validation Loss: 1.0848133563995361\n",
      "Epoch: 732, Batch: 40, Training Loss: 0.516014575958252\n",
      "Epoch: 732, Batch: 80, Training Loss: 0.46719229221343994\n",
      "Epoch: 732, Validation Loss: 1.135027289390564\n",
      "Epoch: 733, Batch: 40, Training Loss: 0.541944146156311\n",
      "Epoch: 733, Batch: 80, Training Loss: 0.515537440776825\n",
      "Epoch: 733, Validation Loss: 1.1867117881774902\n",
      "Epoch: 734, Batch: 40, Training Loss: 0.5077868103981018\n",
      "Epoch: 734, Batch: 80, Training Loss: 0.5564793944358826\n",
      "Epoch: 734, Validation Loss: 1.2283340692520142\n",
      "Epoch: 735, Batch: 40, Training Loss: 0.5877396464347839\n",
      "Epoch: 735, Batch: 80, Training Loss: 0.48118460178375244\n",
      "Epoch: 735, Validation Loss: 1.2477021217346191\n",
      "Epoch: 736, Batch: 40, Training Loss: 0.4606122374534607\n",
      "Epoch: 736, Batch: 80, Training Loss: 0.5211238265037537\n",
      "Epoch: 736, Validation Loss: 1.3065840005874634\n",
      "Epoch: 737, Batch: 40, Training Loss: 0.48663395643234253\n",
      "Epoch: 737, Batch: 80, Training Loss: 0.5218549966812134\n",
      "Epoch: 737, Validation Loss: 1.1332268714904785\n",
      "Epoch: 738, Batch: 40, Training Loss: 0.5421290993690491\n",
      "Epoch: 738, Batch: 80, Training Loss: 0.5492486953735352\n",
      "Epoch: 738, Validation Loss: 1.193520426750183\n",
      "Epoch: 739, Batch: 40, Training Loss: 0.5925086736679077\n",
      "Epoch: 739, Batch: 80, Training Loss: 0.5225210785865784\n",
      "Epoch: 739, Validation Loss: 1.1831239461898804\n",
      "Epoch: 740, Batch: 40, Training Loss: 0.4627019166946411\n",
      "Epoch: 740, Batch: 80, Training Loss: 0.5343019962310791\n",
      "Epoch: 740, Validation Loss: 1.1861224174499512\n",
      "Epoch: 741, Batch: 40, Training Loss: 0.552702784538269\n",
      "Epoch: 741, Batch: 80, Training Loss: 0.461356520652771\n",
      "Epoch: 741, Validation Loss: 1.2208541631698608\n",
      "Epoch: 742, Batch: 40, Training Loss: 0.48107287287712097\n",
      "Epoch: 742, Batch: 80, Training Loss: 0.4858477711677551\n",
      "Epoch: 742, Validation Loss: 1.164789080619812\n",
      "Epoch: 743, Batch: 40, Training Loss: 0.5146583914756775\n",
      "Epoch: 743, Batch: 80, Training Loss: 0.501686155796051\n",
      "Epoch: 743, Validation Loss: 1.1683387756347656\n",
      "Epoch: 744, Batch: 40, Training Loss: 0.5511342287063599\n",
      "Epoch: 744, Batch: 80, Training Loss: 0.5251747965812683\n",
      "Epoch: 744, Validation Loss: 1.2820292711257935\n",
      "Epoch: 745, Batch: 40, Training Loss: 0.5335347652435303\n",
      "Epoch: 745, Batch: 80, Training Loss: 0.5353302955627441\n",
      "Epoch: 745, Validation Loss: 1.2368911504745483\n",
      "Epoch: 746, Batch: 40, Training Loss: 0.564993143081665\n",
      "Epoch: 746, Batch: 80, Training Loss: 0.5302496552467346\n",
      "Epoch: 746, Validation Loss: 1.212295413017273\n",
      "Epoch: 747, Batch: 40, Training Loss: 0.4979974329471588\n",
      "Epoch: 747, Batch: 80, Training Loss: 0.48607590794563293\n",
      "Epoch: 747, Validation Loss: 1.207756519317627\n",
      "Epoch: 748, Batch: 40, Training Loss: 0.5451143980026245\n",
      "Epoch: 748, Batch: 80, Training Loss: 0.4920789301395416\n",
      "Epoch: 748, Validation Loss: 1.1885160207748413\n",
      "Epoch: 749, Batch: 40, Training Loss: 0.5732916593551636\n",
      "Epoch: 749, Batch: 80, Training Loss: 0.572010338306427\n",
      "Epoch: 749, Validation Loss: 1.3188704252243042\n",
      "Epoch: 750, Batch: 40, Training Loss: 0.4955155849456787\n",
      "Epoch: 750, Batch: 80, Training Loss: 0.592846691608429\n",
      "Epoch: 750, Validation Loss: 1.2370846271514893\n",
      "Epoch: 751, Batch: 40, Training Loss: 0.5430014729499817\n",
      "Epoch: 751, Batch: 80, Training Loss: 0.5523593425750732\n",
      "Epoch: 751, Validation Loss: 1.1968944072723389\n",
      "Epoch: 752, Batch: 40, Training Loss: 0.5414276123046875\n",
      "Epoch: 752, Batch: 80, Training Loss: 0.5521310567855835\n",
      "Epoch: 752, Validation Loss: 1.0704209804534912\n",
      "Epoch: 753, Batch: 40, Training Loss: 0.5343576669692993\n",
      "Epoch: 753, Batch: 80, Training Loss: 0.5122159719467163\n",
      "Epoch: 753, Validation Loss: 1.2137600183486938\n",
      "Epoch: 754, Batch: 40, Training Loss: 0.4865574240684509\n",
      "Epoch: 754, Batch: 80, Training Loss: 0.5247424840927124\n",
      "Epoch: 754, Validation Loss: 1.2773218154907227\n",
      "Epoch: 755, Batch: 40, Training Loss: 0.4697001278400421\n",
      "Epoch: 755, Batch: 80, Training Loss: 0.4712059795856476\n",
      "Epoch: 755, Validation Loss: 1.2576011419296265\n",
      "Epoch: 756, Batch: 40, Training Loss: 0.5443533062934875\n",
      "Epoch: 756, Batch: 80, Training Loss: 0.49775153398513794\n",
      "Epoch: 756, Validation Loss: 1.2399001121520996\n",
      "Epoch: 757, Batch: 40, Training Loss: 0.5599460005760193\n",
      "Epoch: 757, Batch: 80, Training Loss: 0.5553625226020813\n",
      "Epoch: 757, Validation Loss: 1.2497398853302002\n",
      "Epoch: 758, Batch: 40, Training Loss: 0.5629875063896179\n",
      "Epoch: 758, Batch: 80, Training Loss: 0.519852340221405\n",
      "Epoch: 758, Validation Loss: 1.189144253730774\n",
      "Epoch: 759, Batch: 40, Training Loss: 0.46872615814208984\n",
      "Epoch: 759, Batch: 80, Training Loss: 0.5430083274841309\n",
      "Epoch: 759, Validation Loss: 1.112376093864441\n",
      "Epoch: 760, Batch: 40, Training Loss: 0.5253298282623291\n",
      "Epoch: 760, Batch: 80, Training Loss: 0.478581041097641\n",
      "Epoch: 760, Validation Loss: 1.2347595691680908\n",
      "Epoch: 761, Batch: 40, Training Loss: 0.5804349184036255\n",
      "Epoch: 761, Batch: 80, Training Loss: 0.5530295372009277\n",
      "Epoch: 761, Validation Loss: 1.1373035907745361\n",
      "Epoch: 762, Batch: 40, Training Loss: 0.555587112903595\n",
      "Epoch: 762, Batch: 80, Training Loss: 0.5139058828353882\n",
      "Epoch: 762, Validation Loss: 1.2670916318893433\n",
      "Epoch: 763, Batch: 40, Training Loss: 0.4775260388851166\n",
      "Epoch: 763, Batch: 80, Training Loss: 0.5862246751785278\n",
      "Epoch: 763, Validation Loss: 1.2370810508728027\n",
      "Epoch: 764, Batch: 40, Training Loss: 0.5090029239654541\n",
      "Epoch: 764, Batch: 80, Training Loss: 0.5433319211006165\n",
      "Epoch: 764, Validation Loss: 1.3782025575637817\n",
      "Epoch: 765, Batch: 40, Training Loss: 0.49669259786605835\n",
      "Epoch: 765, Batch: 80, Training Loss: 0.5648077726364136\n",
      "Epoch: 765, Validation Loss: 1.2826353311538696\n",
      "Epoch: 766, Batch: 40, Training Loss: 0.46716970205307007\n",
      "Epoch: 766, Batch: 80, Training Loss: 0.5194043517112732\n",
      "Epoch: 766, Validation Loss: 1.3010412454605103\n",
      "Epoch: 767, Batch: 40, Training Loss: 0.5366587042808533\n",
      "Epoch: 767, Batch: 80, Training Loss: 0.5226319432258606\n",
      "Epoch: 767, Validation Loss: 1.169878363609314\n",
      "Epoch: 768, Batch: 40, Training Loss: 0.5294855833053589\n",
      "Epoch: 768, Batch: 80, Training Loss: 0.5610839128494263\n",
      "Epoch: 768, Validation Loss: 1.1425882577896118\n",
      "Epoch: 769, Batch: 40, Training Loss: 0.5251737236976624\n",
      "Epoch: 769, Batch: 80, Training Loss: 0.5304438471794128\n",
      "Epoch: 769, Validation Loss: 1.1977496147155762\n",
      "Epoch: 770, Batch: 40, Training Loss: 0.48636236786842346\n",
      "Epoch: 770, Batch: 80, Training Loss: 0.4875234067440033\n",
      "Epoch: 770, Validation Loss: 1.1528892517089844\n",
      "Epoch: 771, Batch: 40, Training Loss: 0.498518168926239\n",
      "Epoch: 771, Batch: 80, Training Loss: 0.5925568342208862\n",
      "Epoch: 771, Validation Loss: 1.104054570198059\n",
      "Epoch: 772, Batch: 40, Training Loss: 0.532547116279602\n",
      "Epoch: 772, Batch: 80, Training Loss: 0.5418500304222107\n",
      "Epoch: 772, Validation Loss: 1.178615689277649\n",
      "Epoch: 773, Batch: 40, Training Loss: 0.543701171875\n",
      "Epoch: 773, Batch: 80, Training Loss: 0.4591977894306183\n",
      "Epoch: 773, Validation Loss: 1.1922694444656372\n",
      "Epoch: 774, Batch: 40, Training Loss: 0.43795889616012573\n",
      "Epoch: 774, Batch: 80, Training Loss: 0.5193735957145691\n",
      "Epoch: 774, Validation Loss: 1.1334378719329834\n",
      "Epoch: 775, Batch: 40, Training Loss: 0.535395622253418\n",
      "Epoch: 775, Batch: 80, Training Loss: 0.5269032716751099\n",
      "Epoch: 775, Validation Loss: 1.3613836765289307\n",
      "Epoch: 776, Batch: 40, Training Loss: 0.524745523929596\n",
      "Epoch: 776, Batch: 80, Training Loss: 0.586225152015686\n",
      "Epoch: 776, Validation Loss: 1.1979731321334839\n",
      "Epoch: 777, Batch: 40, Training Loss: 0.45909756422042847\n",
      "Epoch: 777, Batch: 80, Training Loss: 0.5709941983222961\n",
      "Epoch: 777, Validation Loss: 1.2225559949874878\n",
      "Epoch: 778, Batch: 40, Training Loss: 0.5403704643249512\n",
      "Epoch: 778, Batch: 80, Training Loss: 0.5107690095901489\n",
      "Epoch: 778, Validation Loss: 1.0768492221832275\n",
      "Epoch: 779, Batch: 40, Training Loss: 0.4820423424243927\n",
      "Epoch: 779, Batch: 80, Training Loss: 0.5278308987617493\n",
      "Epoch: 779, Validation Loss: 1.2908997535705566\n",
      "Epoch: 780, Batch: 40, Training Loss: 0.46669140458106995\n",
      "Epoch: 780, Batch: 80, Training Loss: 0.5162886381149292\n",
      "Epoch: 780, Validation Loss: 1.3458008766174316\n",
      "Epoch: 781, Batch: 40, Training Loss: 0.5568349957466125\n",
      "Epoch: 781, Batch: 80, Training Loss: 0.532188892364502\n",
      "Epoch: 781, Validation Loss: 1.2014775276184082\n",
      "Epoch: 782, Batch: 40, Training Loss: 0.5392636656761169\n",
      "Epoch: 782, Batch: 80, Training Loss: 0.6457007527351379\n",
      "Epoch: 782, Validation Loss: 1.0713037252426147\n",
      "Epoch: 783, Batch: 40, Training Loss: 0.5664803981781006\n",
      "Epoch: 783, Batch: 80, Training Loss: 0.4440017342567444\n",
      "Epoch: 783, Validation Loss: 1.2839561700820923\n",
      "Epoch: 784, Batch: 40, Training Loss: 0.49591436982154846\n",
      "Epoch: 784, Batch: 80, Training Loss: 0.5232669711112976\n",
      "Epoch: 784, Validation Loss: 1.2573128938674927\n",
      "Epoch: 785, Batch: 40, Training Loss: 0.5287573933601379\n",
      "Epoch: 785, Batch: 80, Training Loss: 0.5692771673202515\n",
      "Epoch: 785, Validation Loss: 1.2644648551940918\n",
      "Epoch: 786, Batch: 40, Training Loss: 0.5366628766059875\n",
      "Epoch: 786, Batch: 80, Training Loss: 0.5561073422431946\n",
      "Epoch: 786, Validation Loss: 1.320449709892273\n",
      "Epoch: 787, Batch: 40, Training Loss: 0.5294924974441528\n",
      "Epoch: 787, Batch: 80, Training Loss: 0.5319032073020935\n",
      "Epoch: 787, Validation Loss: 1.225655436515808\n",
      "Epoch: 788, Batch: 40, Training Loss: 0.5597218871116638\n",
      "Epoch: 788, Batch: 80, Training Loss: 0.5395810604095459\n",
      "Epoch: 788, Validation Loss: 1.4003024101257324\n",
      "Epoch: 789, Batch: 40, Training Loss: 0.49660974740982056\n",
      "Epoch: 789, Batch: 80, Training Loss: 0.5486103892326355\n",
      "Epoch: 789, Validation Loss: 1.1092345714569092\n",
      "Epoch: 790, Batch: 40, Training Loss: 0.5065982341766357\n",
      "Epoch: 790, Batch: 80, Training Loss: 0.4608498811721802\n",
      "Epoch: 790, Validation Loss: 1.2631090879440308\n",
      "Epoch: 791, Batch: 40, Training Loss: 0.4739965498447418\n",
      "Epoch: 791, Batch: 80, Training Loss: 0.537670373916626\n",
      "Epoch: 791, Validation Loss: 1.1487178802490234\n",
      "Epoch: 792, Batch: 40, Training Loss: 0.48141786456108093\n",
      "Epoch: 792, Batch: 80, Training Loss: 0.5902897715568542\n",
      "Epoch: 792, Validation Loss: 1.1608185768127441\n",
      "Epoch: 793, Batch: 40, Training Loss: 0.5466076731681824\n",
      "Epoch: 793, Batch: 80, Training Loss: 0.544931948184967\n",
      "Epoch: 793, Validation Loss: 1.3081443309783936\n",
      "Epoch: 794, Batch: 40, Training Loss: 0.5366854667663574\n",
      "Epoch: 794, Batch: 80, Training Loss: 0.490534245967865\n",
      "Epoch: 794, Validation Loss: 1.3450814485549927\n",
      "Epoch: 795, Batch: 40, Training Loss: 0.513404905796051\n",
      "Epoch: 795, Batch: 80, Training Loss: 0.5374953150749207\n",
      "Epoch: 795, Validation Loss: 1.3831356763839722\n",
      "Epoch: 796, Batch: 40, Training Loss: 0.5691847801208496\n",
      "Epoch: 796, Batch: 80, Training Loss: 0.5699968338012695\n",
      "Epoch: 796, Validation Loss: 1.308036208152771\n",
      "Epoch: 797, Batch: 40, Training Loss: 0.47289806604385376\n",
      "Epoch: 797, Batch: 80, Training Loss: 0.5547736287117004\n",
      "Epoch: 797, Validation Loss: 1.2172776460647583\n",
      "Epoch: 798, Batch: 40, Training Loss: 0.4657825827598572\n",
      "Epoch: 798, Batch: 80, Training Loss: 0.5390182733535767\n",
      "Epoch: 798, Validation Loss: 1.0857412815093994\n",
      "Epoch: 799, Batch: 40, Training Loss: 0.444974422454834\n",
      "Epoch: 799, Batch: 80, Training Loss: 0.5481939315795898\n",
      "Epoch: 799, Validation Loss: 1.2811369895935059\n",
      "Epoch: 800, Batch: 40, Training Loss: 0.5422692894935608\n",
      "Epoch: 800, Batch: 80, Training Loss: 0.60163414478302\n",
      "Epoch: 800, Validation Loss: 1.2209924459457397\n",
      "Epoch: 801, Batch: 40, Training Loss: 0.5223813056945801\n",
      "Epoch: 801, Batch: 80, Training Loss: 0.6100797057151794\n",
      "Epoch: 801, Validation Loss: 1.2571731805801392\n",
      "Epoch: 802, Batch: 40, Training Loss: 0.5683689117431641\n",
      "Epoch: 802, Batch: 80, Training Loss: 0.579969048500061\n",
      "Epoch: 802, Validation Loss: 1.220942497253418\n",
      "Epoch: 803, Batch: 40, Training Loss: 0.5843358039855957\n",
      "Epoch: 803, Batch: 80, Training Loss: 0.45091840624809265\n",
      "Epoch: 803, Validation Loss: 1.1559540033340454\n",
      "Epoch: 804, Batch: 40, Training Loss: 0.6029988527297974\n",
      "Epoch: 804, Batch: 80, Training Loss: 0.48893555998802185\n",
      "Epoch: 804, Validation Loss: 1.0385679006576538\n",
      "Epoch: 805, Batch: 40, Training Loss: 0.49138107895851135\n",
      "Epoch: 805, Batch: 80, Training Loss: 0.4924186170101166\n",
      "Epoch: 805, Validation Loss: 1.0853749513626099\n",
      "Epoch: 806, Batch: 40, Training Loss: 0.4792787432670593\n",
      "Epoch: 806, Batch: 80, Training Loss: 0.5050264000892639\n",
      "Epoch: 806, Validation Loss: 1.35080087184906\n",
      "Epoch: 807, Batch: 40, Training Loss: 0.5584370493888855\n",
      "Epoch: 807, Batch: 80, Training Loss: 0.5423267483711243\n",
      "Epoch: 807, Validation Loss: 1.1873908042907715\n",
      "Epoch: 808, Batch: 40, Training Loss: 0.5204017162322998\n",
      "Epoch: 808, Batch: 80, Training Loss: 0.54559326171875\n",
      "Epoch: 808, Validation Loss: 1.317383885383606\n",
      "Epoch: 809, Batch: 40, Training Loss: 0.5473641753196716\n",
      "Epoch: 809, Batch: 80, Training Loss: 0.5110285878181458\n",
      "Epoch: 809, Validation Loss: 1.1183708906173706\n",
      "Epoch: 810, Batch: 40, Training Loss: 0.4564017951488495\n",
      "Epoch: 810, Batch: 80, Training Loss: 0.5114696621894836\n",
      "Epoch: 810, Validation Loss: 1.2222408056259155\n",
      "Epoch: 811, Batch: 40, Training Loss: 0.5350302457809448\n",
      "Epoch: 811, Batch: 80, Training Loss: 0.5284721255302429\n",
      "Epoch: 811, Validation Loss: 1.1538522243499756\n",
      "Epoch: 812, Batch: 40, Training Loss: 0.508328914642334\n",
      "Epoch: 812, Batch: 80, Training Loss: 0.5592824220657349\n",
      "Epoch: 812, Validation Loss: 1.0954854488372803\n",
      "Epoch: 813, Batch: 40, Training Loss: 0.48994216322898865\n",
      "Epoch: 813, Batch: 80, Training Loss: 0.552094578742981\n",
      "Epoch: 813, Validation Loss: 1.207558274269104\n",
      "Epoch: 814, Batch: 40, Training Loss: 0.45491349697113037\n",
      "Epoch: 814, Batch: 80, Training Loss: 0.5820204615592957\n",
      "Epoch: 814, Validation Loss: 1.4072678089141846\n",
      "Epoch: 815, Batch: 40, Training Loss: 0.49615001678466797\n",
      "Epoch: 815, Batch: 80, Training Loss: 0.5192340612411499\n",
      "Epoch: 815, Validation Loss: 1.2267266511917114\n",
      "Epoch: 816, Batch: 40, Training Loss: 0.5239025354385376\n",
      "Epoch: 816, Batch: 80, Training Loss: 0.5858603715896606\n",
      "Epoch: 816, Validation Loss: 1.1252483129501343\n",
      "Epoch: 817, Batch: 40, Training Loss: 0.5490703582763672\n",
      "Epoch: 817, Batch: 80, Training Loss: 0.5033037662506104\n",
      "Epoch: 817, Validation Loss: 1.2006603479385376\n",
      "Epoch: 818, Batch: 40, Training Loss: 0.49020916223526\n",
      "Epoch: 818, Batch: 80, Training Loss: 0.48468464612960815\n",
      "Epoch: 818, Validation Loss: 1.1707934141159058\n",
      "Epoch: 819, Batch: 40, Training Loss: 0.5519343614578247\n",
      "Epoch: 819, Batch: 80, Training Loss: 0.5160605907440186\n",
      "Epoch: 819, Validation Loss: 1.1337999105453491\n",
      "Epoch: 820, Batch: 40, Training Loss: 0.5624935030937195\n",
      "Epoch: 820, Batch: 80, Training Loss: 0.5602447390556335\n",
      "Epoch: 820, Validation Loss: 1.1070202589035034\n",
      "Epoch: 821, Batch: 40, Training Loss: 0.5053166747093201\n",
      "Epoch: 821, Batch: 80, Training Loss: 0.5863604545593262\n",
      "Epoch: 821, Validation Loss: 1.1990593671798706\n",
      "Epoch: 822, Batch: 40, Training Loss: 0.5424788594245911\n",
      "Epoch: 822, Batch: 80, Training Loss: 0.44108638167381287\n",
      "Epoch: 822, Validation Loss: 1.3441441059112549\n",
      "Epoch: 823, Batch: 40, Training Loss: 0.516075074672699\n",
      "Epoch: 823, Batch: 80, Training Loss: 0.5176276564598083\n",
      "Epoch: 823, Validation Loss: 1.278710126876831\n",
      "Epoch: 824, Batch: 40, Training Loss: 0.5397554039955139\n",
      "Epoch: 824, Batch: 80, Training Loss: 0.5843359231948853\n",
      "Epoch: 824, Validation Loss: 1.209680438041687\n",
      "Epoch: 825, Batch: 40, Training Loss: 0.5412314534187317\n",
      "Epoch: 825, Batch: 80, Training Loss: 0.5932736992835999\n",
      "Epoch: 825, Validation Loss: 1.1645019054412842\n",
      "Epoch: 826, Batch: 40, Training Loss: 0.5643578171730042\n",
      "Epoch: 826, Batch: 80, Training Loss: 0.5172942280769348\n",
      "Epoch: 826, Validation Loss: 1.295209527015686\n",
      "Epoch: 827, Batch: 40, Training Loss: 0.5177563428878784\n",
      "Epoch: 827, Batch: 80, Training Loss: 0.5381762981414795\n",
      "Epoch: 827, Validation Loss: 1.0871440172195435\n",
      "Epoch: 828, Batch: 40, Training Loss: 0.5216644406318665\n",
      "Epoch: 828, Batch: 80, Training Loss: 0.4926950931549072\n",
      "Epoch: 828, Validation Loss: 1.2850204706192017\n",
      "Epoch: 829, Batch: 40, Training Loss: 0.476040244102478\n",
      "Epoch: 829, Batch: 80, Training Loss: 0.5481570959091187\n",
      "Epoch: 829, Validation Loss: 1.2659016847610474\n",
      "Epoch: 830, Batch: 40, Training Loss: 0.5418113470077515\n",
      "Epoch: 830, Batch: 80, Training Loss: 0.4827539324760437\n",
      "Epoch: 830, Validation Loss: 1.259267807006836\n",
      "Epoch: 831, Batch: 40, Training Loss: 0.5017396807670593\n",
      "Epoch: 831, Batch: 80, Training Loss: 0.5309891104698181\n",
      "Epoch: 831, Validation Loss: 1.136732816696167\n",
      "Epoch: 832, Batch: 40, Training Loss: 0.5212604403495789\n",
      "Epoch: 832, Batch: 80, Training Loss: 0.4563983380794525\n",
      "Epoch: 832, Validation Loss: 1.2237597703933716\n",
      "Epoch: 833, Batch: 40, Training Loss: 0.4901236295700073\n",
      "Epoch: 833, Batch: 80, Training Loss: 0.49846938252449036\n",
      "Epoch: 833, Validation Loss: 1.3871734142303467\n",
      "Epoch: 834, Batch: 40, Training Loss: 0.5106076598167419\n",
      "Epoch: 834, Batch: 80, Training Loss: 0.510628879070282\n",
      "Epoch: 834, Validation Loss: 1.2234069108963013\n",
      "Epoch: 835, Batch: 40, Training Loss: 0.5558663606643677\n",
      "Epoch: 835, Batch: 80, Training Loss: 0.6046608686447144\n",
      "Epoch: 835, Validation Loss: 1.3065789937973022\n",
      "Epoch: 836, Batch: 40, Training Loss: 0.4786823093891144\n",
      "Epoch: 836, Batch: 80, Training Loss: 0.5989585518836975\n",
      "Epoch: 836, Validation Loss: 1.11826753616333\n",
      "Epoch: 837, Batch: 40, Training Loss: 0.47199007868766785\n",
      "Epoch: 837, Batch: 80, Training Loss: 0.49004241824150085\n",
      "Epoch: 837, Validation Loss: 1.3550552129745483\n",
      "Epoch: 838, Batch: 40, Training Loss: 0.5090938210487366\n",
      "Epoch: 838, Batch: 80, Training Loss: 0.49067679047584534\n",
      "Epoch: 838, Validation Loss: 1.174414873123169\n",
      "Epoch: 839, Batch: 40, Training Loss: 0.5301510691642761\n",
      "Epoch: 839, Batch: 80, Training Loss: 0.48952344059944153\n",
      "Epoch: 839, Validation Loss: 1.0125634670257568\n",
      "Epoch: 840, Batch: 40, Training Loss: 0.5235140323638916\n",
      "Epoch: 840, Batch: 80, Training Loss: 0.5477461218833923\n",
      "Epoch: 840, Validation Loss: 1.3012598752975464\n",
      "Epoch: 841, Batch: 40, Training Loss: 0.5230772495269775\n",
      "Epoch: 841, Batch: 80, Training Loss: 0.5595401525497437\n",
      "Epoch: 841, Validation Loss: 1.2839969396591187\n",
      "Epoch: 842, Batch: 40, Training Loss: 0.46261441707611084\n",
      "Epoch: 842, Batch: 80, Training Loss: 0.5449463725090027\n",
      "Epoch: 842, Validation Loss: 1.1566499471664429\n",
      "Epoch: 843, Batch: 40, Training Loss: 0.493309885263443\n",
      "Epoch: 843, Batch: 80, Training Loss: 0.56658536195755\n",
      "Epoch: 843, Validation Loss: 1.112913966178894\n",
      "Epoch: 844, Batch: 40, Training Loss: 0.4799433946609497\n",
      "Epoch: 844, Batch: 80, Training Loss: 0.5033825039863586\n",
      "Epoch: 844, Validation Loss: 1.2087998390197754\n",
      "Epoch: 845, Batch: 40, Training Loss: 0.4473697543144226\n",
      "Epoch: 845, Batch: 80, Training Loss: 0.5017858147621155\n",
      "Epoch: 845, Validation Loss: 1.2150660753250122\n",
      "Epoch: 846, Batch: 40, Training Loss: 0.5942983031272888\n",
      "Epoch: 846, Batch: 80, Training Loss: 0.5972582101821899\n",
      "Epoch: 846, Validation Loss: 1.2001034021377563\n",
      "Epoch: 847, Batch: 40, Training Loss: 0.47143739461898804\n",
      "Epoch: 847, Batch: 80, Training Loss: 0.48823779821395874\n",
      "Epoch: 847, Validation Loss: 1.1569803953170776\n",
      "Epoch: 848, Batch: 40, Training Loss: 0.5405160188674927\n",
      "Epoch: 848, Batch: 80, Training Loss: 0.5207597613334656\n",
      "Epoch: 848, Validation Loss: 1.2535598278045654\n",
      "Epoch: 849, Batch: 40, Training Loss: 0.5050951242446899\n",
      "Epoch: 849, Batch: 80, Training Loss: 0.5015242695808411\n",
      "Epoch: 849, Validation Loss: 1.2756311893463135\n",
      "Epoch: 850, Batch: 40, Training Loss: 0.49360939860343933\n",
      "Epoch: 850, Batch: 80, Training Loss: 0.5425360202789307\n",
      "Epoch: 850, Validation Loss: 1.106975793838501\n",
      "Epoch: 851, Batch: 40, Training Loss: 0.5088677406311035\n",
      "Epoch: 851, Batch: 80, Training Loss: 0.39499399065971375\n",
      "Epoch: 851, Validation Loss: 1.3714855909347534\n",
      "Epoch: 852, Batch: 40, Training Loss: 0.4870024621486664\n",
      "Epoch: 852, Batch: 80, Training Loss: 0.5514540076255798\n",
      "Epoch: 852, Validation Loss: 1.3385491371154785\n",
      "Epoch: 853, Batch: 40, Training Loss: 0.5636674761772156\n",
      "Epoch: 853, Batch: 80, Training Loss: 0.5505357384681702\n",
      "Epoch: 853, Validation Loss: 1.2040032148361206\n",
      "Epoch: 854, Batch: 40, Training Loss: 0.5834531784057617\n",
      "Epoch: 854, Batch: 80, Training Loss: 0.5395786166191101\n",
      "Epoch: 854, Validation Loss: 1.3239250183105469\n",
      "Epoch: 855, Batch: 40, Training Loss: 0.49842244386672974\n",
      "Epoch: 855, Batch: 80, Training Loss: 0.519844651222229\n",
      "Epoch: 855, Validation Loss: 1.0724955797195435\n",
      "Epoch: 856, Batch: 40, Training Loss: 0.5520651340484619\n",
      "Epoch: 856, Batch: 80, Training Loss: 0.5161689519882202\n",
      "Epoch: 856, Validation Loss: 1.1980782747268677\n",
      "Epoch: 857, Batch: 40, Training Loss: 0.484403520822525\n",
      "Epoch: 857, Batch: 80, Training Loss: 0.546364426612854\n",
      "Epoch: 857, Validation Loss: 1.0948222875595093\n",
      "Epoch: 858, Batch: 40, Training Loss: 0.5055476427078247\n",
      "Epoch: 858, Batch: 80, Training Loss: 0.5190567970275879\n",
      "Epoch: 858, Validation Loss: 1.2415207624435425\n",
      "Epoch: 859, Batch: 40, Training Loss: 0.5244532227516174\n",
      "Epoch: 859, Batch: 80, Training Loss: 0.45757147669792175\n",
      "Epoch: 859, Validation Loss: 1.2374906539916992\n",
      "Epoch: 860, Batch: 40, Training Loss: 0.4985981285572052\n",
      "Epoch: 860, Batch: 80, Training Loss: 0.5407407879829407\n",
      "Epoch: 860, Validation Loss: 1.1269959211349487\n",
      "Epoch: 861, Batch: 40, Training Loss: 0.4640679359436035\n",
      "Epoch: 861, Batch: 80, Training Loss: 0.5373024344444275\n",
      "Epoch: 861, Validation Loss: 1.1409178972244263\n",
      "Epoch: 862, Batch: 40, Training Loss: 0.49720439314842224\n",
      "Epoch: 862, Batch: 80, Training Loss: 0.5615624785423279\n",
      "Epoch: 862, Validation Loss: 1.2573933601379395\n",
      "Epoch: 863, Batch: 40, Training Loss: 0.45025452971458435\n",
      "Epoch: 863, Batch: 80, Training Loss: 0.45822420716285706\n",
      "Epoch: 863, Validation Loss: 1.3831502199172974\n",
      "Epoch: 864, Batch: 40, Training Loss: 0.5300186276435852\n",
      "Epoch: 864, Batch: 80, Training Loss: 0.5101524591445923\n",
      "Epoch: 864, Validation Loss: 1.188049077987671\n",
      "Epoch: 865, Batch: 40, Training Loss: 0.44924890995025635\n",
      "Epoch: 865, Batch: 80, Training Loss: 0.41434401273727417\n",
      "Epoch: 865, Validation Loss: 1.2470046281814575\n",
      "Epoch: 866, Batch: 40, Training Loss: 0.4844256639480591\n",
      "Epoch: 866, Batch: 80, Training Loss: 0.5525670647621155\n",
      "Epoch: 866, Validation Loss: 1.2550160884857178\n",
      "Epoch: 867, Batch: 40, Training Loss: 0.4704412817955017\n",
      "Epoch: 867, Batch: 80, Training Loss: 0.46455585956573486\n",
      "Epoch: 867, Validation Loss: 1.2388790845870972\n",
      "Epoch: 868, Batch: 40, Training Loss: 0.4782741367816925\n",
      "Epoch: 868, Batch: 80, Training Loss: 0.5299134850502014\n",
      "Epoch: 868, Validation Loss: 1.1293606758117676\n",
      "Epoch: 869, Batch: 40, Training Loss: 0.5109464526176453\n",
      "Epoch: 869, Batch: 80, Training Loss: 0.5574870705604553\n",
      "Epoch: 869, Validation Loss: 1.1970984935760498\n",
      "Epoch: 870, Batch: 40, Training Loss: 0.5659676194190979\n",
      "Epoch: 870, Batch: 80, Training Loss: 0.48671892285346985\n",
      "Epoch: 870, Validation Loss: 1.0537177324295044\n",
      "Epoch: 871, Batch: 40, Training Loss: 0.4789421260356903\n",
      "Epoch: 871, Batch: 80, Training Loss: 0.4885239899158478\n",
      "Epoch: 871, Validation Loss: 1.3003318309783936\n",
      "Epoch: 872, Batch: 40, Training Loss: 0.49988242983818054\n",
      "Epoch: 872, Batch: 80, Training Loss: 0.5864546298980713\n",
      "Epoch: 872, Validation Loss: 1.3070473670959473\n",
      "Epoch: 873, Batch: 40, Training Loss: 0.5911040306091309\n",
      "Epoch: 873, Batch: 80, Training Loss: 0.5580353140830994\n",
      "Epoch: 873, Validation Loss: 1.230747103691101\n",
      "Epoch: 874, Batch: 40, Training Loss: 0.5358664393424988\n",
      "Epoch: 874, Batch: 80, Training Loss: 0.5472639203071594\n",
      "Epoch: 874, Validation Loss: 1.1693226099014282\n",
      "Epoch: 875, Batch: 40, Training Loss: 0.5660614967346191\n",
      "Epoch: 875, Batch: 80, Training Loss: 0.5805655717849731\n",
      "Epoch: 875, Validation Loss: 1.2583736181259155\n",
      "Epoch: 876, Batch: 40, Training Loss: 0.5562893152236938\n",
      "Epoch: 876, Batch: 80, Training Loss: 0.477912038564682\n",
      "Epoch: 876, Validation Loss: 1.3099228143692017\n",
      "Epoch: 877, Batch: 40, Training Loss: 0.46947044134140015\n",
      "Epoch: 877, Batch: 80, Training Loss: 0.5071712732315063\n",
      "Epoch: 877, Validation Loss: 1.1969399452209473\n",
      "Epoch: 878, Batch: 40, Training Loss: 0.5929123163223267\n",
      "Epoch: 878, Batch: 80, Training Loss: 0.47860532999038696\n",
      "Epoch: 878, Validation Loss: 1.1811797618865967\n",
      "Epoch: 879, Batch: 40, Training Loss: 0.5571669936180115\n",
      "Epoch: 879, Batch: 80, Training Loss: 0.5493519306182861\n",
      "Epoch: 879, Validation Loss: 1.2201967239379883\n",
      "Epoch: 880, Batch: 40, Training Loss: 0.5568265914916992\n",
      "Epoch: 880, Batch: 80, Training Loss: 0.48235148191452026\n",
      "Epoch: 880, Validation Loss: 1.2588151693344116\n",
      "Epoch: 881, Batch: 40, Training Loss: 0.5022426247596741\n",
      "Epoch: 881, Batch: 80, Training Loss: 0.5766141414642334\n",
      "Epoch: 881, Validation Loss: 1.325579047203064\n",
      "Epoch: 882, Batch: 40, Training Loss: 0.5252779722213745\n",
      "Epoch: 882, Batch: 80, Training Loss: 0.541607141494751\n",
      "Epoch: 882, Validation Loss: 1.4165316820144653\n",
      "Epoch: 883, Batch: 40, Training Loss: 0.49256184697151184\n",
      "Epoch: 883, Batch: 80, Training Loss: 0.5453344583511353\n",
      "Epoch: 883, Validation Loss: 1.0904903411865234\n",
      "Epoch: 884, Batch: 40, Training Loss: 0.4949784576892853\n",
      "Epoch: 884, Batch: 80, Training Loss: 0.6272030472755432\n",
      "Epoch: 884, Validation Loss: 1.1576582193374634\n",
      "Epoch: 885, Batch: 40, Training Loss: 0.5534160137176514\n",
      "Epoch: 885, Batch: 80, Training Loss: 0.5411971807479858\n",
      "Epoch: 885, Validation Loss: 1.2676355838775635\n",
      "Epoch: 886, Batch: 40, Training Loss: 0.5693178772926331\n",
      "Epoch: 886, Batch: 80, Training Loss: 0.5172020196914673\n",
      "Epoch: 886, Validation Loss: 1.2846866846084595\n",
      "Epoch: 887, Batch: 40, Training Loss: 0.4704778492450714\n",
      "Epoch: 887, Batch: 80, Training Loss: 0.5303709506988525\n",
      "Epoch: 887, Validation Loss: 1.269905686378479\n",
      "Epoch: 888, Batch: 40, Training Loss: 0.5364691019058228\n",
      "Epoch: 888, Batch: 80, Training Loss: 0.5029107928276062\n",
      "Epoch: 888, Validation Loss: 1.2428598403930664\n",
      "Epoch: 889, Batch: 40, Training Loss: 0.4819672107696533\n",
      "Epoch: 889, Batch: 80, Training Loss: 0.4632989168167114\n",
      "Epoch: 889, Validation Loss: 1.257658839225769\n",
      "Epoch: 890, Batch: 40, Training Loss: 0.4916497468948364\n",
      "Epoch: 890, Batch: 80, Training Loss: 0.5305432677268982\n",
      "Epoch: 890, Validation Loss: 1.4179332256317139\n",
      "Epoch: 891, Batch: 40, Training Loss: 0.5265159010887146\n",
      "Epoch: 891, Batch: 80, Training Loss: 0.5038412809371948\n",
      "Epoch: 891, Validation Loss: 1.199828863143921\n",
      "Epoch: 892, Batch: 40, Training Loss: 0.5837357044219971\n",
      "Epoch: 892, Batch: 80, Training Loss: 0.5032656788825989\n",
      "Epoch: 892, Validation Loss: 1.2300057411193848\n",
      "Epoch: 893, Batch: 40, Training Loss: 0.4876362085342407\n",
      "Epoch: 893, Batch: 80, Training Loss: 0.4738454818725586\n",
      "Epoch: 893, Validation Loss: 1.2022514343261719\n",
      "Epoch: 894, Batch: 40, Training Loss: 0.5470139980316162\n",
      "Epoch: 894, Batch: 80, Training Loss: 0.5680615305900574\n",
      "Epoch: 894, Validation Loss: 1.3535822629928589\n",
      "Epoch: 895, Batch: 40, Training Loss: 0.4622565805912018\n",
      "Epoch: 895, Batch: 80, Training Loss: 0.49145781993865967\n",
      "Epoch: 895, Validation Loss: 1.2613176107406616\n",
      "Epoch: 896, Batch: 40, Training Loss: 0.5226913094520569\n",
      "Epoch: 896, Batch: 80, Training Loss: 0.5212140083312988\n",
      "Epoch: 896, Validation Loss: 1.369038701057434\n",
      "Epoch: 897, Batch: 40, Training Loss: 0.49799925088882446\n",
      "Epoch: 897, Batch: 80, Training Loss: 0.5201939940452576\n",
      "Epoch: 897, Validation Loss: 1.1271125078201294\n",
      "Epoch: 898, Batch: 40, Training Loss: 0.43989676237106323\n",
      "Epoch: 898, Batch: 80, Training Loss: 0.4848678708076477\n",
      "Epoch: 898, Validation Loss: 1.2248128652572632\n",
      "Epoch: 899, Batch: 40, Training Loss: 0.4674648344516754\n",
      "Epoch: 899, Batch: 80, Training Loss: 0.43301522731781006\n",
      "Epoch: 899, Validation Loss: 1.2296758890151978\n",
      "Epoch: 900, Batch: 40, Training Loss: 0.4591616988182068\n",
      "Epoch: 900, Batch: 80, Training Loss: 0.5536271929740906\n",
      "Epoch: 900, Validation Loss: 1.2456862926483154\n",
      "Epoch: 901, Batch: 40, Training Loss: 0.5392028093338013\n",
      "Epoch: 901, Batch: 80, Training Loss: 0.4969930350780487\n",
      "Epoch: 901, Validation Loss: 1.0279183387756348\n",
      "Epoch: 902, Batch: 40, Training Loss: 0.454346626996994\n",
      "Epoch: 902, Batch: 80, Training Loss: 0.5300729274749756\n",
      "Epoch: 902, Validation Loss: 1.233413815498352\n",
      "Epoch: 903, Batch: 40, Training Loss: 0.47513994574546814\n",
      "Epoch: 903, Batch: 80, Training Loss: 0.5015478134155273\n",
      "Epoch: 903, Validation Loss: 1.241283655166626\n",
      "Epoch: 904, Batch: 40, Training Loss: 0.4979385733604431\n",
      "Epoch: 904, Batch: 80, Training Loss: 0.532206118106842\n",
      "Epoch: 904, Validation Loss: 1.2465885877609253\n",
      "Epoch: 905, Batch: 40, Training Loss: 0.5391237735748291\n",
      "Epoch: 905, Batch: 80, Training Loss: 0.4656097888946533\n",
      "Epoch: 905, Validation Loss: 0.9867131114006042\n",
      "Epoch: 906, Batch: 40, Training Loss: 0.5607897043228149\n",
      "Epoch: 906, Batch: 80, Training Loss: 0.47708654403686523\n",
      "Epoch: 906, Validation Loss: 1.145477294921875\n",
      "Epoch: 907, Batch: 40, Training Loss: 0.5186552405357361\n",
      "Epoch: 907, Batch: 80, Training Loss: 0.5252792239189148\n",
      "Epoch: 907, Validation Loss: 1.3683534860610962\n",
      "Epoch: 908, Batch: 40, Training Loss: 0.5238829851150513\n",
      "Epoch: 908, Batch: 80, Training Loss: 0.646836519241333\n",
      "Epoch: 908, Validation Loss: 1.2695931196212769\n",
      "Epoch: 909, Batch: 40, Training Loss: 0.4714849591255188\n",
      "Epoch: 909, Batch: 80, Training Loss: 0.5527309775352478\n",
      "Epoch: 909, Validation Loss: 1.1830836534500122\n",
      "Epoch: 910, Batch: 40, Training Loss: 0.5804592967033386\n",
      "Epoch: 910, Batch: 80, Training Loss: 0.5470730066299438\n",
      "Epoch: 910, Validation Loss: 1.3413565158843994\n",
      "Epoch: 911, Batch: 40, Training Loss: 0.5651898384094238\n",
      "Epoch: 911, Batch: 80, Training Loss: 0.5321289896965027\n",
      "Epoch: 911, Validation Loss: 1.159795880317688\n",
      "Epoch: 912, Batch: 40, Training Loss: 0.4790216088294983\n",
      "Epoch: 912, Batch: 80, Training Loss: 0.5260559916496277\n",
      "Epoch: 912, Validation Loss: 1.256728172302246\n",
      "Epoch: 913, Batch: 40, Training Loss: 0.5275771021842957\n",
      "Epoch: 913, Batch: 80, Training Loss: 0.5690903663635254\n",
      "Epoch: 913, Validation Loss: 1.3291608095169067\n",
      "Epoch: 914, Batch: 40, Training Loss: 0.6020917296409607\n",
      "Epoch: 914, Batch: 80, Training Loss: 0.512270987033844\n",
      "Epoch: 914, Validation Loss: 1.2298308610916138\n",
      "Epoch: 915, Batch: 40, Training Loss: 0.4521031379699707\n",
      "Epoch: 915, Batch: 80, Training Loss: 0.5243005752563477\n",
      "Epoch: 915, Validation Loss: 1.2801975011825562\n",
      "Epoch: 916, Batch: 40, Training Loss: 0.5023868083953857\n",
      "Epoch: 916, Batch: 80, Training Loss: 0.49205735325813293\n",
      "Epoch: 916, Validation Loss: 1.1315510272979736\n",
      "Epoch: 917, Batch: 40, Training Loss: 0.4867534339427948\n",
      "Epoch: 917, Batch: 80, Training Loss: 0.463905394077301\n",
      "Epoch: 917, Validation Loss: 1.151701807975769\n",
      "Epoch: 918, Batch: 40, Training Loss: 0.5389015078544617\n",
      "Epoch: 918, Batch: 80, Training Loss: 0.5367484092712402\n",
      "Epoch: 918, Validation Loss: 1.3451498746871948\n",
      "Epoch: 919, Batch: 40, Training Loss: 0.4825161397457123\n",
      "Epoch: 919, Batch: 80, Training Loss: 0.4976634383201599\n",
      "Epoch: 919, Validation Loss: 1.2053533792495728\n",
      "Epoch: 920, Batch: 40, Training Loss: 0.5211725831031799\n",
      "Epoch: 920, Batch: 80, Training Loss: 0.5458995699882507\n",
      "Epoch: 920, Validation Loss: 1.3123635053634644\n",
      "Epoch: 921, Batch: 40, Training Loss: 0.5188316106796265\n",
      "Epoch: 921, Batch: 80, Training Loss: 0.5145784616470337\n",
      "Epoch: 921, Validation Loss: 1.1816436052322388\n",
      "Epoch: 922, Batch: 40, Training Loss: 0.47072651982307434\n",
      "Epoch: 922, Batch: 80, Training Loss: 0.4958195984363556\n",
      "Epoch: 922, Validation Loss: 1.284543752670288\n",
      "Epoch: 923, Batch: 40, Training Loss: 0.5262725949287415\n",
      "Epoch: 923, Batch: 80, Training Loss: 0.5019250512123108\n",
      "Epoch: 923, Validation Loss: 1.184139370918274\n",
      "Epoch: 924, Batch: 40, Training Loss: 0.4488179385662079\n",
      "Epoch: 924, Batch: 80, Training Loss: 0.5613564252853394\n",
      "Epoch: 924, Validation Loss: 1.2658478021621704\n",
      "Epoch: 925, Batch: 40, Training Loss: 0.5609464049339294\n",
      "Epoch: 925, Batch: 80, Training Loss: 0.5401536226272583\n",
      "Epoch: 925, Validation Loss: 1.1421908140182495\n",
      "Epoch: 926, Batch: 40, Training Loss: 0.4932219684123993\n",
      "Epoch: 926, Batch: 80, Training Loss: 0.5622519254684448\n",
      "Epoch: 926, Validation Loss: 1.24730384349823\n",
      "Epoch: 927, Batch: 40, Training Loss: 0.5064203143119812\n",
      "Epoch: 927, Batch: 80, Training Loss: 0.49925121665000916\n",
      "Epoch: 927, Validation Loss: 1.31648588180542\n",
      "Epoch: 928, Batch: 40, Training Loss: 0.48427268862724304\n",
      "Epoch: 928, Batch: 80, Training Loss: 0.5156048536300659\n",
      "Epoch: 928, Validation Loss: 1.2495721578598022\n",
      "Epoch: 929, Batch: 40, Training Loss: 0.5299769639968872\n",
      "Epoch: 929, Batch: 80, Training Loss: 0.5219571590423584\n",
      "Epoch: 929, Validation Loss: 1.1808851957321167\n",
      "Epoch: 930, Batch: 40, Training Loss: 0.5001637935638428\n",
      "Epoch: 930, Batch: 80, Training Loss: 0.5136953592300415\n",
      "Epoch: 930, Validation Loss: 1.2944691181182861\n",
      "Epoch: 931, Batch: 40, Training Loss: 0.4974331259727478\n",
      "Epoch: 931, Batch: 80, Training Loss: 0.564757227897644\n",
      "Epoch: 931, Validation Loss: 1.22353994846344\n",
      "Epoch: 932, Batch: 40, Training Loss: 0.5325291156768799\n",
      "Epoch: 932, Batch: 80, Training Loss: 0.5765921473503113\n",
      "Epoch: 932, Validation Loss: 1.1275520324707031\n",
      "Epoch: 933, Batch: 40, Training Loss: 0.4980419874191284\n",
      "Epoch: 933, Batch: 80, Training Loss: 0.4664756655693054\n",
      "Epoch: 933, Validation Loss: 0.9866220355033875\n",
      "Epoch: 934, Batch: 40, Training Loss: 0.5099139213562012\n",
      "Epoch: 934, Batch: 80, Training Loss: 0.5411942005157471\n",
      "Epoch: 934, Validation Loss: 1.156139612197876\n",
      "Epoch: 935, Batch: 40, Training Loss: 0.4995209276676178\n",
      "Epoch: 935, Batch: 80, Training Loss: 0.5054367184638977\n",
      "Epoch: 935, Validation Loss: 1.0818743705749512\n",
      "Epoch: 936, Batch: 40, Training Loss: 0.46560588479042053\n",
      "Epoch: 936, Batch: 80, Training Loss: 0.5162490010261536\n",
      "Epoch: 936, Validation Loss: 1.1944525241851807\n",
      "Epoch: 937, Batch: 40, Training Loss: 0.5178769826889038\n",
      "Epoch: 937, Batch: 80, Training Loss: 0.5237295031547546\n",
      "Epoch: 937, Validation Loss: 1.1330190896987915\n",
      "Epoch: 938, Batch: 40, Training Loss: 0.4373394846916199\n",
      "Epoch: 938, Batch: 80, Training Loss: 0.4899539649486542\n",
      "Epoch: 938, Validation Loss: 1.2806649208068848\n",
      "Epoch: 939, Batch: 40, Training Loss: 0.512569010257721\n",
      "Epoch: 939, Batch: 80, Training Loss: 0.38604822754859924\n",
      "Epoch: 939, Validation Loss: 1.3303529024124146\n",
      "Epoch: 940, Batch: 40, Training Loss: 0.5203030109405518\n",
      "Epoch: 940, Batch: 80, Training Loss: 0.5228714942932129\n",
      "Epoch: 940, Validation Loss: 1.2561476230621338\n",
      "Epoch: 941, Batch: 40, Training Loss: 0.5172396302223206\n",
      "Epoch: 941, Batch: 80, Training Loss: 0.5013471841812134\n",
      "Epoch: 941, Validation Loss: 1.28080153465271\n",
      "Epoch: 942, Batch: 40, Training Loss: 0.5937476754188538\n",
      "Epoch: 942, Batch: 80, Training Loss: 0.5259701609611511\n",
      "Epoch: 942, Validation Loss: 1.1212806701660156\n",
      "Epoch: 943, Batch: 40, Training Loss: 0.4547058641910553\n",
      "Epoch: 943, Batch: 80, Training Loss: 0.4987058639526367\n",
      "Epoch: 943, Validation Loss: 1.2267138957977295\n",
      "Epoch: 944, Batch: 40, Training Loss: 0.5069807767868042\n",
      "Epoch: 944, Batch: 80, Training Loss: 0.5597134232521057\n",
      "Epoch: 944, Validation Loss: 1.3489649295806885\n",
      "Epoch: 945, Batch: 40, Training Loss: 0.44580116868019104\n",
      "Epoch: 945, Batch: 80, Training Loss: 0.5545060038566589\n",
      "Epoch: 945, Validation Loss: 1.1949963569641113\n",
      "Epoch: 946, Batch: 40, Training Loss: 0.43207240104675293\n",
      "Epoch: 946, Batch: 80, Training Loss: 0.4872252345085144\n",
      "Epoch: 946, Validation Loss: 1.186396598815918\n",
      "Epoch: 947, Batch: 40, Training Loss: 0.45164987444877625\n",
      "Epoch: 947, Batch: 80, Training Loss: 0.5918771028518677\n",
      "Epoch: 947, Validation Loss: 1.2516639232635498\n",
      "Epoch: 948, Batch: 40, Training Loss: 0.4865432381629944\n",
      "Epoch: 948, Batch: 80, Training Loss: 0.48182833194732666\n",
      "Epoch: 948, Validation Loss: 1.2348918914794922\n",
      "Epoch: 949, Batch: 40, Training Loss: 0.47960999608039856\n",
      "Epoch: 949, Batch: 80, Training Loss: 0.44093433022499084\n",
      "Epoch: 949, Validation Loss: 1.3187509775161743\n",
      "Epoch: 950, Batch: 40, Training Loss: 0.4157326817512512\n",
      "Epoch: 950, Batch: 80, Training Loss: 0.5292310118675232\n",
      "Epoch: 950, Validation Loss: 1.1950922012329102\n",
      "Epoch: 951, Batch: 40, Training Loss: 0.4953831136226654\n",
      "Epoch: 951, Batch: 80, Training Loss: 0.4824700355529785\n",
      "Epoch: 951, Validation Loss: 1.2144180536270142\n",
      "Epoch: 952, Batch: 40, Training Loss: 0.4655744135379791\n",
      "Epoch: 952, Batch: 80, Training Loss: 0.474974662065506\n",
      "Epoch: 952, Validation Loss: 1.415555715560913\n",
      "Epoch: 953, Batch: 40, Training Loss: 0.5422674417495728\n",
      "Epoch: 953, Batch: 80, Training Loss: 0.5652731657028198\n",
      "Epoch: 953, Validation Loss: 1.1624807119369507\n",
      "Epoch: 954, Batch: 40, Training Loss: 0.5117831826210022\n",
      "Epoch: 954, Batch: 80, Training Loss: 0.5479145646095276\n",
      "Epoch: 954, Validation Loss: 1.340570330619812\n",
      "Epoch: 955, Batch: 40, Training Loss: 0.5940887928009033\n",
      "Epoch: 955, Batch: 80, Training Loss: 0.5860492587089539\n",
      "Epoch: 955, Validation Loss: 1.2136937379837036\n",
      "Epoch: 956, Batch: 40, Training Loss: 0.5455458760261536\n",
      "Epoch: 956, Batch: 80, Training Loss: 0.5056267976760864\n",
      "Epoch: 956, Validation Loss: 1.3705878257751465\n",
      "Epoch: 957, Batch: 40, Training Loss: 0.5153926014900208\n",
      "Epoch: 957, Batch: 80, Training Loss: 0.4558332860469818\n",
      "Epoch: 957, Validation Loss: 1.1845637559890747\n",
      "Epoch: 958, Batch: 40, Training Loss: 0.4970850646495819\n",
      "Epoch: 958, Batch: 80, Training Loss: 0.5271981358528137\n",
      "Epoch: 958, Validation Loss: 1.2124335765838623\n",
      "Epoch: 959, Batch: 40, Training Loss: 0.5118489265441895\n",
      "Epoch: 959, Batch: 80, Training Loss: 0.5556197762489319\n",
      "Epoch: 959, Validation Loss: 1.357917308807373\n",
      "Epoch: 960, Batch: 40, Training Loss: 0.477821946144104\n",
      "Epoch: 960, Batch: 80, Training Loss: 0.559799075126648\n",
      "Epoch: 960, Validation Loss: 1.326757550239563\n",
      "Epoch: 961, Batch: 40, Training Loss: 0.5329199433326721\n",
      "Epoch: 961, Batch: 80, Training Loss: 0.4620940089225769\n",
      "Epoch: 961, Validation Loss: 1.3269929885864258\n",
      "Epoch: 962, Batch: 40, Training Loss: 0.4517796039581299\n",
      "Epoch: 962, Batch: 80, Training Loss: 0.5056479573249817\n",
      "Epoch: 962, Validation Loss: 1.3346830606460571\n",
      "Epoch: 963, Batch: 40, Training Loss: 0.4616836905479431\n",
      "Epoch: 963, Batch: 80, Training Loss: 0.5159335732460022\n",
      "Epoch: 963, Validation Loss: 1.2327768802642822\n",
      "Epoch: 964, Batch: 40, Training Loss: 0.5942882299423218\n",
      "Epoch: 964, Batch: 80, Training Loss: 0.4982509911060333\n",
      "Epoch: 964, Validation Loss: 1.2396416664123535\n",
      "Epoch: 965, Batch: 40, Training Loss: 0.5502305626869202\n",
      "Epoch: 965, Batch: 80, Training Loss: 0.540760338306427\n",
      "Epoch: 965, Validation Loss: 1.2153445482254028\n",
      "Epoch: 966, Batch: 40, Training Loss: 0.5292213559150696\n",
      "Epoch: 966, Batch: 80, Training Loss: 0.5186996459960938\n",
      "Epoch: 966, Validation Loss: 1.2613502740859985\n",
      "Epoch: 967, Batch: 40, Training Loss: 0.5025639533996582\n",
      "Epoch: 967, Batch: 80, Training Loss: 0.5201175212860107\n",
      "Epoch: 967, Validation Loss: 1.1550424098968506\n",
      "Epoch: 968, Batch: 40, Training Loss: 0.5071806907653809\n",
      "Epoch: 968, Batch: 80, Training Loss: 0.4676379859447479\n",
      "Epoch: 968, Validation Loss: 1.3047879934310913\n",
      "Epoch: 969, Batch: 40, Training Loss: 0.6160522699356079\n",
      "Epoch: 969, Batch: 80, Training Loss: 0.49708524346351624\n",
      "Epoch: 969, Validation Loss: 1.1967918872833252\n",
      "Epoch: 970, Batch: 40, Training Loss: 0.5408816933631897\n",
      "Epoch: 970, Batch: 80, Training Loss: 0.4668760895729065\n",
      "Epoch: 970, Validation Loss: 1.3156810998916626\n",
      "Epoch: 971, Batch: 40, Training Loss: 0.452094703912735\n",
      "Epoch: 971, Batch: 80, Training Loss: 0.5202023983001709\n",
      "Epoch: 971, Validation Loss: 1.2465895414352417\n",
      "Epoch: 972, Batch: 40, Training Loss: 0.5433857440948486\n",
      "Epoch: 972, Batch: 80, Training Loss: 0.5540052056312561\n",
      "Epoch: 972, Validation Loss: 1.3445583581924438\n",
      "Epoch: 973, Batch: 40, Training Loss: 0.4545448124408722\n",
      "Epoch: 973, Batch: 80, Training Loss: 0.5252472162246704\n",
      "Epoch: 973, Validation Loss: 1.3701883554458618\n",
      "Epoch: 974, Batch: 40, Training Loss: 0.470543771982193\n",
      "Epoch: 974, Batch: 80, Training Loss: 0.4675803482532501\n",
      "Epoch: 974, Validation Loss: 1.217445731163025\n",
      "Epoch: 975, Batch: 40, Training Loss: 0.44965726137161255\n",
      "Epoch: 975, Batch: 80, Training Loss: 0.4911903738975525\n",
      "Epoch: 975, Validation Loss: 1.219050645828247\n",
      "Epoch: 976, Batch: 40, Training Loss: 0.5366936922073364\n",
      "Epoch: 976, Batch: 80, Training Loss: 0.4689423143863678\n",
      "Epoch: 976, Validation Loss: 1.3190968036651611\n",
      "Epoch: 977, Batch: 40, Training Loss: 0.4500500559806824\n",
      "Epoch: 977, Batch: 80, Training Loss: 0.4625570476055145\n",
      "Epoch: 977, Validation Loss: 1.3292070627212524\n",
      "Epoch: 978, Batch: 40, Training Loss: 0.5465279221534729\n",
      "Epoch: 978, Batch: 80, Training Loss: 0.46885761618614197\n",
      "Epoch: 978, Validation Loss: 1.1206761598587036\n",
      "Epoch: 979, Batch: 40, Training Loss: 0.5255295038223267\n",
      "Epoch: 979, Batch: 80, Training Loss: 0.5596196055412292\n",
      "Epoch: 979, Validation Loss: 1.2232837677001953\n",
      "Epoch: 980, Batch: 40, Training Loss: 0.5468278527259827\n",
      "Epoch: 980, Batch: 80, Training Loss: 0.5049186944961548\n",
      "Epoch: 980, Validation Loss: 1.3635599613189697\n",
      "Epoch: 981, Batch: 40, Training Loss: 0.5178767442703247\n",
      "Epoch: 981, Batch: 80, Training Loss: 0.5571371912956238\n",
      "Epoch: 981, Validation Loss: 1.111974835395813\n",
      "Epoch: 982, Batch: 40, Training Loss: 0.47411733865737915\n",
      "Epoch: 982, Batch: 80, Training Loss: 0.5439743399620056\n",
      "Epoch: 982, Validation Loss: 1.2245969772338867\n",
      "Epoch: 983, Batch: 40, Training Loss: 0.5366178154945374\n",
      "Epoch: 983, Batch: 80, Training Loss: 0.4981367588043213\n",
      "Epoch: 983, Validation Loss: 1.2537131309509277\n",
      "Epoch: 984, Batch: 40, Training Loss: 0.44190531969070435\n",
      "Epoch: 984, Batch: 80, Training Loss: 0.5831425786018372\n",
      "Epoch: 984, Validation Loss: 1.344914197921753\n",
      "Epoch: 985, Batch: 40, Training Loss: 0.5097692012786865\n",
      "Epoch: 985, Batch: 80, Training Loss: 0.5140913724899292\n",
      "Epoch: 985, Validation Loss: 1.1056920289993286\n",
      "Epoch: 986, Batch: 40, Training Loss: 0.44133269786834717\n",
      "Epoch: 986, Batch: 80, Training Loss: 0.5533391237258911\n",
      "Epoch: 986, Validation Loss: 1.1746547222137451\n",
      "Epoch: 987, Batch: 40, Training Loss: 0.5489175319671631\n",
      "Epoch: 987, Batch: 80, Training Loss: 0.5051462054252625\n",
      "Epoch: 987, Validation Loss: 1.3050868511199951\n",
      "Epoch: 988, Batch: 40, Training Loss: 0.5004059672355652\n",
      "Epoch: 988, Batch: 80, Training Loss: 0.3962250351905823\n",
      "Epoch: 988, Validation Loss: 1.0685056447982788\n",
      "Epoch: 989, Batch: 40, Training Loss: 0.5814798474311829\n",
      "Epoch: 989, Batch: 80, Training Loss: 0.5160895586013794\n",
      "Epoch: 989, Validation Loss: 1.3532686233520508\n",
      "Epoch: 990, Batch: 40, Training Loss: 0.5409153699874878\n",
      "Epoch: 990, Batch: 80, Training Loss: 0.49035218358039856\n",
      "Epoch: 990, Validation Loss: 1.1935322284698486\n",
      "Epoch: 991, Batch: 40, Training Loss: 0.47748851776123047\n",
      "Epoch: 991, Batch: 80, Training Loss: 0.5480894446372986\n",
      "Epoch: 991, Validation Loss: 1.045506238937378\n",
      "Epoch: 992, Batch: 40, Training Loss: 0.5239467024803162\n",
      "Epoch: 992, Batch: 80, Training Loss: 0.5377385020256042\n",
      "Epoch: 992, Validation Loss: 1.1796436309814453\n",
      "Epoch: 993, Batch: 40, Training Loss: 0.47689107060432434\n",
      "Epoch: 993, Batch: 80, Training Loss: 0.47560638189315796\n",
      "Epoch: 993, Validation Loss: 1.118049144744873\n",
      "Epoch: 994, Batch: 40, Training Loss: 0.4940580725669861\n",
      "Epoch: 994, Batch: 80, Training Loss: 0.5161059498786926\n",
      "Epoch: 994, Validation Loss: 1.2762514352798462\n",
      "Epoch: 995, Batch: 40, Training Loss: 0.5420305728912354\n",
      "Epoch: 995, Batch: 80, Training Loss: 0.46126216650009155\n",
      "Epoch: 995, Validation Loss: 1.2878605127334595\n",
      "Epoch: 996, Batch: 40, Training Loss: 0.5508934259414673\n",
      "Epoch: 996, Batch: 80, Training Loss: 0.49483251571655273\n",
      "Epoch: 996, Validation Loss: 1.258228063583374\n",
      "Epoch: 997, Batch: 40, Training Loss: 0.5790929198265076\n",
      "Epoch: 997, Batch: 80, Training Loss: 0.5773375630378723\n",
      "Epoch: 997, Validation Loss: 1.1803271770477295\n",
      "Epoch: 998, Batch: 40, Training Loss: 0.5229226350784302\n",
      "Epoch: 998, Batch: 80, Training Loss: 0.49029645323753357\n",
      "Epoch: 998, Validation Loss: 1.2414753437042236\n",
      "Epoch: 999, Batch: 40, Training Loss: 0.5206645131111145\n",
      "Epoch: 999, Batch: 80, Training Loss: 0.5173701047897339\n",
      "Epoch: 999, Validation Loss: 1.1905449628829956\n",
      "Training took: 18737.737994909286 seconds, or: 312.2956332484881 minutes!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Variables to track things\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "# accuracy of train_corr[0] = train_corr[0]*100 / len(train_data)\n",
    "train_corr = []\n",
    "valid_corr = []\n",
    "\n",
    "# Epoch loop\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_corr_count = 0\n",
    "    valid_corr_count = 0\n",
    "    # Batch training\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        # start our batches at 1: so batch numbers are in the range [1, batchsize] instead of [0, batchsize-1]\n",
    "        b += 1\n",
    "        # make a prediction on the batch\n",
    "        y_pred = cnn(X_train) # X_train is dimension [batch_size, 3, 32, 32], making y_pred [batchsize, 10]\n",
    "        # Find the loss using the loss function\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        # Computes the back-propagation for each parameter:\n",
    "        loss.backward()\n",
    "        # Applies the update for each parameter\n",
    "        optimizer.step()\n",
    "        # Cleanup step for Pytorch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Keep track of the accuracy of the predictions\n",
    "\n",
    "        # predicted class gives us the index of most probability: i.e. what class the NN predicts the img is\n",
    "        predicted_class = torch.max(y_pred.data, 1)[1]\n",
    "        # batch_corr_count gives us the number of correct guesses in the batch\n",
    "        batch_corr_count = (predicted_class == y_train).sum()\n",
    "        # add that to the total number of correct guesses in the epoch\n",
    "        train_corr_count += batch_corr_count\n",
    "\n",
    "        # Print something so we can monitor the progress of the training\n",
    "        if b % int(len(train_loader) / 2) == 0:\n",
    "            print(f'Epoch: {i}, Batch: {b}, Training Loss: {loss.item()}') # loss.item() = loss[0], which is the value of loss\n",
    "\n",
    "    # Add the final epoch accuracy and loss to train acc and train losses arrays\n",
    "    train_corr.append(train_corr_count)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # test on validation set: NO WEIGHT UPDATES\n",
    "    with torch.no_grad():\n",
    "        for b, (X_valid, y_valid) in enumerate(valid_loader):\n",
    "            y_pred = cnn(X_valid)\n",
    "            predicted_class = torch.max(y_pred.data, 1)[1]\n",
    "            batch_corr_count = (predicted_class == y_valid).sum()\n",
    "            valid_corr_count += batch_corr_count\n",
    "    # add final loss to valid_losses\n",
    "    loss = criterion(y_pred, y_valid)\n",
    "    valid_losses.append(loss)\n",
    "\n",
    "    # print something to monitor the training\n",
    "    print(f'Epoch: {i}, Validation Loss: {loss.item()}') # loss.item() = loss[0], which is the value of loss\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "total = end_time - start_time\n",
    "\n",
    "print(f'Training took: {total} seconds, or: {total/60} minutes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_losses)), [x.item() for x in train_losses])\n",
    "plt.title(\"Training Losses of Deep CNN\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(valid_losses)), [x.item() for x in valid_losses])\n",
    "plt.title(\"Validation Losses of Deep CNN\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: loss not converging, have to tune hyperparameters:\n",
    "- try greatly decreasing/increasing batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "learn_rate = 0.001\n",
    "epochs = 100 #4500\n",
    "# Greatly decrease batch size\n",
    "batch_size = 5000 # was 500: this is actually quite big\n",
    "\n",
    "# # Don't need to redefine this unless we change initial learning rate\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=learn_rate)\n",
    "# learn_rate\n",
    "\n",
    "# Don't need to redefine this unless we change batch size\n",
    "# The samplers we defined above is essentially the same as shuffle=True, except we needed to use them to split training and validation\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Retrain, keeping the training we have already done:\n",
    "- in Jupyter, have to keep the Python kernel open so the CNN object \"cnn\" retains the weights it learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 4, Training Loss: 0.521933913230896\n",
      "Epoch: 0, Batch: 8, Training Loss: 0.5042734742164612\n",
      "Epoch: 0, Validation Loss: 1.2724581956863403\n",
      "Epoch: 1, Batch: 4, Training Loss: 0.4931899905204773\n",
      "Epoch: 1, Batch: 8, Training Loss: 0.4853907823562622\n",
      "Epoch: 1, Validation Loss: 1.1778239011764526\n",
      "Epoch: 2, Batch: 4, Training Loss: 0.4855315089225769\n",
      "Epoch: 2, Batch: 8, Training Loss: 0.461322546005249\n",
      "Epoch: 2, Validation Loss: 1.1862319707870483\n",
      "Epoch: 3, Batch: 4, Training Loss: 0.44974061846733093\n",
      "Epoch: 3, Batch: 8, Training Loss: 0.4742584526538849\n",
      "Epoch: 3, Validation Loss: 1.1938141584396362\n",
      "Epoch: 4, Batch: 4, Training Loss: 0.4370748996734619\n",
      "Epoch: 4, Batch: 8, Training Loss: 0.4451095759868622\n",
      "Epoch: 4, Validation Loss: 1.1660250425338745\n",
      "Epoch: 5, Batch: 4, Training Loss: 0.4383254945278168\n",
      "Epoch: 5, Batch: 8, Training Loss: 0.4746823310852051\n",
      "Epoch: 5, Validation Loss: 1.206008791923523\n",
      "Epoch: 6, Batch: 4, Training Loss: 0.4221138656139374\n",
      "Epoch: 6, Batch: 8, Training Loss: 0.44994744658470154\n",
      "Epoch: 6, Validation Loss: 1.1713050603866577\n",
      "Epoch: 7, Batch: 4, Training Loss: 0.43615013360977173\n",
      "Epoch: 7, Batch: 8, Training Loss: 0.45905986428260803\n",
      "Epoch: 7, Validation Loss: 1.178359031677246\n",
      "Epoch: 8, Batch: 4, Training Loss: 0.44568783044815063\n",
      "Epoch: 8, Batch: 8, Training Loss: 0.46432363986968994\n",
      "Epoch: 8, Validation Loss: 1.1942801475524902\n",
      "Epoch: 9, Batch: 4, Training Loss: 0.4409933090209961\n",
      "Epoch: 9, Batch: 8, Training Loss: 0.46568724513053894\n",
      "Epoch: 9, Validation Loss: 1.185701608657837\n",
      "Epoch: 10, Batch: 4, Training Loss: 0.432034432888031\n",
      "Epoch: 10, Batch: 8, Training Loss: 0.4588671028614044\n",
      "Epoch: 10, Validation Loss: 1.1898325681686401\n",
      "Epoch: 11, Batch: 4, Training Loss: 0.43490615487098694\n",
      "Epoch: 11, Batch: 8, Training Loss: 0.4458230435848236\n",
      "Epoch: 11, Validation Loss: 1.1789730787277222\n",
      "Epoch: 12, Batch: 4, Training Loss: 0.4420625567436218\n",
      "Epoch: 12, Batch: 8, Training Loss: 0.43139326572418213\n",
      "Epoch: 12, Validation Loss: 1.167557954788208\n",
      "Epoch: 13, Batch: 4, Training Loss: 0.4375632405281067\n",
      "Epoch: 13, Batch: 8, Training Loss: 0.43578314781188965\n",
      "Epoch: 13, Validation Loss: 1.1557923555374146\n",
      "Epoch: 14, Batch: 4, Training Loss: 0.4390774369239807\n",
      "Epoch: 14, Batch: 8, Training Loss: 0.4432815909385681\n",
      "Epoch: 14, Validation Loss: 1.190487027168274\n",
      "Epoch: 15, Batch: 4, Training Loss: 0.44798609614372253\n",
      "Epoch: 15, Batch: 8, Training Loss: 0.418911337852478\n",
      "Epoch: 15, Validation Loss: 1.2203248739242554\n",
      "Epoch: 16, Batch: 4, Training Loss: 0.428912878036499\n",
      "Epoch: 16, Batch: 8, Training Loss: 0.45324453711509705\n",
      "Epoch: 16, Validation Loss: 1.1915338039398193\n",
      "Epoch: 17, Batch: 4, Training Loss: 0.4197120666503906\n",
      "Epoch: 17, Batch: 8, Training Loss: 0.42594170570373535\n",
      "Epoch: 17, Validation Loss: 1.232848882675171\n",
      "Epoch: 18, Batch: 4, Training Loss: 0.4316742718219757\n",
      "Epoch: 18, Batch: 8, Training Loss: 0.4280802309513092\n",
      "Epoch: 18, Validation Loss: 1.1891013383865356\n",
      "Epoch: 19, Batch: 4, Training Loss: 0.41830483078956604\n",
      "Epoch: 19, Batch: 8, Training Loss: 0.4310680627822876\n",
      "Epoch: 19, Validation Loss: 1.2258423566818237\n",
      "Epoch: 20, Batch: 4, Training Loss: 0.44518575072288513\n",
      "Epoch: 20, Batch: 8, Training Loss: 0.438676118850708\n",
      "Epoch: 20, Validation Loss: 1.1892017126083374\n",
      "Epoch: 21, Batch: 4, Training Loss: 0.42722806334495544\n",
      "Epoch: 21, Batch: 8, Training Loss: 0.44668707251548767\n",
      "Epoch: 21, Validation Loss: 1.2106213569641113\n",
      "Epoch: 22, Batch: 4, Training Loss: 0.44345131516456604\n",
      "Epoch: 22, Batch: 8, Training Loss: 0.42894765734672546\n",
      "Epoch: 22, Validation Loss: 1.2187470197677612\n",
      "Epoch: 23, Batch: 4, Training Loss: 0.42526543140411377\n",
      "Epoch: 23, Batch: 8, Training Loss: 0.4238255023956299\n",
      "Epoch: 23, Validation Loss: 1.1769713163375854\n",
      "Epoch: 24, Batch: 4, Training Loss: 0.42053690552711487\n",
      "Epoch: 24, Batch: 8, Training Loss: 0.4315476417541504\n",
      "Epoch: 24, Validation Loss: 1.2169597148895264\n",
      "Epoch: 25, Batch: 4, Training Loss: 0.43821996450424194\n",
      "Epoch: 25, Batch: 8, Training Loss: 0.42099329829216003\n",
      "Epoch: 25, Validation Loss: 1.220785140991211\n",
      "Epoch: 26, Batch: 4, Training Loss: 0.43795400857925415\n",
      "Epoch: 26, Batch: 8, Training Loss: 0.43506455421447754\n",
      "Epoch: 26, Validation Loss: 1.1966021060943604\n",
      "Epoch: 27, Batch: 4, Training Loss: 0.4510900378227234\n",
      "Epoch: 27, Batch: 8, Training Loss: 0.42676934599876404\n",
      "Epoch: 27, Validation Loss: 1.2173882722854614\n",
      "Epoch: 28, Batch: 4, Training Loss: 0.42645081877708435\n",
      "Epoch: 28, Batch: 8, Training Loss: 0.4268561601638794\n",
      "Epoch: 28, Validation Loss: 1.2279030084609985\n",
      "Epoch: 29, Batch: 4, Training Loss: 0.43567031621932983\n",
      "Epoch: 29, Batch: 8, Training Loss: 0.4346632957458496\n",
      "Epoch: 29, Validation Loss: 1.1974791288375854\n",
      "Epoch: 30, Batch: 4, Training Loss: 0.43933427333831787\n",
      "Epoch: 30, Batch: 8, Training Loss: 0.42880094051361084\n",
      "Epoch: 30, Validation Loss: 1.1741044521331787\n",
      "Epoch: 31, Batch: 4, Training Loss: 0.44150683283805847\n",
      "Epoch: 31, Batch: 8, Training Loss: 0.45015472173690796\n",
      "Epoch: 31, Validation Loss: 1.2106568813323975\n",
      "Epoch: 32, Batch: 4, Training Loss: 0.4314073324203491\n",
      "Epoch: 32, Batch: 8, Training Loss: 0.4229189455509186\n",
      "Epoch: 32, Validation Loss: 1.2223178148269653\n",
      "Epoch: 33, Batch: 4, Training Loss: 0.42081767320632935\n",
      "Epoch: 33, Batch: 8, Training Loss: 0.4292941987514496\n",
      "Epoch: 33, Validation Loss: 1.2151089906692505\n",
      "Epoch: 34, Batch: 4, Training Loss: 0.43276020884513855\n",
      "Epoch: 34, Batch: 8, Training Loss: 0.4147946238517761\n",
      "Epoch: 34, Validation Loss: 1.1999969482421875\n",
      "Epoch: 35, Batch: 4, Training Loss: 0.43044185638427734\n",
      "Epoch: 35, Batch: 8, Training Loss: 0.4249400496482849\n",
      "Epoch: 35, Validation Loss: 1.165954351425171\n",
      "Epoch: 36, Batch: 4, Training Loss: 0.4220588505268097\n",
      "Epoch: 36, Batch: 8, Training Loss: 0.43779146671295166\n",
      "Epoch: 36, Validation Loss: 1.2225157022476196\n",
      "Epoch: 37, Batch: 4, Training Loss: 0.43074068427085876\n",
      "Epoch: 37, Batch: 8, Training Loss: 0.4253280758857727\n",
      "Epoch: 37, Validation Loss: 1.2390960454940796\n",
      "Epoch: 38, Batch: 4, Training Loss: 0.4327961504459381\n",
      "Epoch: 38, Batch: 8, Training Loss: 0.41744178533554077\n",
      "Epoch: 38, Validation Loss: 1.2405248880386353\n",
      "Epoch: 39, Batch: 4, Training Loss: 0.4066247045993805\n",
      "Epoch: 39, Batch: 8, Training Loss: 0.42559829354286194\n",
      "Epoch: 39, Validation Loss: 1.2169510126113892\n",
      "Epoch: 40, Batch: 4, Training Loss: 0.42212164402008057\n",
      "Epoch: 40, Batch: 8, Training Loss: 0.41197896003723145\n",
      "Epoch: 40, Validation Loss: 1.2000123262405396\n",
      "Epoch: 41, Batch: 4, Training Loss: 0.4350796043872833\n",
      "Epoch: 41, Batch: 8, Training Loss: 0.42715004086494446\n",
      "Epoch: 41, Validation Loss: 1.1960786581039429\n",
      "Epoch: 42, Batch: 4, Training Loss: 0.4303039610385895\n",
      "Epoch: 42, Batch: 8, Training Loss: 0.42895981669425964\n",
      "Epoch: 42, Validation Loss: 1.227669596672058\n",
      "Epoch: 43, Batch: 4, Training Loss: 0.4188716411590576\n",
      "Epoch: 43, Batch: 8, Training Loss: 0.423859179019928\n",
      "Epoch: 43, Validation Loss: 1.2342047691345215\n",
      "Epoch: 44, Batch: 4, Training Loss: 0.41413480043411255\n",
      "Epoch: 44, Batch: 8, Training Loss: 0.43768033385276794\n",
      "Epoch: 44, Validation Loss: 1.207879900932312\n",
      "Epoch: 45, Batch: 4, Training Loss: 0.4363109767436981\n",
      "Epoch: 45, Batch: 8, Training Loss: 0.4195955991744995\n",
      "Epoch: 45, Validation Loss: 1.2112635374069214\n",
      "Epoch: 46, Batch: 4, Training Loss: 0.43096962571144104\n",
      "Epoch: 46, Batch: 8, Training Loss: 0.4430578649044037\n",
      "Epoch: 46, Validation Loss: 1.1919245719909668\n",
      "Epoch: 47, Batch: 4, Training Loss: 0.4084108769893646\n",
      "Epoch: 47, Batch: 8, Training Loss: 0.42180731892585754\n",
      "Epoch: 47, Validation Loss: 1.1944022178649902\n",
      "Epoch: 48, Batch: 4, Training Loss: 0.4084358215332031\n",
      "Epoch: 48, Batch: 8, Training Loss: 0.4205124080181122\n",
      "Epoch: 48, Validation Loss: 1.2471896409988403\n",
      "Epoch: 49, Batch: 4, Training Loss: 0.4194914698600769\n",
      "Epoch: 49, Batch: 8, Training Loss: 0.4142094850540161\n",
      "Epoch: 49, Validation Loss: 1.2266892194747925\n",
      "Epoch: 50, Batch: 4, Training Loss: 0.43866968154907227\n",
      "Epoch: 50, Batch: 8, Training Loss: 0.41472315788269043\n",
      "Epoch: 50, Validation Loss: 1.1809072494506836\n",
      "Epoch: 51, Batch: 4, Training Loss: 0.42075487971305847\n",
      "Epoch: 51, Batch: 8, Training Loss: 0.4219730496406555\n",
      "Epoch: 51, Validation Loss: 1.2207111120224\n",
      "Epoch: 52, Batch: 4, Training Loss: 0.42970678210258484\n",
      "Epoch: 52, Batch: 8, Training Loss: 0.4453405737876892\n",
      "Epoch: 52, Validation Loss: 1.2048345804214478\n",
      "Epoch: 53, Batch: 4, Training Loss: 0.41084930300712585\n",
      "Epoch: 53, Batch: 8, Training Loss: 0.4036567509174347\n",
      "Epoch: 53, Validation Loss: 1.2102856636047363\n",
      "Epoch: 54, Batch: 4, Training Loss: 0.41727128624916077\n",
      "Epoch: 54, Batch: 8, Training Loss: 0.4274793565273285\n",
      "Epoch: 54, Validation Loss: 1.2264646291732788\n",
      "Epoch: 55, Batch: 4, Training Loss: 0.4226338863372803\n",
      "Epoch: 55, Batch: 8, Training Loss: 0.42211011052131653\n",
      "Epoch: 55, Validation Loss: 1.2270076274871826\n",
      "Epoch: 56, Batch: 4, Training Loss: 0.42901474237442017\n",
      "Epoch: 56, Batch: 8, Training Loss: 0.40505874156951904\n",
      "Epoch: 56, Validation Loss: 1.2672921419143677\n",
      "Epoch: 57, Batch: 4, Training Loss: 0.4219728410243988\n",
      "Epoch: 57, Batch: 8, Training Loss: 0.43828433752059937\n",
      "Epoch: 57, Validation Loss: 1.2379783391952515\n",
      "Epoch: 58, Batch: 4, Training Loss: 0.44904008507728577\n",
      "Epoch: 58, Batch: 8, Training Loss: 0.4302118718624115\n",
      "Epoch: 58, Validation Loss: 1.2162349224090576\n",
      "Epoch: 59, Batch: 4, Training Loss: 0.4346170425415039\n",
      "Epoch: 59, Batch: 8, Training Loss: 0.3980284035205841\n",
      "Epoch: 59, Validation Loss: 1.237200140953064\n",
      "Epoch: 60, Batch: 4, Training Loss: 0.41362425684928894\n",
      "Epoch: 60, Batch: 8, Training Loss: 0.4345043897628784\n",
      "Epoch: 60, Validation Loss: 1.193304181098938\n",
      "Epoch: 61, Batch: 4, Training Loss: 0.41923168301582336\n",
      "Epoch: 61, Batch: 8, Training Loss: 0.42437538504600525\n",
      "Epoch: 61, Validation Loss: 1.1996229887008667\n",
      "Epoch: 62, Batch: 4, Training Loss: 0.41041919589042664\n",
      "Epoch: 62, Batch: 8, Training Loss: 0.4413937032222748\n",
      "Epoch: 62, Validation Loss: 1.2463175058364868\n",
      "Epoch: 63, Batch: 4, Training Loss: 0.4286385178565979\n",
      "Epoch: 63, Batch: 8, Training Loss: 0.4213252365589142\n",
      "Epoch: 63, Validation Loss: 1.2441354990005493\n",
      "Epoch: 64, Batch: 4, Training Loss: 0.42736607789993286\n",
      "Epoch: 64, Batch: 8, Training Loss: 0.43025293946266174\n",
      "Epoch: 64, Validation Loss: 1.2537047863006592\n",
      "Epoch: 65, Batch: 4, Training Loss: 0.3959413468837738\n",
      "Epoch: 65, Batch: 8, Training Loss: 0.4126069247722626\n",
      "Epoch: 65, Validation Loss: 1.2375783920288086\n",
      "Epoch: 66, Batch: 4, Training Loss: 0.42512139678001404\n",
      "Epoch: 66, Batch: 8, Training Loss: 0.4140453636646271\n",
      "Epoch: 66, Validation Loss: 1.230530858039856\n",
      "Epoch: 67, Batch: 4, Training Loss: 0.4394707977771759\n",
      "Epoch: 67, Batch: 8, Training Loss: 0.4111054539680481\n",
      "Epoch: 67, Validation Loss: 1.1847399473190308\n",
      "Epoch: 68, Batch: 4, Training Loss: 0.42292100191116333\n",
      "Epoch: 68, Batch: 8, Training Loss: 0.41440102458000183\n",
      "Epoch: 68, Validation Loss: 1.20817232131958\n",
      "Epoch: 69, Batch: 4, Training Loss: 0.4208260178565979\n",
      "Epoch: 69, Batch: 8, Training Loss: 0.3917314112186432\n",
      "Epoch: 69, Validation Loss: 1.206376314163208\n",
      "Epoch: 70, Batch: 4, Training Loss: 0.415623277425766\n",
      "Epoch: 70, Batch: 8, Training Loss: 0.4251610338687897\n",
      "Epoch: 70, Validation Loss: 1.2172759771347046\n",
      "Epoch: 71, Batch: 4, Training Loss: 0.42483335733413696\n",
      "Epoch: 71, Batch: 8, Training Loss: 0.43134477734565735\n",
      "Epoch: 71, Validation Loss: 1.2354907989501953\n",
      "Epoch: 72, Batch: 4, Training Loss: 0.42948007583618164\n",
      "Epoch: 72, Batch: 8, Training Loss: 0.42877694964408875\n",
      "Epoch: 72, Validation Loss: 1.245701551437378\n",
      "Epoch: 73, Batch: 4, Training Loss: 0.4184655249118805\n",
      "Epoch: 73, Batch: 8, Training Loss: 0.4127434194087982\n",
      "Epoch: 73, Validation Loss: 1.2514806985855103\n",
      "Epoch: 74, Batch: 4, Training Loss: 0.4124966859817505\n",
      "Epoch: 74, Batch: 8, Training Loss: 0.40667805075645447\n",
      "Epoch: 74, Validation Loss: 1.2610670328140259\n",
      "Epoch: 75, Batch: 4, Training Loss: 0.4281079173088074\n",
      "Epoch: 75, Batch: 8, Training Loss: 0.4256942868232727\n",
      "Epoch: 75, Validation Loss: 1.1980798244476318\n",
      "Epoch: 76, Batch: 4, Training Loss: 0.40354666113853455\n",
      "Epoch: 76, Batch: 8, Training Loss: 0.4220580458641052\n",
      "Epoch: 76, Validation Loss: 1.243658423423767\n",
      "Epoch: 77, Batch: 4, Training Loss: 0.42413145303726196\n",
      "Epoch: 77, Batch: 8, Training Loss: 0.41727447509765625\n",
      "Epoch: 77, Validation Loss: 1.2464783191680908\n",
      "Epoch: 78, Batch: 4, Training Loss: 0.43826210498809814\n",
      "Epoch: 78, Batch: 8, Training Loss: 0.4109385311603546\n",
      "Epoch: 78, Validation Loss: 1.240018606185913\n",
      "Epoch: 79, Batch: 4, Training Loss: 0.4178982079029083\n",
      "Epoch: 79, Batch: 8, Training Loss: 0.41965463757514954\n",
      "Epoch: 79, Validation Loss: 1.240371823310852\n",
      "Epoch: 80, Batch: 4, Training Loss: 0.41727110743522644\n",
      "Epoch: 80, Batch: 8, Training Loss: 0.4134243130683899\n",
      "Epoch: 80, Validation Loss: 1.2567373514175415\n",
      "Epoch: 81, Batch: 4, Training Loss: 0.42121654748916626\n",
      "Epoch: 81, Batch: 8, Training Loss: 0.419080913066864\n",
      "Epoch: 81, Validation Loss: 1.2159109115600586\n",
      "Epoch: 82, Batch: 4, Training Loss: 0.41983795166015625\n",
      "Epoch: 82, Batch: 8, Training Loss: 0.4040297269821167\n",
      "Epoch: 82, Validation Loss: 1.2325890064239502\n",
      "Epoch: 83, Batch: 4, Training Loss: 0.4045052230358124\n",
      "Epoch: 83, Batch: 8, Training Loss: 0.4300037622451782\n",
      "Epoch: 83, Validation Loss: 1.2198312282562256\n",
      "Epoch: 84, Batch: 4, Training Loss: 0.40538620948791504\n",
      "Epoch: 84, Batch: 8, Training Loss: 0.40214982628822327\n",
      "Epoch: 84, Validation Loss: 1.23091721534729\n",
      "Epoch: 85, Batch: 4, Training Loss: 0.4096360206604004\n",
      "Epoch: 85, Batch: 8, Training Loss: 0.4217679798603058\n",
      "Epoch: 85, Validation Loss: 1.233078956604004\n",
      "Epoch: 86, Batch: 4, Training Loss: 0.42402392625808716\n",
      "Epoch: 86, Batch: 8, Training Loss: 0.41360634565353394\n",
      "Epoch: 86, Validation Loss: 1.235032558441162\n",
      "Epoch: 87, Batch: 4, Training Loss: 0.4412350058555603\n",
      "Epoch: 87, Batch: 8, Training Loss: 0.4190322756767273\n",
      "Epoch: 87, Validation Loss: 1.2386583089828491\n",
      "Epoch: 88, Batch: 4, Training Loss: 0.4437248408794403\n",
      "Epoch: 88, Batch: 8, Training Loss: 0.4309104382991791\n",
      "Epoch: 88, Validation Loss: 1.266906499862671\n",
      "Epoch: 89, Batch: 4, Training Loss: 0.42314207553863525\n",
      "Epoch: 89, Batch: 8, Training Loss: 0.4129239320755005\n",
      "Epoch: 89, Validation Loss: 1.2059825658798218\n",
      "Epoch: 90, Batch: 4, Training Loss: 0.42194780707359314\n",
      "Epoch: 90, Batch: 8, Training Loss: 0.4160768985748291\n",
      "Epoch: 90, Validation Loss: 1.2096387147903442\n",
      "Epoch: 91, Batch: 4, Training Loss: 0.43658867478370667\n",
      "Epoch: 91, Batch: 8, Training Loss: 0.42909327149391174\n",
      "Epoch: 91, Validation Loss: 1.2494633197784424\n",
      "Epoch: 92, Batch: 4, Training Loss: 0.41992685198783875\n",
      "Epoch: 92, Batch: 8, Training Loss: 0.41614145040512085\n",
      "Epoch: 92, Validation Loss: 1.1946252584457397\n",
      "Epoch: 93, Batch: 4, Training Loss: 0.4095135033130646\n",
      "Epoch: 93, Batch: 8, Training Loss: 0.40371859073638916\n",
      "Epoch: 93, Validation Loss: 1.2770593166351318\n",
      "Epoch: 94, Batch: 4, Training Loss: 0.4139784574508667\n",
      "Epoch: 94, Batch: 8, Training Loss: 0.41074681282043457\n",
      "Epoch: 94, Validation Loss: 1.2391753196716309\n",
      "Epoch: 95, Batch: 4, Training Loss: 0.43111446499824524\n",
      "Epoch: 95, Batch: 8, Training Loss: 0.43501514196395874\n",
      "Epoch: 95, Validation Loss: 1.247641682624817\n",
      "Epoch: 96, Batch: 4, Training Loss: 0.4239700138568878\n",
      "Epoch: 96, Batch: 8, Training Loss: 0.40322133898735046\n",
      "Epoch: 96, Validation Loss: 1.2452120780944824\n",
      "Epoch: 97, Batch: 4, Training Loss: 0.40857550501823425\n",
      "Epoch: 97, Batch: 8, Training Loss: 0.41377729177474976\n",
      "Epoch: 97, Validation Loss: 1.2726362943649292\n",
      "Epoch: 98, Batch: 4, Training Loss: 0.4204208552837372\n",
      "Epoch: 98, Batch: 8, Training Loss: 0.42124199867248535\n",
      "Epoch: 98, Validation Loss: 1.2474340200424194\n",
      "Epoch: 99, Batch: 4, Training Loss: 0.4296628534793854\n",
      "Epoch: 99, Batch: 8, Training Loss: 0.42052581906318665\n",
      "Epoch: 99, Validation Loss: 1.2593508958816528\n",
      "Training took: 1698.8898539543152 seconds, or: 28.314830899238586 minutes!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Variables to track things\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "# accuracy of train_corr[0] = train_corr[0]*100 / len(train_data)\n",
    "train_corr = []\n",
    "valid_corr = []\n",
    "\n",
    "# Epoch loop\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_corr_count = 0\n",
    "    valid_corr_count = 0\n",
    "    # Batch training\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        # start our batches at 1: so batch numbers are in the range [1, batchsize] instead of [0, batchsize-1]\n",
    "        b += 1\n",
    "        # make a prediction on the batch\n",
    "        y_pred = cnn(X_train) # X_train is dimension [batch_size, 3, 32, 32], making y_pred [batchsize, 10]\n",
    "        # Find the loss using the loss function\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        # Computes the back-propagation for each parameter:\n",
    "        loss.backward()\n",
    "        # Applies the update for each parameter\n",
    "        optimizer.step()\n",
    "        # Cleanup step for Pytorch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Keep track of the accuracy of the predictions\n",
    "\n",
    "        # predicted class gives us the index of most probability: i.e. what class the NN predicts the img is\n",
    "        predicted_class = torch.max(y_pred.data, 1)[1]\n",
    "        # batch_corr_count gives us the number of correct guesses in the batch\n",
    "        batch_corr_count = (predicted_class == y_train).sum()\n",
    "        # add that to the total number of correct guesses in the epoch\n",
    "        train_corr_count += batch_corr_count\n",
    "\n",
    "        # Print something so we can monitor the progress of the training\n",
    "        if b % int(len(train_loader) / 2) == 0:\n",
    "            print(f'Epoch: {i}, Batch: {b}, Training Loss: {loss.item()}') # loss.item() = loss[0], which is the value of loss\n",
    "\n",
    "    # Add the final epoch accuracy and loss to train acc and train losses arrays\n",
    "    train_corr.append(train_corr_count)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # test on validation set: NO WEIGHT UPDATES\n",
    "    with torch.no_grad():\n",
    "        for b, (X_valid, y_valid) in enumerate(valid_loader):\n",
    "            y_pred = cnn(X_valid)\n",
    "            predicted_class = torch.max(y_pred.data, 1)[1]\n",
    "            batch_corr_count = (predicted_class == y_valid).sum()\n",
    "            valid_corr_count += batch_corr_count\n",
    "    # add final loss to valid_losses\n",
    "    loss = criterion(y_pred, y_valid)\n",
    "    valid_losses.append(loss)\n",
    "\n",
    "    # print something to monitor the training\n",
    "    print(f'Epoch: {i}, Validation Loss: {loss.item()}') # loss.item() = loss[0], which is the value of loss\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "total = end_time - start_time\n",
    "\n",
    "print(f'Training took: {total} seconds, or: {total/60} minutes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_losses)), [x.item() for x in train_losses])\n",
    "plt.title(\"Training Losses of Deep CNN\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(valid_losses)), [x.item() for x in valid_losses])\n",
    "plt.title(\"Validation Losses of Deep CNN\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loss is decreasing, but the validation loss is increasing:\n",
    "- the model is \"memorizing\" the training data: the model is biased\n",
    "- this means the model is overfitting\n",
    "- why?\n",
    "    - likely, not enough data (50,000) for the size of CNN we made\n",
    "    - i.e. the CNN is too big\n",
    "- maybe class distribution in training data is skewed?\n",
    "    - not the case as seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 486, 1: 489, 2: 505, 3: 512, 4: 484, 5: 527, 6: 474, 7: 493, 8: 501, 9: 529}\n",
      "{0: 985, 1: 985, 2: 988, 3: 1048, 4: 998, 5: 1029, 6: 978, 7: 994, 8: 972, 9: 1023}\n",
      "{0: 1495, 1: 1489, 2: 1496, 3: 1537, 4: 1474, 5: 1534, 6: 1457, 7: 1496, 8: 1514, 9: 1508}\n",
      "{0: 2003, 1: 1953, 2: 1976, 3: 2020, 4: 1972, 5: 2062, 6: 1985, 7: 2002, 8: 2049, 9: 1978}\n",
      "{0: 2487, 1: 2475, 2: 2480, 3: 2530, 4: 2477, 5: 2539, 6: 2490, 7: 2483, 8: 2549, 9: 2490}\n",
      "{0: 2964, 1: 2985, 2: 2989, 3: 3022, 4: 2974, 5: 3041, 6: 2991, 7: 2989, 8: 3023, 9: 3022}\n",
      "{0: 3481, 1: 3523, 2: 3458, 3: 3500, 4: 3510, 5: 3522, 6: 3508, 7: 3463, 8: 3505, 9: 3530}\n",
      "{0: 4014, 1: 4014, 2: 3962, 3: 4011, 4: 3993, 5: 4005, 6: 4013, 7: 3988, 8: 4022, 9: 3978}\n"
     ]
    }
   ],
   "source": [
    "classes = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
    "\n",
    "for b, (X_train, y_train) in enumerate(train_loader):\n",
    "    for item in y_train:\n",
    "        for c in classes.keys():\n",
    "            if c == int(item):\n",
    "                classes[c] += 1\n",
    "\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen: this model does not generalize!\n",
    "\n",
    "Suggestions: \n",
    "- decrease learning rate, increase batch size\n",
    "- the validation loss is noisy, but is small at some points:\n",
    "    - save the weights of the iterations with the best validation loss minimization performance, and try making predictions on the test set with those three models\n",
    "        - could yield decent results \n",
    "- use learning rate scheduling\n",
    "    - decrease learning rate with each epoch number\n",
    "- making a shallower NN\n",
    "    - there might not be enough data to train a big NN: Deep NN's need lots of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to save a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_32152\\3797122439.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  my_model_loaded.load_state_dict(torch.load(\"my_model.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(cnn.state_dict(), 'my_model.pt')\n",
    "\n",
    "# Load the model\n",
    "my_model_loaded = CNN()\n",
    "my_model_loaded.load_state_dict(torch.load(\"my_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decrease learning rate and increase batch size. We'll also decrease epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "learn_rate = 0.0005\n",
    "epochs = 100 #4500\n",
    "# Greatly decrease batch size\n",
    "batch_size = 5000 # was 500: this is actually quite big\n",
    "\n",
    "# # Don't need to redefine this unless we change initial learning rate\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=learn_rate)\n",
    "# learn_rate\n",
    "\n",
    "# Don't need to redefine this unless we change batch size\n",
    "# The samplers we defined above is essentially the same as shuffle=True, except we needed to use them to split training and validation\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try the same, large CNN and save the best 3 models:\n",
    "- use a new instance of the CNN( i.e. discard the previous weight training, train from scratch) since we arent getting good validation loss\n",
    "- scrapped this for now, we will use a smaller cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 4, Training Loss: 0.40968531370162964\n",
      "Epoch: 0, Batch: 8, Training Loss: 0.4094444215297699\n",
      "Epoch: 0, Validation Loss: 1.239349126815796\n",
      "Epoch: 1, Batch: 4, Training Loss: 0.4293288588523865\n",
      "Epoch: 1, Batch: 8, Training Loss: 0.40665626525878906\n",
      "Epoch: 1, Validation Loss: 1.2111397981643677\n",
      "Epoch: 2, Batch: 4, Training Loss: 0.3954826593399048\n",
      "Epoch: 2, Batch: 8, Training Loss: 0.42409542202949524\n",
      "Epoch: 2, Validation Loss: 1.2398014068603516\n",
      "Epoch: 3, Batch: 4, Training Loss: 0.4276799261569977\n",
      "Epoch: 3, Batch: 8, Training Loss: 0.4240001440048218\n",
      "Epoch: 3, Validation Loss: 1.2203418016433716\n",
      "Epoch: 4, Batch: 4, Training Loss: 0.4071558713912964\n",
      "Epoch: 4, Batch: 8, Training Loss: 0.39736735820770264\n",
      "Epoch: 4, Validation Loss: 1.2129671573638916\n",
      "Epoch: 5, Batch: 4, Training Loss: 0.4224494695663452\n",
      "Epoch: 5, Batch: 8, Training Loss: 0.4326253831386566\n",
      "Epoch: 5, Validation Loss: 1.2781124114990234\n",
      "Epoch: 6, Batch: 4, Training Loss: 0.4167087972164154\n",
      "Epoch: 6, Batch: 8, Training Loss: 0.4067222476005554\n",
      "Epoch: 6, Validation Loss: 1.2502185106277466\n",
      "Epoch: 7, Batch: 4, Training Loss: 0.4114210307598114\n",
      "Epoch: 7, Batch: 8, Training Loss: 0.4162435531616211\n",
      "Epoch: 7, Validation Loss: 1.2732367515563965\n",
      "Epoch: 8, Batch: 4, Training Loss: 0.4378899335861206\n",
      "Epoch: 8, Batch: 8, Training Loss: 0.4162774980068207\n",
      "Epoch: 8, Validation Loss: 1.2322129011154175\n",
      "Epoch: 9, Batch: 4, Training Loss: 0.4213418960571289\n",
      "Epoch: 9, Batch: 8, Training Loss: 0.40198561549186707\n",
      "Epoch: 9, Validation Loss: 1.2465174198150635\n",
      "Epoch: 10, Batch: 4, Training Loss: 0.4306109845638275\n",
      "Epoch: 10, Batch: 8, Training Loss: 0.4218500852584839\n",
      "Epoch: 10, Validation Loss: 1.2283977270126343\n",
      "Epoch: 11, Batch: 4, Training Loss: 0.4225166141986847\n",
      "Epoch: 11, Batch: 8, Training Loss: 0.3953869044780731\n",
      "Epoch: 11, Validation Loss: 1.2449047565460205\n",
      "Epoch: 12, Batch: 4, Training Loss: 0.40857765078544617\n",
      "Epoch: 12, Batch: 8, Training Loss: 0.4592013657093048\n",
      "Epoch: 12, Validation Loss: 1.2378063201904297\n",
      "Epoch: 13, Batch: 4, Training Loss: 0.41911235451698303\n",
      "Epoch: 13, Batch: 8, Training Loss: 0.4166814982891083\n",
      "Epoch: 13, Validation Loss: 1.2571896314620972\n",
      "Epoch: 14, Batch: 4, Training Loss: 0.4111901819705963\n",
      "Epoch: 14, Batch: 8, Training Loss: 0.4184431731700897\n",
      "Epoch: 14, Validation Loss: 1.2005504369735718\n",
      "Epoch: 15, Batch: 4, Training Loss: 0.42975249886512756\n",
      "Epoch: 15, Batch: 8, Training Loss: 0.4071688950061798\n",
      "Epoch: 15, Validation Loss: 1.2404309511184692\n",
      "Epoch: 16, Batch: 4, Training Loss: 0.4076438844203949\n",
      "Epoch: 16, Batch: 8, Training Loss: 0.4257766604423523\n",
      "Epoch: 16, Validation Loss: 1.2768605947494507\n",
      "Epoch: 17, Batch: 4, Training Loss: 0.4326156675815582\n",
      "Epoch: 17, Batch: 8, Training Loss: 0.40875768661499023\n",
      "Epoch: 17, Validation Loss: 1.277214765548706\n",
      "Epoch: 18, Batch: 4, Training Loss: 0.41957953572273254\n",
      "Epoch: 18, Batch: 8, Training Loss: 0.4227519631385803\n",
      "Epoch: 18, Validation Loss: 1.2663925886154175\n",
      "Epoch: 19, Batch: 4, Training Loss: 0.4234309196472168\n",
      "Epoch: 19, Batch: 8, Training Loss: 0.41440239548683167\n",
      "Epoch: 19, Validation Loss: 1.2731802463531494\n",
      "Epoch: 20, Batch: 4, Training Loss: 0.44335585832595825\n",
      "Epoch: 20, Batch: 8, Training Loss: 0.40059220790863037\n",
      "Epoch: 20, Validation Loss: 1.2269684076309204\n",
      "Epoch: 21, Batch: 4, Training Loss: 0.41881245374679565\n",
      "Epoch: 21, Batch: 8, Training Loss: 0.40813273191452026\n",
      "Epoch: 21, Validation Loss: 1.2303040027618408\n",
      "Epoch: 22, Batch: 4, Training Loss: 0.4276806116104126\n",
      "Epoch: 22, Batch: 8, Training Loss: 0.41315996646881104\n",
      "Epoch: 22, Validation Loss: 1.2608177661895752\n",
      "Epoch: 23, Batch: 4, Training Loss: 0.4136062562465668\n",
      "Epoch: 23, Batch: 8, Training Loss: 0.41717109084129333\n",
      "Epoch: 23, Validation Loss: 1.2347619533538818\n",
      "Epoch: 24, Batch: 4, Training Loss: 0.4190421402454376\n",
      "Epoch: 24, Batch: 8, Training Loss: 0.4073675870895386\n",
      "Epoch: 24, Validation Loss: 1.2822153568267822\n",
      "Epoch: 25, Batch: 4, Training Loss: 0.42176273465156555\n",
      "Epoch: 25, Batch: 8, Training Loss: 0.3980633616447449\n",
      "Epoch: 25, Validation Loss: 1.215369701385498\n",
      "Epoch: 26, Batch: 4, Training Loss: 0.39194974303245544\n",
      "Epoch: 26, Batch: 8, Training Loss: 0.416885107755661\n",
      "Epoch: 26, Validation Loss: 1.2438770532608032\n",
      "Epoch: 27, Batch: 4, Training Loss: 0.3930681347846985\n",
      "Epoch: 27, Batch: 8, Training Loss: 0.4290923476219177\n",
      "Epoch: 27, Validation Loss: 1.2239891290664673\n",
      "Epoch: 28, Batch: 4, Training Loss: 0.4132768213748932\n",
      "Epoch: 28, Batch: 8, Training Loss: 0.42536699771881104\n",
      "Epoch: 28, Validation Loss: 1.2428462505340576\n",
      "Epoch: 29, Batch: 4, Training Loss: 0.4068886339664459\n",
      "Epoch: 29, Batch: 8, Training Loss: 0.4229477643966675\n",
      "Epoch: 29, Validation Loss: 1.26870858669281\n",
      "Epoch: 30, Batch: 4, Training Loss: 0.4180154800415039\n",
      "Epoch: 30, Batch: 8, Training Loss: 0.4131438434123993\n",
      "Epoch: 30, Validation Loss: 1.2433373928070068\n",
      "Epoch: 31, Batch: 4, Training Loss: 0.4072810411453247\n",
      "Epoch: 31, Batch: 8, Training Loss: 0.427631139755249\n",
      "Epoch: 31, Validation Loss: 1.3008570671081543\n",
      "Epoch: 32, Batch: 4, Training Loss: 0.42049673199653625\n",
      "Epoch: 32, Batch: 8, Training Loss: 0.4133923351764679\n",
      "Epoch: 32, Validation Loss: 1.267726182937622\n",
      "Epoch: 33, Batch: 4, Training Loss: 0.4164697825908661\n",
      "Epoch: 33, Batch: 8, Training Loss: 0.41714346408843994\n",
      "Epoch: 33, Validation Loss: 1.232201337814331\n",
      "Epoch: 34, Batch: 4, Training Loss: 0.4334394633769989\n",
      "Epoch: 34, Batch: 8, Training Loss: 0.42279043793678284\n",
      "Epoch: 34, Validation Loss: 1.2175395488739014\n",
      "Epoch: 35, Batch: 4, Training Loss: 0.41055482625961304\n",
      "Epoch: 35, Batch: 8, Training Loss: 0.4172065556049347\n",
      "Epoch: 35, Validation Loss: 1.2433154582977295\n",
      "Epoch: 36, Batch: 4, Training Loss: 0.42417627573013306\n",
      "Epoch: 36, Batch: 8, Training Loss: 0.4183301329612732\n",
      "Epoch: 36, Validation Loss: 1.227317452430725\n",
      "Epoch: 37, Batch: 4, Training Loss: 0.41214150190353394\n",
      "Epoch: 37, Batch: 8, Training Loss: 0.4093984067440033\n",
      "Epoch: 37, Validation Loss: 1.24722421169281\n",
      "Epoch: 38, Batch: 4, Training Loss: 0.41463857889175415\n",
      "Epoch: 38, Batch: 8, Training Loss: 0.4334089457988739\n",
      "Epoch: 38, Validation Loss: 1.2212655544281006\n",
      "Epoch: 39, Batch: 4, Training Loss: 0.4366368055343628\n",
      "Epoch: 39, Batch: 8, Training Loss: 0.41519132256507874\n",
      "Epoch: 39, Validation Loss: 1.2237756252288818\n",
      "Epoch: 40, Batch: 4, Training Loss: 0.4202965199947357\n",
      "Epoch: 40, Batch: 8, Training Loss: 0.4242391586303711\n",
      "Epoch: 40, Validation Loss: 1.2483123540878296\n",
      "Epoch: 41, Batch: 4, Training Loss: 0.3966270089149475\n",
      "Epoch: 41, Batch: 8, Training Loss: 0.40606099367141724\n",
      "Epoch: 41, Validation Loss: 1.2395226955413818\n",
      "Epoch: 42, Batch: 4, Training Loss: 0.4229015111923218\n",
      "Epoch: 42, Batch: 8, Training Loss: 0.3947773873806\n",
      "Epoch: 42, Validation Loss: 1.260248064994812\n",
      "Epoch: 43, Batch: 4, Training Loss: 0.43980181217193604\n",
      "Epoch: 43, Batch: 8, Training Loss: 0.4243144094944\n",
      "Epoch: 43, Validation Loss: 1.211388349533081\n",
      "Epoch: 44, Batch: 4, Training Loss: 0.4161219596862793\n",
      "Epoch: 44, Batch: 8, Training Loss: 0.4100833535194397\n",
      "Epoch: 44, Validation Loss: 1.2263787984848022\n",
      "Epoch: 45, Batch: 4, Training Loss: 0.4211457073688507\n",
      "Epoch: 45, Batch: 8, Training Loss: 0.4202761650085449\n",
      "Epoch: 45, Validation Loss: 1.2875665426254272\n",
      "Epoch: 46, Batch: 4, Training Loss: 0.39790308475494385\n",
      "Epoch: 46, Batch: 8, Training Loss: 0.4143596589565277\n",
      "Epoch: 46, Validation Loss: 1.2344008684158325\n",
      "Epoch: 47, Batch: 4, Training Loss: 0.43222755193710327\n",
      "Epoch: 47, Batch: 8, Training Loss: 0.4083072543144226\n",
      "Epoch: 47, Validation Loss: 1.2846949100494385\n",
      "Epoch: 48, Batch: 4, Training Loss: 0.41694751381874084\n",
      "Epoch: 48, Batch: 8, Training Loss: 0.41143104434013367\n",
      "Epoch: 48, Validation Loss: 1.2605482339859009\n",
      "Epoch: 49, Batch: 4, Training Loss: 0.41005221009254456\n",
      "Epoch: 49, Batch: 8, Training Loss: 0.42552340030670166\n",
      "Epoch: 49, Validation Loss: 1.2699862718582153\n",
      "Epoch: 50, Batch: 4, Training Loss: 0.4109273850917816\n",
      "Epoch: 50, Batch: 8, Training Loss: 0.398752897977829\n",
      "Epoch: 50, Validation Loss: 1.2561910152435303\n",
      "Epoch: 51, Batch: 4, Training Loss: 0.39755138754844666\n",
      "Epoch: 51, Batch: 8, Training Loss: 0.4087476134300232\n",
      "Epoch: 51, Validation Loss: 1.2528685331344604\n",
      "Epoch: 52, Batch: 4, Training Loss: 0.4132731854915619\n",
      "Epoch: 52, Batch: 8, Training Loss: 0.4036949574947357\n",
      "Epoch: 52, Validation Loss: 1.2202016115188599\n",
      "Epoch: 53, Batch: 4, Training Loss: 0.38864439725875854\n",
      "Epoch: 53, Batch: 8, Training Loss: 0.4168655276298523\n",
      "Epoch: 53, Validation Loss: 1.2379361391067505\n",
      "Epoch: 54, Batch: 4, Training Loss: 0.4079672396183014\n",
      "Epoch: 54, Batch: 8, Training Loss: 0.4038255214691162\n",
      "Epoch: 54, Validation Loss: 1.2901179790496826\n",
      "Epoch: 55, Batch: 4, Training Loss: 0.4043641984462738\n",
      "Epoch: 55, Batch: 8, Training Loss: 0.404314786195755\n",
      "Epoch: 55, Validation Loss: 1.246098279953003\n",
      "Epoch: 56, Batch: 4, Training Loss: 0.41394051909446716\n",
      "Epoch: 56, Batch: 8, Training Loss: 0.4072597324848175\n",
      "Epoch: 56, Validation Loss: 1.2130351066589355\n",
      "Epoch: 57, Batch: 4, Training Loss: 0.4035729765892029\n",
      "Epoch: 57, Batch: 8, Training Loss: 0.39490118622779846\n",
      "Epoch: 57, Validation Loss: 1.2695649862289429\n",
      "Epoch: 58, Batch: 4, Training Loss: 0.42759546637535095\n",
      "Epoch: 58, Batch: 8, Training Loss: 0.40785443782806396\n",
      "Epoch: 58, Validation Loss: 1.2751833200454712\n",
      "Epoch: 59, Batch: 4, Training Loss: 0.40285414457321167\n",
      "Epoch: 59, Batch: 8, Training Loss: 0.4117722511291504\n",
      "Epoch: 59, Validation Loss: 1.2449404001235962\n",
      "Epoch: 60, Batch: 4, Training Loss: 0.41140228509902954\n",
      "Epoch: 60, Batch: 8, Training Loss: 0.40619412064552307\n",
      "Epoch: 60, Validation Loss: 1.260033130645752\n",
      "Epoch: 61, Batch: 4, Training Loss: 0.4194606840610504\n",
      "Epoch: 61, Batch: 8, Training Loss: 0.4204239249229431\n",
      "Epoch: 61, Validation Loss: 1.2890557050704956\n",
      "Epoch: 62, Batch: 4, Training Loss: 0.43069857358932495\n",
      "Epoch: 62, Batch: 8, Training Loss: 0.4107181131839752\n",
      "Epoch: 62, Validation Loss: 1.247521996498108\n",
      "Epoch: 63, Batch: 4, Training Loss: 0.416303813457489\n",
      "Epoch: 63, Batch: 8, Training Loss: 0.41108667850494385\n",
      "Epoch: 63, Validation Loss: 1.248199224472046\n",
      "Epoch: 64, Batch: 4, Training Loss: 0.41549253463745117\n",
      "Epoch: 64, Batch: 8, Training Loss: 0.4211365580558777\n",
      "Epoch: 64, Validation Loss: 1.223673701286316\n",
      "Epoch: 65, Batch: 4, Training Loss: 0.40450868010520935\n",
      "Epoch: 65, Batch: 8, Training Loss: 0.4217929244041443\n",
      "Epoch: 65, Validation Loss: 1.299221158027649\n",
      "Epoch: 66, Batch: 4, Training Loss: 0.40045809745788574\n",
      "Epoch: 66, Batch: 8, Training Loss: 0.41275596618652344\n",
      "Epoch: 66, Validation Loss: 1.2590965032577515\n",
      "Epoch: 67, Batch: 4, Training Loss: 0.4252329170703888\n",
      "Epoch: 67, Batch: 8, Training Loss: 0.4010782837867737\n",
      "Epoch: 67, Validation Loss: 1.2616171836853027\n",
      "Epoch: 68, Batch: 4, Training Loss: 0.43352943658828735\n",
      "Epoch: 68, Batch: 8, Training Loss: 0.41986265778541565\n",
      "Epoch: 68, Validation Loss: 1.268799066543579\n",
      "Epoch: 69, Batch: 4, Training Loss: 0.3935706913471222\n",
      "Epoch: 69, Batch: 8, Training Loss: 0.4139654338359833\n",
      "Epoch: 69, Validation Loss: 1.2539628744125366\n",
      "Epoch: 70, Batch: 4, Training Loss: 0.4207676351070404\n",
      "Epoch: 70, Batch: 8, Training Loss: 0.42580342292785645\n",
      "Epoch: 70, Validation Loss: 1.2674859762191772\n",
      "Epoch: 71, Batch: 4, Training Loss: 0.429623007774353\n",
      "Epoch: 71, Batch: 8, Training Loss: 0.4140087962150574\n",
      "Epoch: 71, Validation Loss: 1.272505521774292\n",
      "Epoch: 72, Batch: 4, Training Loss: 0.41330093145370483\n",
      "Epoch: 72, Batch: 8, Training Loss: 0.3991294801235199\n",
      "Epoch: 72, Validation Loss: 1.29061758518219\n",
      "Epoch: 73, Batch: 4, Training Loss: 0.4336082637310028\n",
      "Epoch: 73, Batch: 8, Training Loss: 0.3932679295539856\n",
      "Epoch: 73, Validation Loss: 1.2852234840393066\n",
      "Epoch: 74, Batch: 4, Training Loss: 0.4122127890586853\n",
      "Epoch: 74, Batch: 8, Training Loss: 0.4341803193092346\n",
      "Epoch: 74, Validation Loss: 1.2671303749084473\n",
      "Epoch: 75, Batch: 4, Training Loss: 0.411652535200119\n",
      "Epoch: 75, Batch: 8, Training Loss: 0.42004525661468506\n",
      "Epoch: 75, Validation Loss: 1.2872782945632935\n",
      "Epoch: 76, Batch: 4, Training Loss: 0.42302411794662476\n",
      "Epoch: 76, Batch: 8, Training Loss: 0.400892972946167\n",
      "Epoch: 76, Validation Loss: 1.2286295890808105\n",
      "Epoch: 77, Batch: 4, Training Loss: 0.3932698667049408\n",
      "Epoch: 77, Batch: 8, Training Loss: 0.4094672203063965\n",
      "Epoch: 77, Validation Loss: 1.2504727840423584\n",
      "Epoch: 78, Batch: 4, Training Loss: 0.3924166262149811\n",
      "Epoch: 78, Batch: 8, Training Loss: 0.39984580874443054\n",
      "Epoch: 78, Validation Loss: 1.2746206521987915\n",
      "Epoch: 79, Batch: 4, Training Loss: 0.4120338261127472\n",
      "Epoch: 79, Batch: 8, Training Loss: 0.41749605536460876\n",
      "Epoch: 79, Validation Loss: 1.282747745513916\n",
      "Epoch: 80, Batch: 4, Training Loss: 0.41079917550086975\n",
      "Epoch: 80, Batch: 8, Training Loss: 0.4025261402130127\n",
      "Epoch: 80, Validation Loss: 1.2419523000717163\n",
      "Epoch: 81, Batch: 4, Training Loss: 0.41591671109199524\n",
      "Epoch: 81, Batch: 8, Training Loss: 0.40196168422698975\n",
      "Epoch: 81, Validation Loss: 1.277116060256958\n",
      "Epoch: 82, Batch: 4, Training Loss: 0.40552663803100586\n",
      "Epoch: 82, Batch: 8, Training Loss: 0.4175862669944763\n",
      "Epoch: 82, Validation Loss: 1.229854941368103\n",
      "Epoch: 83, Batch: 4, Training Loss: 0.4197612702846527\n",
      "Epoch: 83, Batch: 8, Training Loss: 0.40856143832206726\n",
      "Epoch: 83, Validation Loss: 1.2482826709747314\n",
      "Epoch: 84, Batch: 4, Training Loss: 0.40181487798690796\n",
      "Epoch: 84, Batch: 8, Training Loss: 0.42163512110710144\n",
      "Epoch: 84, Validation Loss: 1.2750416994094849\n",
      "Epoch: 85, Batch: 4, Training Loss: 0.3859672248363495\n",
      "Epoch: 85, Batch: 8, Training Loss: 0.41156160831451416\n",
      "Epoch: 85, Validation Loss: 1.2874327898025513\n",
      "Epoch: 86, Batch: 4, Training Loss: 0.4193992614746094\n",
      "Epoch: 86, Batch: 8, Training Loss: 0.41995254158973694\n",
      "Epoch: 86, Validation Loss: 1.2540451288223267\n",
      "Epoch: 87, Batch: 4, Training Loss: 0.4173806607723236\n",
      "Epoch: 87, Batch: 8, Training Loss: 0.4044201076030731\n",
      "Epoch: 87, Validation Loss: 1.2454928159713745\n",
      "Epoch: 88, Batch: 4, Training Loss: 0.4145932197570801\n",
      "Epoch: 88, Batch: 8, Training Loss: 0.4175620973110199\n",
      "Epoch: 88, Validation Loss: 1.2409965991973877\n",
      "Epoch: 89, Batch: 4, Training Loss: 0.4068050682544708\n",
      "Epoch: 89, Batch: 8, Training Loss: 0.4161381721496582\n",
      "Epoch: 89, Validation Loss: 1.2576206922531128\n",
      "Epoch: 90, Batch: 4, Training Loss: 0.4034765660762787\n",
      "Epoch: 90, Batch: 8, Training Loss: 0.3995986878871918\n",
      "Epoch: 90, Validation Loss: 1.2451398372650146\n",
      "Epoch: 91, Batch: 4, Training Loss: 0.4238441288471222\n",
      "Epoch: 91, Batch: 8, Training Loss: 0.4057318866252899\n",
      "Epoch: 91, Validation Loss: 1.2754465341567993\n",
      "Epoch: 92, Batch: 4, Training Loss: 0.4258900284767151\n",
      "Epoch: 92, Batch: 8, Training Loss: 0.4264278709888458\n",
      "Epoch: 92, Validation Loss: 1.2830537557601929\n",
      "Epoch: 93, Batch: 4, Training Loss: 0.3993442952632904\n",
      "Epoch: 93, Batch: 8, Training Loss: 0.39977189898490906\n",
      "Epoch: 93, Validation Loss: 1.258408784866333\n",
      "Epoch: 94, Batch: 4, Training Loss: 0.3992372751235962\n",
      "Epoch: 94, Batch: 8, Training Loss: 0.4240887761116028\n",
      "Epoch: 94, Validation Loss: 1.2435697317123413\n",
      "Epoch: 95, Batch: 4, Training Loss: 0.4086761474609375\n",
      "Epoch: 95, Batch: 8, Training Loss: 0.4036102294921875\n",
      "Epoch: 95, Validation Loss: 1.2904303073883057\n",
      "Epoch: 96, Batch: 4, Training Loss: 0.3961314260959625\n",
      "Epoch: 96, Batch: 8, Training Loss: 0.4153171479701996\n",
      "Epoch: 96, Validation Loss: 1.2749847173690796\n",
      "Epoch: 97, Batch: 4, Training Loss: 0.4212774336338043\n",
      "Epoch: 97, Batch: 8, Training Loss: 0.41429150104522705\n",
      "Epoch: 97, Validation Loss: 1.289143681526184\n",
      "Epoch: 98, Batch: 4, Training Loss: 0.41115254163742065\n",
      "Epoch: 98, Batch: 8, Training Loss: 0.4245358407497406\n",
      "Epoch: 98, Validation Loss: 1.2931371927261353\n",
      "Epoch: 99, Batch: 4, Training Loss: 0.4133067727088928\n",
      "Epoch: 99, Batch: 8, Training Loss: 0.4115767478942871\n",
      "Epoch: 99, Validation Loss: 1.2347034215927124\n",
      "Training took: 2061.3662395477295 seconds, or: 34.35610399246216 minutes!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Variables to track things\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "lowest_losses = [float('inf'), float('inf'), float('inf')] # each elem = ()\n",
    "# accuracy of train_corr[0] = train_corr[0]*100 / len(train_data)\n",
    "train_corr = []\n",
    "valid_corr = []\n",
    "\n",
    "# Epoch loop\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_corr_count = 0\n",
    "    valid_corr_count = 0\n",
    "    # Batch training\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        # start our batches at 1: so batch numbers are in the range [1, batchsize] instead of [0, batchsize-1]\n",
    "        b += 1\n",
    "        # make a prediction on the batch\n",
    "        y_pred = cnn(X_train) # X_train is dimension [batch_size, 3, 32, 32], making y_pred [batchsize, 10]\n",
    "        # Find the loss using the loss function\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        # Computes the back-propagation for each parameter:\n",
    "        loss.backward()\n",
    "        # Applies the update for each parameter\n",
    "        optimizer.step()\n",
    "        # Cleanup step for Pytorch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Keep track of the accuracy of the predictions\n",
    "\n",
    "        # predicted class gives us the index of most probability: i.e. what class the NN predicts the img is\n",
    "        predicted_class = torch.max(y_pred.data, 1)[1]\n",
    "        # batch_corr_count gives us the number of correct guesses in the batch\n",
    "        batch_corr_count = (predicted_class == y_train).sum()\n",
    "        # add that to the total number of correct guesses in the epoch\n",
    "        train_corr_count += batch_corr_count\n",
    "\n",
    "        # Print something so we can monitor the progress of the training\n",
    "        if b % int(len(train_loader) / 2) == 0:\n",
    "            print(f'Epoch: {i}, Batch: {b}, Training Loss: {loss.item()}') # loss.item() = loss[0], which is the value of loss\n",
    "\n",
    "    # Add the final epoch accuracy and loss to train acc and train losses arrays\n",
    "    train_corr.append(train_corr_count)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # test on validation set: NO WEIGHT UPDATES\n",
    "    with torch.no_grad():\n",
    "        for b, (X_valid, y_valid) in enumerate(valid_loader):\n",
    "            y_pred = cnn(X_valid)\n",
    "            predicted_class = torch.max(y_pred.data, 1)[1]\n",
    "            batch_corr_count = (predicted_class == y_valid).sum()\n",
    "            valid_corr_count += batch_corr_count\n",
    "    # add final loss to valid_losses\n",
    "    loss = criterion(y_pred, y_valid)\n",
    "    valid_losses.append(loss)\n",
    "\n",
    "    # save models with highest performance\n",
    "\n",
    "    # save cur model\n",
    "    torch.save(cnn.state_dict(), 'cnnbest.pt')\n",
    "\n",
    "    # Check if the current loss is lower than the highest of the three saved losses\n",
    "    if loss < lowest_losses[0]:\n",
    "        # Shift the current lowest losses\n",
    "        lowest_losses = [loss, lowest_losses[0], lowest_losses[1]]\n",
    "        \n",
    "        # Rename files to reflect the new order of losses\n",
    "        if os.path.exists(\"cnnbest2.pt\"):\n",
    "            shutil.move(\"cnnbest2.pt\", \"cnnbest3.pt\")\n",
    "        if os.path.exists(\"cnnbest1.pt\"):\n",
    "            shutil.move(\"cnnbest1.pt\", \"cnnbest2.pt\")\n",
    "        shutil.move(\"cnnbest.pt\", \"cnnbest1.pt\")\n",
    "    \n",
    "    elif loss < lowest_losses[1]:\n",
    "        # Shift the second and third lowest losses\n",
    "        lowest_losses = [lowest_losses[0], loss, lowest_losses[1]]\n",
    "        \n",
    "        # Rename files to reflect the new order of losses\n",
    "        if os.path.exists(\"cnnbest2.pt\"):\n",
    "            shutil.move(\"cnnbest2.pt\", \"cnnbest3.pt\")\n",
    "        shutil.move(\"cnnbest.pt\", \"cnnbest2.pt\")\n",
    "    \n",
    "    elif loss < lowest_losses[2]:\n",
    "        # Update the third lowest loss\n",
    "        lowest_losses[2] = loss\n",
    "        \n",
    "        # Rename the file to reflect the new third lowest loss\n",
    "        shutil.move(\"cnnbest.pt\", \"cnnbest3.pt\")\n",
    "    \n",
    "    # If the current loss isn't among the top three, the temporary file \"cnnbest.pt\" can be removed\n",
    "    else:\n",
    "        os.remove(\"cnnbest.pt\")\n",
    "\n",
    "    # print something to monitor the training\n",
    "    print(f'Epoch: {i}, Validation Loss: {loss.item()}') # loss.item() = loss[0], which is the value of loss\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "total = end_time - start_time\n",
    "\n",
    "print(f'Training took: {total} seconds, or: {total/60} minutes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_32152\\1560622286.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best1.load_state_dict(torch.load(\"cnnbest1.pt\"))\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_32152\\1560622286.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best2.load_state_dict(torch.load(\"cnnbest2.pt\"))\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_32152\\1560622286.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best3.load_state_dict(torch.load(\"cnnbest3.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "accuracy of the best model: 65.5999984741211\n",
      "accuracy of the second-best model: 65.66999816894531\n",
      "accuracy of the third-best model: 65.5999984741211\n"
     ]
    }
   ],
   "source": [
    "best1 = CNN()\n",
    "best2 = CNN()\n",
    "best3 = CNN()\n",
    "\n",
    "best1.load_state_dict(torch.load(\"cnnbest1.pt\"))\n",
    "best2.load_state_dict(torch.load(\"cnnbest2.pt\"))\n",
    "best3.load_state_dict(torch.load(\"cnnbest3.pt\"))\n",
    "\n",
    "len(test_data)\n",
    "# with torch.no_grad():\n",
    "#     for X_test, y_test in e\n",
    "#     y_eval1 = best3()\n",
    "\n",
    "test_corr_count1 = 0 \n",
    "test_corr_count2 = 0\n",
    "test_corr_count3 = 0 \n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "        y_pred1 = best1(X_test)\n",
    "        predicted_class1 = torch.max(y_pred1.data, 1)[1]\n",
    "        batch_corr_count1 = (predicted_class1 == y_test).sum()\n",
    "        test_corr_count1 += batch_corr_count1\n",
    "\n",
    "        y_pred2 = best2(X_test)\n",
    "        predicted_class2 = torch.max(y_pred2.data, 1)[1]\n",
    "        batch_corr_count2 = (predicted_class2 == y_test).sum()\n",
    "        test_corr_count2 += batch_corr_count2\n",
    "\n",
    "        y_pred3 = best3(X_test)\n",
    "        predicted_class3 = torch.max(y_pred3.data, 1)[1]\n",
    "        batch_corr_count3 = (predicted_class3 == y_test).sum()\n",
    "        test_corr_count3 += batch_corr_count3\n",
    "\n",
    "print(b + 1)\n",
    "print(f'accuracy of the best model: {test_corr_count1*100/len(test_data)}')\n",
    "print(f'accuracy of the second-best model: {test_corr_count2*100/len(test_data)}')\n",
    "print(f'accuracy of the third-best model: {test_corr_count3*100/len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments: that's obviously not great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's design a smaller CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # DIM = 3x32x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding='same')\n",
    "        # DIM = 6x32x32\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        # DIM = (32 - 2(0) - 2)/2 + 1 = 16 -> 6x16x16\n",
    "        self.o = 16\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1, padding='same')\n",
    "        # DIM = 16x16x16\n",
    "        # self.pool = nn.MaxPool2d(kernel_size=2,stride=2): dont need to define this here since its the same pooling layer\n",
    "        # DIM = (16 - 2(0) - 2)/2 + 1 = 8 -> 16x8x8\n",
    "        self.o2 = 8\n",
    "        \n",
    "        self.flattened_dim = self.o2*self.o2*16\n",
    "        self.fc1 = nn.Linear(in_features=self.flattened_dim, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.out = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "        # CHANGE 1: Add 25% dropout\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, self.flattened_dim)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUG 18: START HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine some hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "learn_rate = 0.001\n",
    "epochs = 1000 #4500\n",
    "# Greatly decrease batch size\n",
    "batch_size = 500 # was 500: this is actually quite big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = CNN2()\n",
    "\n",
    "# Loss function optimizer\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.Adam(cnn2.parameters(), lr = learn_rate)\n",
    "\n",
    "# Don't need to redefine this unless we change batch size\n",
    "# The samplers we defined above is essentially the same as shuffle=True, except we needed to use them to split training and validation\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN2(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (fc1): Linear(in_features=1024, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (out): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 3, 32, 32])\n",
      "torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "for b, (X_train, y_train) in enumerate(train_loader):\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    break\n",
    "\n",
    "#X_train.shape\n",
    "test = cnn2.forward(X_train)\n",
    "#test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 40, Training Loss: 2.1056039333343506\n",
      "Epoch: 0, Batch: 80, Training Loss: 1.9112272262573242\n",
      "Epoch: 0, Validation Loss: 1.9339944124221802\n",
      "Epoch: 1, Batch: 40, Training Loss: 1.8119834661483765\n",
      "Epoch: 1, Batch: 80, Training Loss: 1.8281844854354858\n",
      "Epoch: 1, Validation Loss: 1.723433256149292\n",
      "Epoch: 2, Batch: 40, Training Loss: 1.7408732175827026\n",
      "Epoch: 2, Batch: 80, Training Loss: 1.6958447694778442\n",
      "Epoch: 2, Validation Loss: 1.6198492050170898\n",
      "Epoch: 3, Batch: 40, Training Loss: 1.6327643394470215\n",
      "Epoch: 3, Batch: 80, Training Loss: 1.6108859777450562\n",
      "Epoch: 3, Validation Loss: 1.5479726791381836\n",
      "Epoch: 4, Batch: 40, Training Loss: 1.6076326370239258\n",
      "Epoch: 4, Batch: 80, Training Loss: 1.5484830141067505\n",
      "Epoch: 4, Validation Loss: 1.5811622142791748\n",
      "Epoch: 5, Batch: 40, Training Loss: 1.5330804586410522\n",
      "Epoch: 5, Batch: 80, Training Loss: 1.5736936330795288\n",
      "Epoch: 5, Validation Loss: 1.5231212377548218\n",
      "Epoch: 6, Batch: 40, Training Loss: 1.490497350692749\n",
      "Epoch: 6, Batch: 80, Training Loss: 1.5141141414642334\n",
      "Epoch: 6, Validation Loss: 1.4649245738983154\n",
      "Epoch: 7, Batch: 40, Training Loss: 1.4829400777816772\n",
      "Epoch: 7, Batch: 80, Training Loss: 1.4330240488052368\n",
      "Epoch: 7, Validation Loss: 1.5275981426239014\n",
      "Epoch: 8, Batch: 40, Training Loss: 1.5199896097183228\n",
      "Epoch: 8, Batch: 80, Training Loss: 1.4049841165542603\n",
      "Epoch: 8, Validation Loss: 1.3561973571777344\n",
      "Epoch: 9, Batch: 40, Training Loss: 1.441848874092102\n",
      "Epoch: 9, Batch: 80, Training Loss: 1.4544463157653809\n",
      "Epoch: 9, Validation Loss: 1.443286657333374\n",
      "Epoch: 10, Batch: 40, Training Loss: 1.470095157623291\n",
      "Epoch: 10, Batch: 80, Training Loss: 1.37913978099823\n",
      "Epoch: 10, Validation Loss: 1.365904450416565\n",
      "Epoch: 11, Batch: 40, Training Loss: 1.307479977607727\n",
      "Epoch: 11, Batch: 80, Training Loss: 1.297184944152832\n",
      "Epoch: 11, Validation Loss: 1.4815768003463745\n",
      "Epoch: 12, Batch: 40, Training Loss: 1.373450517654419\n",
      "Epoch: 12, Batch: 80, Training Loss: 1.3689993619918823\n",
      "Epoch: 12, Validation Loss: 1.3399118185043335\n",
      "Epoch: 13, Batch: 40, Training Loss: 1.3795040845870972\n",
      "Epoch: 13, Batch: 80, Training Loss: 1.312723994255066\n",
      "Epoch: 13, Validation Loss: 1.3085108995437622\n",
      "Epoch: 14, Batch: 40, Training Loss: 1.3098810911178589\n",
      "Epoch: 14, Batch: 80, Training Loss: 1.3289943933486938\n",
      "Epoch: 14, Validation Loss: 1.3578964471817017\n",
      "Epoch: 15, Batch: 40, Training Loss: 1.3309524059295654\n",
      "Epoch: 15, Batch: 80, Training Loss: 1.262120246887207\n",
      "Epoch: 15, Validation Loss: 1.383346438407898\n",
      "Epoch: 16, Batch: 40, Training Loss: 1.2776471376419067\n",
      "Epoch: 16, Batch: 80, Training Loss: 1.3050389289855957\n",
      "Epoch: 16, Validation Loss: 1.3232933282852173\n",
      "Epoch: 17, Batch: 40, Training Loss: 1.287534475326538\n",
      "Epoch: 17, Batch: 80, Training Loss: 1.2643866539001465\n",
      "Epoch: 17, Validation Loss: 1.275914192199707\n",
      "Epoch: 18, Batch: 40, Training Loss: 1.2592369318008423\n",
      "Epoch: 18, Batch: 80, Training Loss: 1.2535059452056885\n",
      "Epoch: 18, Validation Loss: 1.3046953678131104\n",
      "Epoch: 19, Batch: 40, Training Loss: 1.1230393648147583\n",
      "Epoch: 19, Batch: 80, Training Loss: 1.1958647966384888\n",
      "Epoch: 19, Validation Loss: 1.3375437259674072\n",
      "Epoch: 20, Batch: 40, Training Loss: 1.2114455699920654\n",
      "Epoch: 20, Batch: 80, Training Loss: 1.1903055906295776\n",
      "Epoch: 20, Validation Loss: 1.2347992658615112\n",
      "Epoch: 21, Batch: 40, Training Loss: 1.1829744577407837\n",
      "Epoch: 21, Batch: 80, Training Loss: 1.1926119327545166\n",
      "Epoch: 21, Validation Loss: 1.3353363275527954\n",
      "Epoch: 22, Batch: 40, Training Loss: 1.2236050367355347\n",
      "Epoch: 22, Batch: 80, Training Loss: 1.1954097747802734\n",
      "Epoch: 22, Validation Loss: 1.2324637174606323\n",
      "Epoch: 23, Batch: 40, Training Loss: 1.1614757776260376\n",
      "Epoch: 23, Batch: 80, Training Loss: 1.2461947202682495\n",
      "Epoch: 23, Validation Loss: 1.1852811574935913\n",
      "Epoch: 24, Batch: 40, Training Loss: 1.1567455530166626\n",
      "Epoch: 24, Batch: 80, Training Loss: 1.206472635269165\n",
      "Epoch: 24, Validation Loss: 1.179159164428711\n",
      "Epoch: 25, Batch: 40, Training Loss: 1.192526936531067\n",
      "Epoch: 25, Batch: 80, Training Loss: 1.2568633556365967\n",
      "Epoch: 25, Validation Loss: 1.2121094465255737\n",
      "Epoch: 26, Batch: 40, Training Loss: 1.200706124305725\n",
      "Epoch: 26, Batch: 80, Training Loss: 1.0981534719467163\n",
      "Epoch: 26, Validation Loss: 1.2069345712661743\n",
      "Epoch: 27, Batch: 40, Training Loss: 1.163125991821289\n",
      "Epoch: 27, Batch: 80, Training Loss: 1.1700482368469238\n",
      "Epoch: 27, Validation Loss: 1.235518455505371\n",
      "Epoch: 28, Batch: 40, Training Loss: 1.11026132106781\n",
      "Epoch: 28, Batch: 80, Training Loss: 1.1558525562286377\n",
      "Epoch: 28, Validation Loss: 1.1156224012374878\n",
      "Epoch: 29, Batch: 40, Training Loss: 1.105745792388916\n",
      "Epoch: 29, Batch: 80, Training Loss: 1.1269962787628174\n",
      "Epoch: 29, Validation Loss: 1.3244131803512573\n",
      "Epoch: 30, Batch: 40, Training Loss: 1.1635549068450928\n",
      "Epoch: 30, Batch: 80, Training Loss: 1.0943334102630615\n",
      "Epoch: 30, Validation Loss: 1.2609591484069824\n",
      "Epoch: 31, Batch: 40, Training Loss: 1.0673205852508545\n",
      "Epoch: 31, Batch: 80, Training Loss: 1.1174325942993164\n",
      "Epoch: 31, Validation Loss: 1.092240333557129\n",
      "Epoch: 32, Batch: 40, Training Loss: 1.0116997957229614\n",
      "Epoch: 32, Batch: 80, Training Loss: 1.0882755517959595\n",
      "Epoch: 32, Validation Loss: 1.1557303667068481\n",
      "Epoch: 33, Batch: 40, Training Loss: 0.9692322015762329\n",
      "Epoch: 33, Batch: 80, Training Loss: 1.1366560459136963\n",
      "Epoch: 33, Validation Loss: 1.116546630859375\n",
      "Epoch: 34, Batch: 40, Training Loss: 1.0329766273498535\n",
      "Epoch: 34, Batch: 80, Training Loss: 1.083889365196228\n",
      "Epoch: 34, Validation Loss: 1.1943504810333252\n",
      "Epoch: 35, Batch: 40, Training Loss: 1.078244924545288\n",
      "Epoch: 35, Batch: 80, Training Loss: 1.145296573638916\n",
      "Epoch: 35, Validation Loss: 1.116038203239441\n",
      "Epoch: 36, Batch: 40, Training Loss: 1.0595811605453491\n",
      "Epoch: 36, Batch: 80, Training Loss: 1.0934545993804932\n",
      "Epoch: 36, Validation Loss: 1.1005440950393677\n",
      "Epoch: 37, Batch: 40, Training Loss: 1.0740017890930176\n",
      "Epoch: 37, Batch: 80, Training Loss: 1.0566297769546509\n",
      "Epoch: 37, Validation Loss: 1.1582200527191162\n",
      "Epoch: 38, Batch: 40, Training Loss: 1.0401008129119873\n",
      "Epoch: 38, Batch: 80, Training Loss: 1.0248712301254272\n",
      "Epoch: 38, Validation Loss: 1.1262329816818237\n",
      "Epoch: 39, Batch: 40, Training Loss: 1.0735998153686523\n",
      "Epoch: 39, Batch: 80, Training Loss: 1.0291792154312134\n",
      "Epoch: 39, Validation Loss: 1.0980890989303589\n",
      "Epoch: 40, Batch: 40, Training Loss: 0.9906328320503235\n",
      "Epoch: 40, Batch: 80, Training Loss: 0.9468428492546082\n",
      "Epoch: 40, Validation Loss: 1.1379330158233643\n",
      "Epoch: 41, Batch: 40, Training Loss: 1.0387065410614014\n",
      "Epoch: 41, Batch: 80, Training Loss: 0.993208646774292\n",
      "Epoch: 41, Validation Loss: 1.1109236478805542\n",
      "Epoch: 42, Batch: 40, Training Loss: 1.0624302625656128\n",
      "Epoch: 42, Batch: 80, Training Loss: 1.0389282703399658\n",
      "Epoch: 42, Validation Loss: 1.0989021062850952\n",
      "Epoch: 43, Batch: 40, Training Loss: 1.1345669031143188\n",
      "Epoch: 43, Batch: 80, Training Loss: 1.002992868423462\n",
      "Epoch: 43, Validation Loss: 1.0596880912780762\n",
      "Epoch: 44, Batch: 40, Training Loss: 1.0367225408554077\n",
      "Epoch: 44, Batch: 80, Training Loss: 0.9883605241775513\n",
      "Epoch: 44, Validation Loss: 1.1260758638381958\n",
      "Epoch: 45, Batch: 40, Training Loss: 1.0142604112625122\n",
      "Epoch: 45, Batch: 80, Training Loss: 0.9324946403503418\n",
      "Epoch: 45, Validation Loss: 1.0679361820220947\n",
      "Epoch: 46, Batch: 40, Training Loss: 1.0269825458526611\n",
      "Epoch: 46, Batch: 80, Training Loss: 0.9562708735466003\n",
      "Epoch: 46, Validation Loss: 1.0885841846466064\n",
      "Epoch: 47, Batch: 40, Training Loss: 0.9658117294311523\n",
      "Epoch: 47, Batch: 80, Training Loss: 1.0003770589828491\n",
      "Epoch: 47, Validation Loss: 1.09421706199646\n",
      "Epoch: 48, Batch: 40, Training Loss: 1.0458970069885254\n",
      "Epoch: 48, Batch: 80, Training Loss: 0.9772520661354065\n",
      "Epoch: 48, Validation Loss: 1.1294490098953247\n",
      "Epoch: 49, Batch: 40, Training Loss: 0.9810325503349304\n",
      "Epoch: 49, Batch: 80, Training Loss: 0.9809218049049377\n",
      "Epoch: 49, Validation Loss: 1.096001386642456\n",
      "Epoch: 50, Batch: 40, Training Loss: 0.98509281873703\n",
      "Epoch: 50, Batch: 80, Training Loss: 0.9994089603424072\n",
      "Epoch: 50, Validation Loss: 0.9292090535163879\n",
      "Epoch: 51, Batch: 40, Training Loss: 1.0228809118270874\n",
      "Epoch: 51, Batch: 80, Training Loss: 0.9444407224655151\n",
      "Epoch: 51, Validation Loss: 1.0713016986846924\n",
      "Epoch: 52, Batch: 40, Training Loss: 1.0012445449829102\n",
      "Epoch: 52, Batch: 80, Training Loss: 0.966678261756897\n",
      "Epoch: 52, Validation Loss: 0.9792982935905457\n",
      "Epoch: 53, Batch: 40, Training Loss: 0.9299232959747314\n",
      "Epoch: 53, Batch: 80, Training Loss: 0.9797053337097168\n",
      "Epoch: 53, Validation Loss: 1.0113319158554077\n",
      "Epoch: 54, Batch: 40, Training Loss: 0.9459400773048401\n",
      "Epoch: 54, Batch: 80, Training Loss: 0.9279178977012634\n",
      "Epoch: 54, Validation Loss: 1.0681954622268677\n",
      "Epoch: 55, Batch: 40, Training Loss: 0.9129089713096619\n",
      "Epoch: 55, Batch: 80, Training Loss: 0.926787793636322\n",
      "Epoch: 55, Validation Loss: 1.1444751024246216\n",
      "Epoch: 56, Batch: 40, Training Loss: 1.0151498317718506\n",
      "Epoch: 56, Batch: 80, Training Loss: 0.9947652220726013\n",
      "Epoch: 56, Validation Loss: 1.1119542121887207\n",
      "Epoch: 57, Batch: 40, Training Loss: 0.8482527136802673\n",
      "Epoch: 57, Batch: 80, Training Loss: 0.9512412548065186\n",
      "Epoch: 57, Validation Loss: 1.0043877363204956\n",
      "Epoch: 58, Batch: 40, Training Loss: 0.9982827305793762\n",
      "Epoch: 58, Batch: 80, Training Loss: 0.9210010766983032\n",
      "Epoch: 58, Validation Loss: 1.0784727334976196\n",
      "Epoch: 59, Batch: 40, Training Loss: 0.9133524894714355\n",
      "Epoch: 59, Batch: 80, Training Loss: 0.9656112194061279\n",
      "Epoch: 59, Validation Loss: 1.0853506326675415\n",
      "Epoch: 60, Batch: 40, Training Loss: 0.9249759316444397\n",
      "Epoch: 60, Batch: 80, Training Loss: 0.9180007576942444\n",
      "Epoch: 60, Validation Loss: 1.0587575435638428\n",
      "Epoch: 61, Batch: 40, Training Loss: 0.9127892255783081\n",
      "Epoch: 61, Batch: 80, Training Loss: 0.8920356631278992\n",
      "Epoch: 61, Validation Loss: 1.092331886291504\n",
      "Epoch: 62, Batch: 40, Training Loss: 0.9667913317680359\n",
      "Epoch: 62, Batch: 80, Training Loss: 0.8425285220146179\n",
      "Epoch: 62, Validation Loss: 1.0679494142532349\n",
      "Epoch: 63, Batch: 40, Training Loss: 0.9536688327789307\n",
      "Epoch: 63, Batch: 80, Training Loss: 0.8802188038825989\n",
      "Epoch: 63, Validation Loss: 1.0088075399398804\n",
      "Epoch: 64, Batch: 40, Training Loss: 0.8901137709617615\n",
      "Epoch: 64, Batch: 80, Training Loss: 0.9014338254928589\n",
      "Epoch: 64, Validation Loss: 0.994683027267456\n",
      "Epoch: 65, Batch: 40, Training Loss: 0.9351469874382019\n",
      "Epoch: 65, Batch: 80, Training Loss: 0.8019845485687256\n",
      "Epoch: 65, Validation Loss: 1.077431321144104\n",
      "Epoch: 66, Batch: 40, Training Loss: 0.9675369262695312\n",
      "Epoch: 66, Batch: 80, Training Loss: 0.9131061434745789\n",
      "Epoch: 66, Validation Loss: 1.048664927482605\n",
      "Epoch: 67, Batch: 40, Training Loss: 0.8813419342041016\n",
      "Epoch: 67, Batch: 80, Training Loss: 0.9406092762947083\n",
      "Epoch: 67, Validation Loss: 1.005402684211731\n",
      "Epoch: 68, Batch: 40, Training Loss: 0.9006825685501099\n",
      "Epoch: 68, Batch: 80, Training Loss: 0.9128351211547852\n",
      "Epoch: 68, Validation Loss: 1.0565743446350098\n",
      "Epoch: 69, Batch: 40, Training Loss: 0.9326281547546387\n",
      "Epoch: 69, Batch: 80, Training Loss: 0.8848109245300293\n",
      "Epoch: 69, Validation Loss: 1.071158528327942\n",
      "Epoch: 70, Batch: 40, Training Loss: 0.8768744468688965\n",
      "Epoch: 70, Batch: 80, Training Loss: 0.9452741742134094\n",
      "Epoch: 70, Validation Loss: 1.0620903968811035\n",
      "Epoch: 71, Batch: 40, Training Loss: 0.9046657681465149\n",
      "Epoch: 71, Batch: 80, Training Loss: 0.9067579507827759\n",
      "Epoch: 71, Validation Loss: 1.0725412368774414\n",
      "Epoch: 72, Batch: 40, Training Loss: 0.9354242086410522\n",
      "Epoch: 72, Batch: 80, Training Loss: 0.8756346106529236\n",
      "Epoch: 72, Validation Loss: 1.0509426593780518\n",
      "Epoch: 73, Batch: 40, Training Loss: 0.9023067355155945\n",
      "Epoch: 73, Batch: 80, Training Loss: 0.8422841429710388\n",
      "Epoch: 73, Validation Loss: 1.0691161155700684\n",
      "Epoch: 74, Batch: 40, Training Loss: 0.8942310214042664\n",
      "Epoch: 74, Batch: 80, Training Loss: 0.8726905584335327\n",
      "Epoch: 74, Validation Loss: 1.032160997390747\n",
      "Epoch: 75, Batch: 40, Training Loss: 0.8624613881111145\n",
      "Epoch: 75, Batch: 80, Training Loss: 0.9493388533592224\n",
      "Epoch: 75, Validation Loss: 1.1081522703170776\n",
      "Epoch: 76, Batch: 40, Training Loss: 0.8211493492126465\n",
      "Epoch: 76, Batch: 80, Training Loss: 0.9259974956512451\n",
      "Epoch: 76, Validation Loss: 1.0653867721557617\n",
      "Epoch: 77, Batch: 40, Training Loss: 0.8404162526130676\n",
      "Epoch: 77, Batch: 80, Training Loss: 0.9069781303405762\n",
      "Epoch: 77, Validation Loss: 1.1089539527893066\n",
      "Epoch: 78, Batch: 40, Training Loss: 0.8230358362197876\n",
      "Epoch: 78, Batch: 80, Training Loss: 0.8523512482643127\n",
      "Epoch: 78, Validation Loss: 1.1284431219100952\n",
      "Epoch: 79, Batch: 40, Training Loss: 0.8662073016166687\n",
      "Epoch: 79, Batch: 80, Training Loss: 0.9231660962104797\n",
      "Epoch: 79, Validation Loss: 1.0811477899551392\n",
      "Epoch: 80, Batch: 40, Training Loss: 0.8246809244155884\n",
      "Epoch: 80, Batch: 80, Training Loss: 0.8170164823532104\n",
      "Epoch: 80, Validation Loss: 1.0577954053878784\n",
      "Epoch: 81, Batch: 40, Training Loss: 0.8649281859397888\n",
      "Epoch: 81, Batch: 80, Training Loss: 0.754816472530365\n",
      "Epoch: 81, Validation Loss: 1.1643004417419434\n",
      "Epoch: 82, Batch: 40, Training Loss: 0.8372436761856079\n",
      "Epoch: 82, Batch: 80, Training Loss: 0.8847595453262329\n",
      "Epoch: 82, Validation Loss: 1.0335768461227417\n",
      "Epoch: 83, Batch: 40, Training Loss: 0.8436893820762634\n",
      "Epoch: 83, Batch: 80, Training Loss: 0.8530116081237793\n",
      "Epoch: 83, Validation Loss: 1.0370527505874634\n",
      "Epoch: 84, Batch: 40, Training Loss: 0.8690455555915833\n",
      "Epoch: 84, Batch: 80, Training Loss: 0.8355751633644104\n",
      "Epoch: 84, Validation Loss: 1.016482949256897\n",
      "Epoch: 85, Batch: 40, Training Loss: 0.8155776262283325\n",
      "Epoch: 85, Batch: 80, Training Loss: 0.8765066266059875\n",
      "Epoch: 85, Validation Loss: 1.1031322479248047\n",
      "Epoch: 86, Batch: 40, Training Loss: 0.8328419923782349\n",
      "Epoch: 86, Batch: 80, Training Loss: 0.9285619854927063\n",
      "Epoch: 86, Validation Loss: 1.1023428440093994\n",
      "Epoch: 87, Batch: 40, Training Loss: 0.7785367965698242\n",
      "Epoch: 87, Batch: 80, Training Loss: 0.8073189854621887\n",
      "Epoch: 87, Validation Loss: 1.1358239650726318\n",
      "Epoch: 88, Batch: 40, Training Loss: 0.8093550205230713\n",
      "Epoch: 88, Batch: 80, Training Loss: 1.032856822013855\n",
      "Epoch: 88, Validation Loss: 1.1762728691101074\n",
      "Epoch: 89, Batch: 40, Training Loss: 0.89300537109375\n",
      "Epoch: 89, Batch: 80, Training Loss: 0.77736496925354\n",
      "Epoch: 89, Validation Loss: 1.073859691619873\n",
      "Epoch: 90, Batch: 40, Training Loss: 0.8563639521598816\n",
      "Epoch: 90, Batch: 80, Training Loss: 0.9402024745941162\n",
      "Epoch: 90, Validation Loss: 1.0471340417861938\n",
      "Epoch: 91, Batch: 40, Training Loss: 0.8043501377105713\n",
      "Epoch: 91, Batch: 80, Training Loss: 0.8338599801063538\n",
      "Epoch: 91, Validation Loss: 1.1332802772521973\n",
      "Epoch: 92, Batch: 40, Training Loss: 0.8431923985481262\n",
      "Epoch: 92, Batch: 80, Training Loss: 0.7788100242614746\n",
      "Epoch: 92, Validation Loss: 1.0592607259750366\n",
      "Epoch: 93, Batch: 40, Training Loss: 0.8475638031959534\n",
      "Epoch: 93, Batch: 80, Training Loss: 0.8635380864143372\n",
      "Epoch: 93, Validation Loss: 1.0529805421829224\n",
      "Epoch: 94, Batch: 40, Training Loss: 0.7992771863937378\n",
      "Epoch: 94, Batch: 80, Training Loss: 0.8811805844306946\n",
      "Epoch: 94, Validation Loss: 1.0022907257080078\n",
      "Epoch: 95, Batch: 40, Training Loss: 0.8452060222625732\n",
      "Epoch: 95, Batch: 80, Training Loss: 0.8495298624038696\n",
      "Epoch: 95, Validation Loss: 1.0417673587799072\n",
      "Epoch: 96, Batch: 40, Training Loss: 0.807201087474823\n",
      "Epoch: 96, Batch: 80, Training Loss: 0.8392803072929382\n",
      "Epoch: 96, Validation Loss: 1.0092967748641968\n",
      "Epoch: 97, Batch: 40, Training Loss: 0.8040503859519958\n",
      "Epoch: 97, Batch: 80, Training Loss: 0.8160905241966248\n",
      "Epoch: 97, Validation Loss: 1.1122701168060303\n",
      "Epoch: 98, Batch: 40, Training Loss: 0.8793184757232666\n",
      "Epoch: 98, Batch: 80, Training Loss: 0.8406023979187012\n",
      "Epoch: 98, Validation Loss: 1.0848745107650757\n",
      "Epoch: 99, Batch: 40, Training Loss: 0.8145034313201904\n",
      "Epoch: 99, Batch: 80, Training Loss: 0.8215444684028625\n",
      "Epoch: 99, Validation Loss: 1.0414639711380005\n",
      "Epoch: 100, Batch: 40, Training Loss: 0.8306293487548828\n",
      "Epoch: 100, Batch: 80, Training Loss: 0.8348608016967773\n",
      "Epoch: 100, Validation Loss: 1.0817396640777588\n",
      "Epoch: 101, Batch: 40, Training Loss: 0.8332024216651917\n",
      "Epoch: 101, Batch: 80, Training Loss: 0.7947845458984375\n",
      "Epoch: 101, Validation Loss: 1.0554012060165405\n",
      "Epoch: 102, Batch: 40, Training Loss: 0.7797885537147522\n",
      "Epoch: 102, Batch: 80, Training Loss: 0.8057743310928345\n",
      "Epoch: 102, Validation Loss: 0.9834731817245483\n",
      "Epoch: 103, Batch: 40, Training Loss: 0.7735488414764404\n",
      "Epoch: 103, Batch: 80, Training Loss: 0.9159782528877258\n",
      "Epoch: 103, Validation Loss: 1.0293387174606323\n",
      "Epoch: 104, Batch: 40, Training Loss: 0.7559692859649658\n",
      "Epoch: 104, Batch: 80, Training Loss: 0.8662018775939941\n",
      "Epoch: 104, Validation Loss: 1.1161223649978638\n",
      "Epoch: 105, Batch: 40, Training Loss: 0.8165239095687866\n",
      "Epoch: 105, Batch: 80, Training Loss: 0.8130911588668823\n",
      "Epoch: 105, Validation Loss: 1.0937888622283936\n",
      "Epoch: 106, Batch: 40, Training Loss: 0.7440165877342224\n",
      "Epoch: 106, Batch: 80, Training Loss: 0.7652108073234558\n",
      "Epoch: 106, Validation Loss: 1.0080342292785645\n",
      "Epoch: 107, Batch: 40, Training Loss: 0.7376515865325928\n",
      "Epoch: 107, Batch: 80, Training Loss: 0.7697033882141113\n",
      "Epoch: 107, Validation Loss: 1.0921390056610107\n",
      "Epoch: 108, Batch: 40, Training Loss: 0.7993196249008179\n",
      "Epoch: 108, Batch: 80, Training Loss: 0.8306731581687927\n",
      "Epoch: 108, Validation Loss: 1.2363239526748657\n",
      "Epoch: 109, Batch: 40, Training Loss: 0.7757299542427063\n",
      "Epoch: 109, Batch: 80, Training Loss: 0.8431041240692139\n",
      "Epoch: 109, Validation Loss: 1.0747286081314087\n",
      "Epoch: 110, Batch: 40, Training Loss: 0.7922587990760803\n",
      "Epoch: 110, Batch: 80, Training Loss: 0.8050165176391602\n",
      "Epoch: 110, Validation Loss: 1.0605837106704712\n",
      "Epoch: 111, Batch: 40, Training Loss: 0.7635309100151062\n",
      "Epoch: 111, Batch: 80, Training Loss: 0.7478945851325989\n",
      "Epoch: 111, Validation Loss: 1.0609755516052246\n",
      "Epoch: 112, Batch: 40, Training Loss: 0.7646821141242981\n",
      "Epoch: 112, Batch: 80, Training Loss: 0.7915657162666321\n",
      "Epoch: 112, Validation Loss: 1.154561161994934\n",
      "Epoch: 113, Batch: 40, Training Loss: 0.8002234697341919\n",
      "Epoch: 113, Batch: 80, Training Loss: 0.7826787829399109\n",
      "Epoch: 113, Validation Loss: 1.182830572128296\n",
      "Epoch: 114, Batch: 40, Training Loss: 0.71759033203125\n",
      "Epoch: 114, Batch: 80, Training Loss: 0.8341683149337769\n",
      "Epoch: 114, Validation Loss: 1.0717235803604126\n",
      "Epoch: 115, Batch: 40, Training Loss: 0.7442291975021362\n",
      "Epoch: 115, Batch: 80, Training Loss: 0.801871120929718\n",
      "Epoch: 115, Validation Loss: 1.0973607301712036\n",
      "Epoch: 116, Batch: 40, Training Loss: 0.7978135347366333\n",
      "Epoch: 116, Batch: 80, Training Loss: 0.7754092812538147\n",
      "Epoch: 116, Validation Loss: 1.1007455587387085\n",
      "Epoch: 117, Batch: 40, Training Loss: 0.7544896602630615\n",
      "Epoch: 117, Batch: 80, Training Loss: 0.7975817918777466\n",
      "Epoch: 117, Validation Loss: 1.062666893005371\n",
      "Epoch: 118, Batch: 40, Training Loss: 0.7011194825172424\n",
      "Epoch: 118, Batch: 80, Training Loss: 0.8471314311027527\n",
      "Epoch: 118, Validation Loss: 1.0300488471984863\n",
      "Epoch: 119, Batch: 40, Training Loss: 0.7141101956367493\n",
      "Epoch: 119, Batch: 80, Training Loss: 0.8063212633132935\n",
      "Epoch: 119, Validation Loss: 1.0279502868652344\n",
      "Epoch: 120, Batch: 40, Training Loss: 0.7226052284240723\n",
      "Epoch: 120, Batch: 80, Training Loss: 0.7528359293937683\n",
      "Epoch: 120, Validation Loss: 1.084882378578186\n",
      "Epoch: 121, Batch: 40, Training Loss: 0.8408605456352234\n",
      "Epoch: 121, Batch: 80, Training Loss: 0.8173217177391052\n",
      "Epoch: 121, Validation Loss: 1.128669261932373\n",
      "Epoch: 122, Batch: 40, Training Loss: 0.7854448556900024\n",
      "Epoch: 122, Batch: 80, Training Loss: 0.8212342858314514\n",
      "Epoch: 122, Validation Loss: 1.114521861076355\n",
      "Epoch: 123, Batch: 40, Training Loss: 0.8187501430511475\n",
      "Epoch: 123, Batch: 80, Training Loss: 0.8148428797721863\n",
      "Epoch: 123, Validation Loss: 1.1115676164627075\n",
      "Epoch: 124, Batch: 40, Training Loss: 0.7789489030838013\n",
      "Epoch: 124, Batch: 80, Training Loss: 0.7112860083580017\n",
      "Epoch: 124, Validation Loss: 1.129913568496704\n",
      "Epoch: 125, Batch: 40, Training Loss: 0.757071852684021\n",
      "Epoch: 125, Batch: 80, Training Loss: 0.6957680583000183\n",
      "Epoch: 125, Validation Loss: 0.971285879611969\n",
      "Epoch: 126, Batch: 40, Training Loss: 0.8251392841339111\n",
      "Epoch: 126, Batch: 80, Training Loss: 0.819107711315155\n",
      "Epoch: 126, Validation Loss: 1.1903153657913208\n",
      "Epoch: 127, Batch: 40, Training Loss: 0.7743385434150696\n",
      "Epoch: 127, Batch: 80, Training Loss: 0.7469818592071533\n",
      "Epoch: 127, Validation Loss: 1.079245686531067\n",
      "Epoch: 128, Batch: 40, Training Loss: 0.8440907001495361\n",
      "Epoch: 128, Batch: 80, Training Loss: 0.7543119788169861\n",
      "Epoch: 128, Validation Loss: 1.121341347694397\n",
      "Epoch: 129, Batch: 40, Training Loss: 0.8008407354354858\n",
      "Epoch: 129, Batch: 80, Training Loss: 0.7755501866340637\n",
      "Epoch: 129, Validation Loss: 1.0835648775100708\n",
      "Epoch: 130, Batch: 40, Training Loss: 0.8356066346168518\n",
      "Epoch: 130, Batch: 80, Training Loss: 0.749742865562439\n",
      "Epoch: 130, Validation Loss: 1.030692458152771\n",
      "Epoch: 131, Batch: 40, Training Loss: 0.7110333442687988\n",
      "Epoch: 131, Batch: 80, Training Loss: 0.6977413296699524\n",
      "Epoch: 131, Validation Loss: 1.1131452322006226\n",
      "Epoch: 132, Batch: 40, Training Loss: 0.7952172160148621\n",
      "Epoch: 132, Batch: 80, Training Loss: 0.8054012656211853\n",
      "Epoch: 132, Validation Loss: 1.1377360820770264\n",
      "Epoch: 133, Batch: 40, Training Loss: 0.7921521067619324\n",
      "Epoch: 133, Batch: 80, Training Loss: 0.8055498003959656\n",
      "Epoch: 133, Validation Loss: 1.0228190422058105\n",
      "Epoch: 134, Batch: 40, Training Loss: 0.7148695588111877\n",
      "Epoch: 134, Batch: 80, Training Loss: 0.7801331877708435\n",
      "Epoch: 134, Validation Loss: 1.0249221324920654\n",
      "Epoch: 135, Batch: 40, Training Loss: 0.7241303324699402\n",
      "Epoch: 135, Batch: 80, Training Loss: 0.7107685804367065\n",
      "Epoch: 135, Validation Loss: 1.082696557044983\n",
      "Epoch: 136, Batch: 40, Training Loss: 0.7724102139472961\n",
      "Epoch: 136, Batch: 80, Training Loss: 0.6985770463943481\n",
      "Epoch: 136, Validation Loss: 1.1136022806167603\n",
      "Epoch: 137, Batch: 40, Training Loss: 0.7487854957580566\n",
      "Epoch: 137, Batch: 80, Training Loss: 0.8329007029533386\n",
      "Epoch: 137, Validation Loss: 1.0206609964370728\n",
      "Epoch: 138, Batch: 40, Training Loss: 0.7007591724395752\n",
      "Epoch: 138, Batch: 80, Training Loss: 0.7517880201339722\n",
      "Epoch: 138, Validation Loss: 1.1396986246109009\n",
      "Epoch: 139, Batch: 40, Training Loss: 0.7723895907402039\n",
      "Epoch: 139, Batch: 80, Training Loss: 0.7030654549598694\n",
      "Epoch: 139, Validation Loss: 1.0656085014343262\n",
      "Epoch: 140, Batch: 40, Training Loss: 0.8654576539993286\n",
      "Epoch: 140, Batch: 80, Training Loss: 0.7680399417877197\n",
      "Epoch: 140, Validation Loss: 1.1075867414474487\n",
      "Epoch: 141, Batch: 40, Training Loss: 0.7536970973014832\n",
      "Epoch: 141, Batch: 80, Training Loss: 0.7512050271034241\n",
      "Epoch: 141, Validation Loss: 1.0962122678756714\n",
      "Epoch: 142, Batch: 40, Training Loss: 0.7610572576522827\n",
      "Epoch: 142, Batch: 80, Training Loss: 0.7480521202087402\n",
      "Epoch: 142, Validation Loss: 1.0686352252960205\n",
      "Epoch: 143, Batch: 40, Training Loss: 0.7255751490592957\n",
      "Epoch: 143, Batch: 80, Training Loss: 0.7012104988098145\n",
      "Epoch: 143, Validation Loss: 1.115841269493103\n",
      "Epoch: 144, Batch: 40, Training Loss: 0.7917174100875854\n",
      "Epoch: 144, Batch: 80, Training Loss: 0.7324798703193665\n",
      "Epoch: 144, Validation Loss: 1.1068636178970337\n",
      "Epoch: 145, Batch: 40, Training Loss: 0.7393741607666016\n",
      "Epoch: 145, Batch: 80, Training Loss: 0.7682128548622131\n",
      "Epoch: 145, Validation Loss: 1.1109517812728882\n",
      "Epoch: 146, Batch: 40, Training Loss: 0.8329529762268066\n",
      "Epoch: 146, Batch: 80, Training Loss: 0.7387964725494385\n",
      "Epoch: 146, Validation Loss: 1.04153311252594\n",
      "Epoch: 147, Batch: 40, Training Loss: 0.7484679222106934\n",
      "Epoch: 147, Batch: 80, Training Loss: 0.8189494013786316\n",
      "Epoch: 147, Validation Loss: 1.0501097440719604\n",
      "Epoch: 148, Batch: 40, Training Loss: 0.7779077887535095\n",
      "Epoch: 148, Batch: 80, Training Loss: 0.7727036476135254\n",
      "Epoch: 148, Validation Loss: 1.1087497472763062\n",
      "Epoch: 149, Batch: 40, Training Loss: 0.6672654151916504\n",
      "Epoch: 149, Batch: 80, Training Loss: 0.7881181240081787\n",
      "Epoch: 149, Validation Loss: 1.2114452123641968\n",
      "Epoch: 150, Batch: 40, Training Loss: 0.6944862008094788\n",
      "Epoch: 150, Batch: 80, Training Loss: 0.7693366408348083\n",
      "Epoch: 150, Validation Loss: 1.0086580514907837\n",
      "Epoch: 151, Batch: 40, Training Loss: 0.7343501448631287\n",
      "Epoch: 151, Batch: 80, Training Loss: 0.7737277746200562\n",
      "Epoch: 151, Validation Loss: 1.0874525308609009\n",
      "Epoch: 152, Batch: 40, Training Loss: 0.7406780123710632\n",
      "Epoch: 152, Batch: 80, Training Loss: 0.7547073364257812\n",
      "Epoch: 152, Validation Loss: 1.0985908508300781\n",
      "Epoch: 153, Batch: 40, Training Loss: 0.8117705583572388\n",
      "Epoch: 153, Batch: 80, Training Loss: 0.6456174850463867\n",
      "Epoch: 153, Validation Loss: 1.113935947418213\n",
      "Epoch: 154, Batch: 40, Training Loss: 0.7365801930427551\n",
      "Epoch: 154, Batch: 80, Training Loss: 0.7894728183746338\n",
      "Epoch: 154, Validation Loss: 1.004630208015442\n",
      "Epoch: 155, Batch: 40, Training Loss: 0.7939097881317139\n",
      "Epoch: 155, Batch: 80, Training Loss: 0.7117573022842407\n",
      "Epoch: 155, Validation Loss: 1.0781551599502563\n",
      "Epoch: 156, Batch: 40, Training Loss: 0.7266215085983276\n",
      "Epoch: 156, Batch: 80, Training Loss: 0.6522924304008484\n",
      "Epoch: 156, Validation Loss: 1.0991308689117432\n",
      "Epoch: 157, Batch: 40, Training Loss: 0.7465100288391113\n",
      "Epoch: 157, Batch: 80, Training Loss: 0.7237313985824585\n",
      "Epoch: 157, Validation Loss: 1.1618825197219849\n",
      "Epoch: 158, Batch: 40, Training Loss: 0.7410575151443481\n",
      "Epoch: 158, Batch: 80, Training Loss: 0.7131631374359131\n",
      "Epoch: 158, Validation Loss: 1.2341305017471313\n",
      "Epoch: 159, Batch: 40, Training Loss: 0.6702783107757568\n",
      "Epoch: 159, Batch: 80, Training Loss: 0.768166184425354\n",
      "Epoch: 159, Validation Loss: 1.0953786373138428\n",
      "Epoch: 160, Batch: 40, Training Loss: 0.7871868014335632\n",
      "Epoch: 160, Batch: 80, Training Loss: 0.7487902641296387\n",
      "Epoch: 160, Validation Loss: 1.0478383302688599\n",
      "Epoch: 161, Batch: 40, Training Loss: 0.736667275428772\n",
      "Epoch: 161, Batch: 80, Training Loss: 0.7668542265892029\n",
      "Epoch: 161, Validation Loss: 1.0759278535842896\n",
      "Epoch: 162, Batch: 40, Training Loss: 0.7297873497009277\n",
      "Epoch: 162, Batch: 80, Training Loss: 0.721130907535553\n",
      "Epoch: 162, Validation Loss: 1.0804494619369507\n",
      "Epoch: 163, Batch: 40, Training Loss: 0.7214061617851257\n",
      "Epoch: 163, Batch: 80, Training Loss: 0.7784478664398193\n",
      "Epoch: 163, Validation Loss: 1.0823990106582642\n",
      "Epoch: 164, Batch: 40, Training Loss: 0.7496107816696167\n",
      "Epoch: 164, Batch: 80, Training Loss: 0.7189812064170837\n",
      "Epoch: 164, Validation Loss: 1.1496819257736206\n",
      "Epoch: 165, Batch: 40, Training Loss: 0.6488668918609619\n",
      "Epoch: 165, Batch: 80, Training Loss: 0.7589237093925476\n",
      "Epoch: 165, Validation Loss: 1.1233330965042114\n",
      "Epoch: 166, Batch: 40, Training Loss: 0.6711644530296326\n",
      "Epoch: 166, Batch: 80, Training Loss: 0.6725888252258301\n",
      "Epoch: 166, Validation Loss: 1.1572526693344116\n",
      "Epoch: 167, Batch: 40, Training Loss: 0.7332618236541748\n",
      "Epoch: 167, Batch: 80, Training Loss: 0.653757631778717\n",
      "Epoch: 167, Validation Loss: 1.203185796737671\n",
      "Epoch: 168, Batch: 40, Training Loss: 0.7327208518981934\n",
      "Epoch: 168, Batch: 80, Training Loss: 0.6271550059318542\n",
      "Epoch: 168, Validation Loss: 1.2258986234664917\n",
      "Epoch: 169, Batch: 40, Training Loss: 0.6593685150146484\n",
      "Epoch: 169, Batch: 80, Training Loss: 0.729871928691864\n",
      "Epoch: 169, Validation Loss: 1.1468653678894043\n",
      "Epoch: 170, Batch: 40, Training Loss: 0.7700499892234802\n",
      "Epoch: 170, Batch: 80, Training Loss: 0.687976598739624\n",
      "Epoch: 170, Validation Loss: 1.1347445249557495\n",
      "Epoch: 171, Batch: 40, Training Loss: 0.7259272336959839\n",
      "Epoch: 171, Batch: 80, Training Loss: 0.7478720545768738\n",
      "Epoch: 171, Validation Loss: 1.1442509889602661\n",
      "Epoch: 172, Batch: 40, Training Loss: 0.7477935552597046\n",
      "Epoch: 172, Batch: 80, Training Loss: 0.6983999609947205\n",
      "Epoch: 172, Validation Loss: 1.0380821228027344\n",
      "Epoch: 173, Batch: 40, Training Loss: 0.7582424283027649\n",
      "Epoch: 173, Batch: 80, Training Loss: 0.7292078137397766\n",
      "Epoch: 173, Validation Loss: 1.2105920314788818\n",
      "Epoch: 174, Batch: 40, Training Loss: 0.7165201902389526\n",
      "Epoch: 174, Batch: 80, Training Loss: 0.7437456250190735\n",
      "Epoch: 174, Validation Loss: 1.116956353187561\n",
      "Epoch: 175, Batch: 40, Training Loss: 0.738827645778656\n",
      "Epoch: 175, Batch: 80, Training Loss: 0.7522673010826111\n",
      "Epoch: 175, Validation Loss: 1.1390482187271118\n",
      "Epoch: 176, Batch: 40, Training Loss: 0.7895032167434692\n",
      "Epoch: 176, Batch: 80, Training Loss: 0.750068187713623\n",
      "Epoch: 176, Validation Loss: 1.0925637483596802\n",
      "Epoch: 177, Batch: 40, Training Loss: 0.6998136639595032\n",
      "Epoch: 177, Batch: 80, Training Loss: 0.761936604976654\n",
      "Epoch: 177, Validation Loss: 1.043379306793213\n",
      "Epoch: 178, Batch: 40, Training Loss: 0.6814684867858887\n",
      "Epoch: 178, Batch: 80, Training Loss: 0.7087152600288391\n",
      "Epoch: 178, Validation Loss: 1.0744199752807617\n",
      "Epoch: 179, Batch: 40, Training Loss: 0.7208325862884521\n",
      "Epoch: 179, Batch: 80, Training Loss: 0.6848654747009277\n",
      "Epoch: 179, Validation Loss: 1.1858528852462769\n",
      "Epoch: 180, Batch: 40, Training Loss: 0.6926035284996033\n",
      "Epoch: 180, Batch: 80, Training Loss: 0.7097440958023071\n",
      "Epoch: 180, Validation Loss: 1.0996675491333008\n",
      "Epoch: 181, Batch: 40, Training Loss: 0.7408771514892578\n",
      "Epoch: 181, Batch: 80, Training Loss: 0.7631660103797913\n",
      "Epoch: 181, Validation Loss: 1.078316330909729\n",
      "Epoch: 182, Batch: 40, Training Loss: 0.7201179265975952\n",
      "Epoch: 182, Batch: 80, Training Loss: 0.753214418888092\n",
      "Epoch: 182, Validation Loss: 1.160925269126892\n",
      "Epoch: 183, Batch: 40, Training Loss: 0.7453667521476746\n",
      "Epoch: 183, Batch: 80, Training Loss: 0.6930951476097107\n",
      "Epoch: 183, Validation Loss: 0.9830020666122437\n",
      "Epoch: 184, Batch: 40, Training Loss: 0.756698727607727\n",
      "Epoch: 184, Batch: 80, Training Loss: 0.7569912075996399\n",
      "Epoch: 184, Validation Loss: 1.216251254081726\n",
      "Epoch: 185, Batch: 40, Training Loss: 0.732886791229248\n",
      "Epoch: 185, Batch: 80, Training Loss: 0.667614758014679\n",
      "Epoch: 185, Validation Loss: 1.1586061716079712\n",
      "Epoch: 186, Batch: 40, Training Loss: 0.6861535906791687\n",
      "Epoch: 186, Batch: 80, Training Loss: 0.6550034284591675\n",
      "Epoch: 186, Validation Loss: 1.11520516872406\n",
      "Epoch: 187, Batch: 40, Training Loss: 0.7074499726295471\n",
      "Epoch: 187, Batch: 80, Training Loss: 0.7099288702011108\n",
      "Epoch: 187, Validation Loss: 1.108155369758606\n",
      "Epoch: 188, Batch: 40, Training Loss: 0.7346861958503723\n",
      "Epoch: 188, Batch: 80, Training Loss: 0.6941217184066772\n",
      "Epoch: 188, Validation Loss: 1.0829799175262451\n",
      "Epoch: 189, Batch: 40, Training Loss: 0.6613724231719971\n",
      "Epoch: 189, Batch: 80, Training Loss: 0.7228346467018127\n",
      "Epoch: 189, Validation Loss: 1.2015186548233032\n",
      "Epoch: 190, Batch: 40, Training Loss: 0.7604257464408875\n",
      "Epoch: 190, Batch: 80, Training Loss: 0.6619029641151428\n",
      "Epoch: 190, Validation Loss: 1.169761061668396\n",
      "Epoch: 191, Batch: 40, Training Loss: 0.6970801949501038\n",
      "Epoch: 191, Batch: 80, Training Loss: 0.6816307306289673\n",
      "Epoch: 191, Validation Loss: 1.1744844913482666\n",
      "Epoch: 192, Batch: 40, Training Loss: 0.7816003561019897\n",
      "Epoch: 192, Batch: 80, Training Loss: 0.7485589385032654\n",
      "Epoch: 192, Validation Loss: 1.2216918468475342\n",
      "Epoch: 193, Batch: 40, Training Loss: 0.7049224376678467\n",
      "Epoch: 193, Batch: 80, Training Loss: 0.7418002486228943\n",
      "Epoch: 193, Validation Loss: 0.9680644869804382\n",
      "Epoch: 194, Batch: 40, Training Loss: 0.7109829783439636\n",
      "Epoch: 194, Batch: 80, Training Loss: 0.7586098313331604\n",
      "Epoch: 194, Validation Loss: 1.0755549669265747\n",
      "Epoch: 195, Batch: 40, Training Loss: 0.7552679777145386\n",
      "Epoch: 195, Batch: 80, Training Loss: 0.7799672484397888\n",
      "Epoch: 195, Validation Loss: 1.115909218788147\n",
      "Epoch: 196, Batch: 40, Training Loss: 0.6520756483078003\n",
      "Epoch: 196, Batch: 80, Training Loss: 0.7726334929466248\n",
      "Epoch: 196, Validation Loss: 1.1721875667572021\n",
      "Epoch: 197, Batch: 40, Training Loss: 0.6552494168281555\n",
      "Epoch: 197, Batch: 80, Training Loss: 0.7724432945251465\n",
      "Epoch: 197, Validation Loss: 1.0848556756973267\n",
      "Epoch: 198, Batch: 40, Training Loss: 0.7946767210960388\n",
      "Epoch: 198, Batch: 80, Training Loss: 0.6870900988578796\n",
      "Epoch: 198, Validation Loss: 1.1159864664077759\n",
      "Epoch: 199, Batch: 40, Training Loss: 0.7320219874382019\n",
      "Epoch: 199, Batch: 80, Training Loss: 0.6619712114334106\n",
      "Epoch: 199, Validation Loss: 1.1779817342758179\n",
      "Epoch: 200, Batch: 40, Training Loss: 0.6892205476760864\n",
      "Epoch: 200, Batch: 80, Training Loss: 0.6793454885482788\n",
      "Epoch: 200, Validation Loss: 1.2269325256347656\n",
      "Epoch: 201, Batch: 40, Training Loss: 0.7329447865486145\n",
      "Epoch: 201, Batch: 80, Training Loss: 0.7200210094451904\n",
      "Epoch: 201, Validation Loss: 1.0187028646469116\n",
      "Epoch: 202, Batch: 40, Training Loss: 0.6654373407363892\n",
      "Epoch: 202, Batch: 80, Training Loss: 0.6609999537467957\n",
      "Epoch: 202, Validation Loss: 1.1286147832870483\n",
      "Epoch: 203, Batch: 40, Training Loss: 0.6392157673835754\n",
      "Epoch: 203, Batch: 80, Training Loss: 0.7448232769966125\n",
      "Epoch: 203, Validation Loss: 1.1998003721237183\n",
      "Epoch: 204, Batch: 40, Training Loss: 0.6938780546188354\n",
      "Epoch: 204, Batch: 80, Training Loss: 0.656008780002594\n",
      "Epoch: 204, Validation Loss: 1.131693959236145\n",
      "Epoch: 205, Batch: 40, Training Loss: 0.7193639278411865\n",
      "Epoch: 205, Batch: 80, Training Loss: 0.6549575924873352\n",
      "Epoch: 205, Validation Loss: 1.0686968564987183\n",
      "Epoch: 206, Batch: 40, Training Loss: 0.6475439071655273\n",
      "Epoch: 206, Batch: 80, Training Loss: 0.7358951568603516\n",
      "Epoch: 206, Validation Loss: 1.194846510887146\n",
      "Epoch: 207, Batch: 40, Training Loss: 0.618556797504425\n",
      "Epoch: 207, Batch: 80, Training Loss: 0.8124449253082275\n",
      "Epoch: 207, Validation Loss: 1.1093508005142212\n",
      "Epoch: 208, Batch: 40, Training Loss: 0.69060879945755\n",
      "Epoch: 208, Batch: 80, Training Loss: 0.721759557723999\n",
      "Epoch: 208, Validation Loss: 1.0844881534576416\n",
      "Epoch: 209, Batch: 40, Training Loss: 0.7030162811279297\n",
      "Epoch: 209, Batch: 80, Training Loss: 0.7048753499984741\n",
      "Epoch: 209, Validation Loss: 1.238534688949585\n",
      "Epoch: 210, Batch: 40, Training Loss: 0.6769929528236389\n",
      "Epoch: 210, Batch: 80, Training Loss: 0.5575945973396301\n",
      "Epoch: 210, Validation Loss: 1.2297214269638062\n",
      "Epoch: 211, Batch: 40, Training Loss: 0.7569636702537537\n",
      "Epoch: 211, Batch: 80, Training Loss: 0.6665542721748352\n",
      "Epoch: 211, Validation Loss: 1.1956968307495117\n",
      "Epoch: 212, Batch: 40, Training Loss: 0.7499459981918335\n",
      "Epoch: 212, Batch: 80, Training Loss: 0.7108799815177917\n",
      "Epoch: 212, Validation Loss: 1.0499080419540405\n",
      "Epoch: 213, Batch: 40, Training Loss: 0.6765084862709045\n",
      "Epoch: 213, Batch: 80, Training Loss: 0.7259969711303711\n",
      "Epoch: 213, Validation Loss: 1.1343586444854736\n",
      "Epoch: 214, Batch: 40, Training Loss: 0.6891245245933533\n",
      "Epoch: 214, Batch: 80, Training Loss: 0.632814347743988\n",
      "Epoch: 214, Validation Loss: 1.0523314476013184\n",
      "Epoch: 215, Batch: 40, Training Loss: 0.7615131139755249\n",
      "Epoch: 215, Batch: 80, Training Loss: 0.7492994666099548\n",
      "Epoch: 215, Validation Loss: 1.1405742168426514\n",
      "Epoch: 216, Batch: 40, Training Loss: 0.6634047627449036\n",
      "Epoch: 216, Batch: 80, Training Loss: 0.6976340413093567\n",
      "Epoch: 216, Validation Loss: 1.097495436668396\n",
      "Epoch: 217, Batch: 40, Training Loss: 0.683447003364563\n",
      "Epoch: 217, Batch: 80, Training Loss: 0.6997016668319702\n",
      "Epoch: 217, Validation Loss: 1.1253377199172974\n",
      "Epoch: 218, Batch: 40, Training Loss: 0.6633240580558777\n",
      "Epoch: 218, Batch: 80, Training Loss: 0.6570450663566589\n",
      "Epoch: 218, Validation Loss: 1.0794235467910767\n",
      "Epoch: 219, Batch: 40, Training Loss: 0.6412336826324463\n",
      "Epoch: 219, Batch: 80, Training Loss: 0.628671407699585\n",
      "Epoch: 219, Validation Loss: 1.082366704940796\n",
      "Epoch: 220, Batch: 40, Training Loss: 0.5817756056785583\n",
      "Epoch: 220, Batch: 80, Training Loss: 0.703606367111206\n",
      "Epoch: 220, Validation Loss: 1.1142551898956299\n",
      "Epoch: 221, Batch: 40, Training Loss: 0.7182055115699768\n",
      "Epoch: 221, Batch: 80, Training Loss: 0.7177573442459106\n",
      "Epoch: 221, Validation Loss: 1.1587661504745483\n",
      "Epoch: 222, Batch: 40, Training Loss: 0.6967901587486267\n",
      "Epoch: 222, Batch: 80, Training Loss: 0.7414655685424805\n",
      "Epoch: 222, Validation Loss: 1.0729320049285889\n",
      "Epoch: 223, Batch: 40, Training Loss: 0.6680536270141602\n",
      "Epoch: 223, Batch: 80, Training Loss: 0.6822350025177002\n",
      "Epoch: 223, Validation Loss: 1.0475304126739502\n",
      "Epoch: 224, Batch: 40, Training Loss: 0.6686452031135559\n",
      "Epoch: 224, Batch: 80, Training Loss: 0.7117815017700195\n",
      "Epoch: 224, Validation Loss: 1.1765902042388916\n",
      "Epoch: 225, Batch: 40, Training Loss: 0.6560220122337341\n",
      "Epoch: 225, Batch: 80, Training Loss: 0.8518347144126892\n",
      "Epoch: 225, Validation Loss: 1.177170991897583\n",
      "Epoch: 226, Batch: 40, Training Loss: 0.6481786370277405\n",
      "Epoch: 226, Batch: 80, Training Loss: 0.7230382561683655\n",
      "Epoch: 226, Validation Loss: 1.0957200527191162\n",
      "Epoch: 227, Batch: 40, Training Loss: 0.6112695336341858\n",
      "Epoch: 227, Batch: 80, Training Loss: 0.7678530812263489\n",
      "Epoch: 227, Validation Loss: 1.0522314310073853\n",
      "Epoch: 228, Batch: 40, Training Loss: 0.6386799812316895\n",
      "Epoch: 228, Batch: 80, Training Loss: 0.698982834815979\n",
      "Epoch: 228, Validation Loss: 1.1161500215530396\n",
      "Epoch: 229, Batch: 40, Training Loss: 0.6977534890174866\n",
      "Epoch: 229, Batch: 80, Training Loss: 0.6414244771003723\n",
      "Epoch: 229, Validation Loss: 0.998374342918396\n",
      "Epoch: 230, Batch: 40, Training Loss: 0.7569890022277832\n",
      "Epoch: 230, Batch: 80, Training Loss: 0.6306950449943542\n",
      "Epoch: 230, Validation Loss: 1.1181418895721436\n",
      "Epoch: 231, Batch: 40, Training Loss: 0.7316417098045349\n",
      "Epoch: 231, Batch: 80, Training Loss: 0.6706435084342957\n",
      "Epoch: 231, Validation Loss: 1.1089352369308472\n",
      "Epoch: 232, Batch: 40, Training Loss: 0.7496949434280396\n",
      "Epoch: 232, Batch: 80, Training Loss: 0.7102835178375244\n",
      "Epoch: 232, Validation Loss: 1.2039724588394165\n",
      "Epoch: 233, Batch: 40, Training Loss: 0.7611203789710999\n",
      "Epoch: 233, Batch: 80, Training Loss: 0.8010280728340149\n",
      "Epoch: 233, Validation Loss: 1.1159987449645996\n",
      "Epoch: 234, Batch: 40, Training Loss: 0.6841226816177368\n",
      "Epoch: 234, Batch: 80, Training Loss: 0.7573584318161011\n",
      "Epoch: 234, Validation Loss: 1.154713749885559\n",
      "Epoch: 235, Batch: 40, Training Loss: 0.6323313117027283\n",
      "Epoch: 235, Batch: 80, Training Loss: 0.7019945383071899\n",
      "Epoch: 235, Validation Loss: 1.1043177843093872\n",
      "Epoch: 236, Batch: 40, Training Loss: 0.658560037612915\n",
      "Epoch: 236, Batch: 80, Training Loss: 0.6652811169624329\n",
      "Epoch: 236, Validation Loss: 1.1476489305496216\n",
      "Epoch: 237, Batch: 40, Training Loss: 0.722905158996582\n",
      "Epoch: 237, Batch: 80, Training Loss: 0.714767575263977\n",
      "Epoch: 237, Validation Loss: 1.090481162071228\n",
      "Epoch: 238, Batch: 40, Training Loss: 0.6535080671310425\n",
      "Epoch: 238, Batch: 80, Training Loss: 0.6576793789863586\n",
      "Epoch: 238, Validation Loss: 1.1502150297164917\n",
      "Epoch: 239, Batch: 40, Training Loss: 0.6859909296035767\n",
      "Epoch: 239, Batch: 80, Training Loss: 0.7473194003105164\n",
      "Epoch: 239, Validation Loss: 1.1075230836868286\n",
      "Epoch: 240, Batch: 40, Training Loss: 0.6340195536613464\n",
      "Epoch: 240, Batch: 80, Training Loss: 0.570732593536377\n",
      "Epoch: 240, Validation Loss: 1.0397950410842896\n",
      "Epoch: 241, Batch: 40, Training Loss: 0.6410993337631226\n",
      "Epoch: 241, Batch: 80, Training Loss: 0.6959767937660217\n",
      "Epoch: 241, Validation Loss: 1.139333963394165\n",
      "Epoch: 242, Batch: 40, Training Loss: 0.668128252029419\n",
      "Epoch: 242, Batch: 80, Training Loss: 0.7124524712562561\n",
      "Epoch: 242, Validation Loss: 1.1878011226654053\n",
      "Epoch: 243, Batch: 40, Training Loss: 0.7202454209327698\n",
      "Epoch: 243, Batch: 80, Training Loss: 0.7412390112876892\n",
      "Epoch: 243, Validation Loss: 1.195739507675171\n",
      "Epoch: 244, Batch: 40, Training Loss: 0.7507365345954895\n",
      "Epoch: 244, Batch: 80, Training Loss: 0.7139000296592712\n",
      "Epoch: 244, Validation Loss: 1.0528861284255981\n",
      "Epoch: 245, Batch: 40, Training Loss: 0.667473554611206\n",
      "Epoch: 245, Batch: 80, Training Loss: 0.6503162980079651\n",
      "Epoch: 245, Validation Loss: 1.092081069946289\n",
      "Epoch: 246, Batch: 40, Training Loss: 0.7019391655921936\n",
      "Epoch: 246, Batch: 80, Training Loss: 0.7155939936637878\n",
      "Epoch: 246, Validation Loss: 1.1723215579986572\n",
      "Epoch: 247, Batch: 40, Training Loss: 0.7423233985900879\n",
      "Epoch: 247, Batch: 80, Training Loss: 0.6849449276924133\n",
      "Epoch: 247, Validation Loss: 1.0507616996765137\n",
      "Epoch: 248, Batch: 40, Training Loss: 0.6658990383148193\n",
      "Epoch: 248, Batch: 80, Training Loss: 0.6592010259628296\n",
      "Epoch: 248, Validation Loss: 1.0126738548278809\n",
      "Epoch: 249, Batch: 40, Training Loss: 0.7188365459442139\n",
      "Epoch: 249, Batch: 80, Training Loss: 0.705695390701294\n",
      "Epoch: 249, Validation Loss: 1.0408166646957397\n",
      "Epoch: 250, Batch: 40, Training Loss: 0.7325151562690735\n",
      "Epoch: 250, Batch: 80, Training Loss: 0.6240274906158447\n",
      "Epoch: 250, Validation Loss: 1.0746105909347534\n",
      "Epoch: 251, Batch: 40, Training Loss: 0.6874501705169678\n",
      "Epoch: 251, Batch: 80, Training Loss: 0.7277069687843323\n",
      "Epoch: 251, Validation Loss: 1.2124520540237427\n",
      "Epoch: 252, Batch: 40, Training Loss: 0.63805091381073\n",
      "Epoch: 252, Batch: 80, Training Loss: 0.704319179058075\n",
      "Epoch: 252, Validation Loss: 1.1674340963363647\n",
      "Epoch: 253, Batch: 40, Training Loss: 0.6633769869804382\n",
      "Epoch: 253, Batch: 80, Training Loss: 0.7073819041252136\n",
      "Epoch: 253, Validation Loss: 1.1116794347763062\n",
      "Epoch: 254, Batch: 40, Training Loss: 0.6200835704803467\n",
      "Epoch: 254, Batch: 80, Training Loss: 0.679245114326477\n",
      "Epoch: 254, Validation Loss: 1.2105034589767456\n",
      "Epoch: 255, Batch: 40, Training Loss: 0.6990246176719666\n",
      "Epoch: 255, Batch: 80, Training Loss: 0.7355349063873291\n",
      "Epoch: 255, Validation Loss: 1.1052178144454956\n",
      "Epoch: 256, Batch: 40, Training Loss: 0.7659943699836731\n",
      "Epoch: 256, Batch: 80, Training Loss: 0.6796296834945679\n",
      "Epoch: 256, Validation Loss: 1.1069098711013794\n",
      "Epoch: 257, Batch: 40, Training Loss: 0.7491011619567871\n",
      "Epoch: 257, Batch: 80, Training Loss: 0.6634070873260498\n",
      "Epoch: 257, Validation Loss: 1.1541227102279663\n",
      "Epoch: 258, Batch: 40, Training Loss: 0.6668294072151184\n",
      "Epoch: 258, Batch: 80, Training Loss: 0.7184937596321106\n",
      "Epoch: 258, Validation Loss: 1.2372300624847412\n",
      "Epoch: 259, Batch: 40, Training Loss: 0.7192732095718384\n",
      "Epoch: 259, Batch: 80, Training Loss: 0.7711225748062134\n",
      "Epoch: 259, Validation Loss: 1.1913365125656128\n",
      "Epoch: 260, Batch: 40, Training Loss: 0.6529132723808289\n",
      "Epoch: 260, Batch: 80, Training Loss: 0.6812820434570312\n",
      "Epoch: 260, Validation Loss: 1.160172462463379\n",
      "Epoch: 261, Batch: 40, Training Loss: 0.6359548568725586\n",
      "Epoch: 261, Batch: 80, Training Loss: 0.672680675983429\n",
      "Epoch: 261, Validation Loss: 1.187461256980896\n",
      "Epoch: 262, Batch: 40, Training Loss: 0.6427149772644043\n",
      "Epoch: 262, Batch: 80, Training Loss: 0.6705465316772461\n",
      "Epoch: 262, Validation Loss: 1.1828513145446777\n",
      "Epoch: 263, Batch: 40, Training Loss: 0.757279634475708\n",
      "Epoch: 263, Batch: 80, Training Loss: 0.6756033897399902\n",
      "Epoch: 263, Validation Loss: 1.0976905822753906\n",
      "Epoch: 264, Batch: 40, Training Loss: 0.6984262466430664\n",
      "Epoch: 264, Batch: 80, Training Loss: 0.6725626587867737\n",
      "Epoch: 264, Validation Loss: 1.1849223375320435\n",
      "Epoch: 265, Batch: 40, Training Loss: 0.7389538288116455\n",
      "Epoch: 265, Batch: 80, Training Loss: 0.669557511806488\n",
      "Epoch: 265, Validation Loss: 1.2252439260482788\n",
      "Epoch: 266, Batch: 40, Training Loss: 0.7062475681304932\n",
      "Epoch: 266, Batch: 80, Training Loss: 0.6566261649131775\n",
      "Epoch: 266, Validation Loss: 1.140287160873413\n",
      "Epoch: 267, Batch: 40, Training Loss: 0.5690141916275024\n",
      "Epoch: 267, Batch: 80, Training Loss: 0.6032323241233826\n",
      "Epoch: 267, Validation Loss: 1.1368224620819092\n",
      "Epoch: 268, Batch: 40, Training Loss: 0.735538125038147\n",
      "Epoch: 268, Batch: 80, Training Loss: 0.6905964016914368\n",
      "Epoch: 268, Validation Loss: 1.1705697774887085\n",
      "Epoch: 269, Batch: 40, Training Loss: 0.6220331192016602\n",
      "Epoch: 269, Batch: 80, Training Loss: 0.6172531247138977\n",
      "Epoch: 269, Validation Loss: 1.1403902769088745\n",
      "Epoch: 270, Batch: 40, Training Loss: 0.7815998196601868\n",
      "Epoch: 270, Batch: 80, Training Loss: 0.6608287692070007\n",
      "Epoch: 270, Validation Loss: 1.1709833145141602\n",
      "Epoch: 271, Batch: 40, Training Loss: 0.7157387137413025\n",
      "Epoch: 271, Batch: 80, Training Loss: 0.6624847650527954\n",
      "Epoch: 271, Validation Loss: 1.1940276622772217\n",
      "Epoch: 272, Batch: 40, Training Loss: 0.6912860870361328\n",
      "Epoch: 272, Batch: 80, Training Loss: 0.6897674202919006\n",
      "Epoch: 272, Validation Loss: 1.0941332578659058\n",
      "Epoch: 273, Batch: 40, Training Loss: 0.6357577443122864\n",
      "Epoch: 273, Batch: 80, Training Loss: 0.6763810515403748\n",
      "Epoch: 273, Validation Loss: 1.2193610668182373\n",
      "Epoch: 274, Batch: 40, Training Loss: 0.6422455906867981\n",
      "Epoch: 274, Batch: 80, Training Loss: 0.6719760298728943\n",
      "Epoch: 274, Validation Loss: 1.0781753063201904\n",
      "Epoch: 275, Batch: 40, Training Loss: 0.5918505787849426\n",
      "Epoch: 275, Batch: 80, Training Loss: 0.6446396708488464\n",
      "Epoch: 275, Validation Loss: 1.13686203956604\n",
      "Epoch: 276, Batch: 40, Training Loss: 0.6884450912475586\n",
      "Epoch: 276, Batch: 80, Training Loss: 0.721351683139801\n",
      "Epoch: 276, Validation Loss: 1.0915733575820923\n",
      "Epoch: 277, Batch: 40, Training Loss: 0.696484386920929\n",
      "Epoch: 277, Batch: 80, Training Loss: 0.6702905297279358\n",
      "Epoch: 277, Validation Loss: 1.0816994905471802\n",
      "Epoch: 278, Batch: 40, Training Loss: 0.6312211155891418\n",
      "Epoch: 278, Batch: 80, Training Loss: 0.6225951313972473\n",
      "Epoch: 278, Validation Loss: 1.2880526781082153\n",
      "Epoch: 279, Batch: 40, Training Loss: 0.6411455869674683\n",
      "Epoch: 279, Batch: 80, Training Loss: 0.6634207367897034\n",
      "Epoch: 279, Validation Loss: 1.127339482307434\n",
      "Epoch: 280, Batch: 40, Training Loss: 0.6390174627304077\n",
      "Epoch: 280, Batch: 80, Training Loss: 0.6744909882545471\n",
      "Epoch: 280, Validation Loss: 1.0840673446655273\n",
      "Epoch: 281, Batch: 40, Training Loss: 0.6766305565834045\n",
      "Epoch: 281, Batch: 80, Training Loss: 0.6787518262863159\n",
      "Epoch: 281, Validation Loss: 1.2038438320159912\n",
      "Epoch: 282, Batch: 40, Training Loss: 0.6377887725830078\n",
      "Epoch: 282, Batch: 80, Training Loss: 0.6273230910301208\n",
      "Epoch: 282, Validation Loss: 1.1301332712173462\n",
      "Epoch: 283, Batch: 40, Training Loss: 0.6418858766555786\n",
      "Epoch: 283, Batch: 80, Training Loss: 0.6716014742851257\n",
      "Epoch: 283, Validation Loss: 1.1668096780776978\n",
      "Epoch: 284, Batch: 40, Training Loss: 0.7087631225585938\n",
      "Epoch: 284, Batch: 80, Training Loss: 0.7366527915000916\n",
      "Epoch: 284, Validation Loss: 1.1758087873458862\n",
      "Epoch: 285, Batch: 40, Training Loss: 0.7259458899497986\n",
      "Epoch: 285, Batch: 80, Training Loss: 0.6780356764793396\n",
      "Epoch: 285, Validation Loss: 1.0605705976486206\n",
      "Epoch: 286, Batch: 40, Training Loss: 0.606259822845459\n",
      "Epoch: 286, Batch: 80, Training Loss: 0.6935333609580994\n",
      "Epoch: 286, Validation Loss: 1.2143397331237793\n",
      "Epoch: 287, Batch: 40, Training Loss: 0.6620275378227234\n",
      "Epoch: 287, Batch: 80, Training Loss: 0.6167263984680176\n",
      "Epoch: 287, Validation Loss: 1.0643055438995361\n",
      "Epoch: 288, Batch: 40, Training Loss: 0.5661574602127075\n",
      "Epoch: 288, Batch: 80, Training Loss: 0.649885892868042\n",
      "Epoch: 288, Validation Loss: 1.1622334718704224\n",
      "Epoch: 289, Batch: 40, Training Loss: 0.6890589594841003\n",
      "Epoch: 289, Batch: 80, Training Loss: 0.6619558930397034\n",
      "Epoch: 289, Validation Loss: 1.2452197074890137\n",
      "Epoch: 290, Batch: 40, Training Loss: 0.6493760943412781\n",
      "Epoch: 290, Batch: 80, Training Loss: 0.6553265452384949\n",
      "Epoch: 290, Validation Loss: 1.0377205610275269\n",
      "Epoch: 291, Batch: 40, Training Loss: 0.7054046988487244\n",
      "Epoch: 291, Batch: 80, Training Loss: 0.6932150721549988\n",
      "Epoch: 291, Validation Loss: 1.250508189201355\n",
      "Epoch: 292, Batch: 40, Training Loss: 0.6897220015525818\n",
      "Epoch: 292, Batch: 80, Training Loss: 0.6185375452041626\n",
      "Epoch: 292, Validation Loss: 1.1514588594436646\n",
      "Epoch: 293, Batch: 40, Training Loss: 0.646376371383667\n",
      "Epoch: 293, Batch: 80, Training Loss: 0.6712119579315186\n",
      "Epoch: 293, Validation Loss: 1.0550520420074463\n",
      "Epoch: 294, Batch: 40, Training Loss: 0.7070662975311279\n",
      "Epoch: 294, Batch: 80, Training Loss: 0.5982528924942017\n",
      "Epoch: 294, Validation Loss: 1.104306697845459\n",
      "Epoch: 295, Batch: 40, Training Loss: 0.6635487675666809\n",
      "Epoch: 295, Batch: 80, Training Loss: 0.7210859656333923\n",
      "Epoch: 295, Validation Loss: 1.0991261005401611\n",
      "Epoch: 296, Batch: 40, Training Loss: 0.7073925733566284\n",
      "Epoch: 296, Batch: 80, Training Loss: 0.7019269466400146\n",
      "Epoch: 296, Validation Loss: 1.1709167957305908\n",
      "Epoch: 297, Batch: 40, Training Loss: 0.6008109450340271\n",
      "Epoch: 297, Batch: 80, Training Loss: 0.6653039455413818\n",
      "Epoch: 297, Validation Loss: 1.053336501121521\n",
      "Epoch: 298, Batch: 40, Training Loss: 0.5523678064346313\n",
      "Epoch: 298, Batch: 80, Training Loss: 0.6517523527145386\n",
      "Epoch: 298, Validation Loss: 1.1526823043823242\n",
      "Epoch: 299, Batch: 40, Training Loss: 0.5981429815292358\n",
      "Epoch: 299, Batch: 80, Training Loss: 0.6883813738822937\n",
      "Epoch: 299, Validation Loss: 0.9862754344940186\n",
      "Epoch: 300, Batch: 40, Training Loss: 0.6944463849067688\n",
      "Epoch: 300, Batch: 80, Training Loss: 0.6914852857589722\n",
      "Epoch: 300, Validation Loss: 1.1612639427185059\n",
      "Epoch: 301, Batch: 40, Training Loss: 0.7042325735092163\n",
      "Epoch: 301, Batch: 80, Training Loss: 0.6354292035102844\n",
      "Epoch: 301, Validation Loss: 1.1743214130401611\n",
      "Epoch: 302, Batch: 40, Training Loss: 0.673917829990387\n",
      "Epoch: 302, Batch: 80, Training Loss: 0.6773023009300232\n",
      "Epoch: 302, Validation Loss: 1.0954508781433105\n",
      "Epoch: 303, Batch: 40, Training Loss: 0.6243129372596741\n",
      "Epoch: 303, Batch: 80, Training Loss: 0.6002368927001953\n",
      "Epoch: 303, Validation Loss: 1.0556581020355225\n",
      "Epoch: 304, Batch: 40, Training Loss: 0.6502884030342102\n",
      "Epoch: 304, Batch: 80, Training Loss: 0.6479181051254272\n",
      "Epoch: 304, Validation Loss: 1.116084337234497\n",
      "Epoch: 305, Batch: 40, Training Loss: 0.5834701061248779\n",
      "Epoch: 305, Batch: 80, Training Loss: 0.655676007270813\n",
      "Epoch: 305, Validation Loss: 1.327694058418274\n",
      "Epoch: 306, Batch: 40, Training Loss: 0.6266703605651855\n",
      "Epoch: 306, Batch: 80, Training Loss: 0.7543517351150513\n",
      "Epoch: 306, Validation Loss: 1.1834617853164673\n",
      "Epoch: 307, Batch: 40, Training Loss: 0.6352705359458923\n",
      "Epoch: 307, Batch: 80, Training Loss: 0.6343393921852112\n",
      "Epoch: 307, Validation Loss: 1.1553083658218384\n",
      "Epoch: 308, Batch: 40, Training Loss: 0.6221747398376465\n",
      "Epoch: 308, Batch: 80, Training Loss: 0.6821852922439575\n",
      "Epoch: 308, Validation Loss: 1.0831193923950195\n",
      "Epoch: 309, Batch: 40, Training Loss: 0.7102845311164856\n",
      "Epoch: 309, Batch: 80, Training Loss: 0.6285338997840881\n",
      "Epoch: 309, Validation Loss: 1.0293785333633423\n",
      "Epoch: 310, Batch: 40, Training Loss: 0.6870853304862976\n",
      "Epoch: 310, Batch: 80, Training Loss: 0.6866838932037354\n",
      "Epoch: 310, Validation Loss: 1.238100290298462\n",
      "Epoch: 311, Batch: 40, Training Loss: 0.6501542329788208\n",
      "Epoch: 311, Batch: 80, Training Loss: 0.5864662528038025\n",
      "Epoch: 311, Validation Loss: 1.100374698638916\n",
      "Epoch: 312, Batch: 40, Training Loss: 0.6346979737281799\n",
      "Epoch: 312, Batch: 80, Training Loss: 0.6832941174507141\n",
      "Epoch: 312, Validation Loss: 1.1864722967147827\n",
      "Epoch: 313, Batch: 40, Training Loss: 0.5849855542182922\n",
      "Epoch: 313, Batch: 80, Training Loss: 0.6463014483451843\n",
      "Epoch: 313, Validation Loss: 1.0786454677581787\n",
      "Epoch: 314, Batch: 40, Training Loss: 0.7517459988594055\n",
      "Epoch: 314, Batch: 80, Training Loss: 0.7197906970977783\n",
      "Epoch: 314, Validation Loss: 1.1568268537521362\n",
      "Epoch: 315, Batch: 40, Training Loss: 0.6321801543235779\n",
      "Epoch: 315, Batch: 80, Training Loss: 0.7176609635353088\n",
      "Epoch: 315, Validation Loss: 1.2096720933914185\n",
      "Epoch: 316, Batch: 40, Training Loss: 0.6887533664703369\n",
      "Epoch: 316, Batch: 80, Training Loss: 0.623110294342041\n",
      "Epoch: 316, Validation Loss: 1.2121573686599731\n",
      "Epoch: 317, Batch: 40, Training Loss: 0.6217171549797058\n",
      "Epoch: 317, Batch: 80, Training Loss: 0.5525394678115845\n",
      "Epoch: 317, Validation Loss: 1.155536413192749\n",
      "Epoch: 318, Batch: 40, Training Loss: 0.6898631453514099\n",
      "Epoch: 318, Batch: 80, Training Loss: 0.6582329869270325\n",
      "Epoch: 318, Validation Loss: 1.0853315591812134\n",
      "Epoch: 319, Batch: 40, Training Loss: 0.5768085718154907\n",
      "Epoch: 319, Batch: 80, Training Loss: 0.6876933574676514\n",
      "Epoch: 319, Validation Loss: 1.020218849182129\n",
      "Epoch: 320, Batch: 40, Training Loss: 0.7481832504272461\n",
      "Epoch: 320, Batch: 80, Training Loss: 0.641461193561554\n",
      "Epoch: 320, Validation Loss: 1.0903797149658203\n",
      "Epoch: 321, Batch: 40, Training Loss: 0.6307268142700195\n",
      "Epoch: 321, Batch: 80, Training Loss: 0.6994607448577881\n",
      "Epoch: 321, Validation Loss: 1.1452538967132568\n",
      "Epoch: 322, Batch: 40, Training Loss: 0.699067234992981\n",
      "Epoch: 322, Batch: 80, Training Loss: 0.6619288325309753\n",
      "Epoch: 322, Validation Loss: 1.1642955541610718\n",
      "Epoch: 323, Batch: 40, Training Loss: 0.674812376499176\n",
      "Epoch: 323, Batch: 80, Training Loss: 0.6898790001869202\n",
      "Epoch: 323, Validation Loss: 1.128524899482727\n",
      "Epoch: 324, Batch: 40, Training Loss: 0.6660764217376709\n",
      "Epoch: 324, Batch: 80, Training Loss: 0.6739830374717712\n",
      "Epoch: 324, Validation Loss: 1.1181889772415161\n",
      "Epoch: 325, Batch: 40, Training Loss: 0.5924277901649475\n",
      "Epoch: 325, Batch: 80, Training Loss: 0.6511819362640381\n",
      "Epoch: 325, Validation Loss: 1.1316618919372559\n",
      "Epoch: 326, Batch: 40, Training Loss: 0.6196508407592773\n",
      "Epoch: 326, Batch: 80, Training Loss: 0.6619169116020203\n",
      "Epoch: 326, Validation Loss: 1.0546234846115112\n",
      "Epoch: 327, Batch: 40, Training Loss: 0.5895378589630127\n",
      "Epoch: 327, Batch: 80, Training Loss: 0.6554502248764038\n",
      "Epoch: 327, Validation Loss: 1.1370916366577148\n",
      "Epoch: 328, Batch: 40, Training Loss: 0.5817816853523254\n",
      "Epoch: 328, Batch: 80, Training Loss: 0.6345394253730774\n",
      "Epoch: 328, Validation Loss: 1.3226206302642822\n",
      "Epoch: 329, Batch: 40, Training Loss: 0.6658703684806824\n",
      "Epoch: 329, Batch: 80, Training Loss: 0.65602707862854\n",
      "Epoch: 329, Validation Loss: 1.069553017616272\n",
      "Epoch: 330, Batch: 40, Training Loss: 0.6841803789138794\n",
      "Epoch: 330, Batch: 80, Training Loss: 0.6263083815574646\n",
      "Epoch: 330, Validation Loss: 1.2322403192520142\n",
      "Epoch: 331, Batch: 40, Training Loss: 0.6258719563484192\n",
      "Epoch: 331, Batch: 80, Training Loss: 0.6521094441413879\n",
      "Epoch: 331, Validation Loss: 1.164427638053894\n",
      "Epoch: 332, Batch: 40, Training Loss: 0.654373288154602\n",
      "Epoch: 332, Batch: 80, Training Loss: 0.7077221870422363\n",
      "Epoch: 332, Validation Loss: 1.1907455921173096\n",
      "Epoch: 333, Batch: 40, Training Loss: 0.6851722002029419\n",
      "Epoch: 333, Batch: 80, Training Loss: 0.6725650429725647\n",
      "Epoch: 333, Validation Loss: 1.159998893737793\n",
      "Epoch: 334, Batch: 40, Training Loss: 0.6068784594535828\n",
      "Epoch: 334, Batch: 80, Training Loss: 0.6434922218322754\n",
      "Epoch: 334, Validation Loss: 1.2069790363311768\n",
      "Epoch: 335, Batch: 40, Training Loss: 0.6241748332977295\n",
      "Epoch: 335, Batch: 80, Training Loss: 0.6062140464782715\n",
      "Epoch: 335, Validation Loss: 1.0629910230636597\n",
      "Epoch: 336, Batch: 40, Training Loss: 0.6381655335426331\n",
      "Epoch: 336, Batch: 80, Training Loss: 0.6500644683837891\n",
      "Epoch: 336, Validation Loss: 1.1800297498703003\n",
      "Epoch: 337, Batch: 40, Training Loss: 0.6241910457611084\n",
      "Epoch: 337, Batch: 80, Training Loss: 0.6075469851493835\n",
      "Epoch: 337, Validation Loss: 1.2797906398773193\n",
      "Epoch: 338, Batch: 40, Training Loss: 0.6295216083526611\n",
      "Epoch: 338, Batch: 80, Training Loss: 0.6971005201339722\n",
      "Epoch: 338, Validation Loss: 1.0721648931503296\n",
      "Epoch: 339, Batch: 40, Training Loss: 0.6557866334915161\n",
      "Epoch: 339, Batch: 80, Training Loss: 0.6150013208389282\n",
      "Epoch: 339, Validation Loss: 1.131965160369873\n",
      "Epoch: 340, Batch: 40, Training Loss: 0.6780896186828613\n",
      "Epoch: 340, Batch: 80, Training Loss: 0.6936722993850708\n",
      "Epoch: 340, Validation Loss: 1.1622763872146606\n",
      "Epoch: 341, Batch: 40, Training Loss: 0.6158493757247925\n",
      "Epoch: 341, Batch: 80, Training Loss: 0.615841805934906\n",
      "Epoch: 341, Validation Loss: 1.0442289113998413\n",
      "Epoch: 342, Batch: 40, Training Loss: 0.6147111058235168\n",
      "Epoch: 342, Batch: 80, Training Loss: 0.622892439365387\n",
      "Epoch: 342, Validation Loss: 1.1444295644760132\n",
      "Epoch: 343, Batch: 40, Training Loss: 0.5842862129211426\n",
      "Epoch: 343, Batch: 80, Training Loss: 0.6862767934799194\n",
      "Epoch: 343, Validation Loss: 1.024768352508545\n",
      "Epoch: 344, Batch: 40, Training Loss: 0.665542721748352\n",
      "Epoch: 344, Batch: 80, Training Loss: 0.6289979219436646\n",
      "Epoch: 344, Validation Loss: 1.3190085887908936\n",
      "Epoch: 345, Batch: 40, Training Loss: 0.619651734828949\n",
      "Epoch: 345, Batch: 80, Training Loss: 0.7291200757026672\n",
      "Epoch: 345, Validation Loss: 1.1189367771148682\n",
      "Epoch: 346, Batch: 40, Training Loss: 0.6631197929382324\n",
      "Epoch: 346, Batch: 80, Training Loss: 0.715469479560852\n",
      "Epoch: 346, Validation Loss: 1.132527470588684\n",
      "Epoch: 347, Batch: 40, Training Loss: 0.5576513409614563\n",
      "Epoch: 347, Batch: 80, Training Loss: 0.6828771829605103\n",
      "Epoch: 347, Validation Loss: 1.2404465675354004\n",
      "Epoch: 348, Batch: 40, Training Loss: 0.6410410404205322\n",
      "Epoch: 348, Batch: 80, Training Loss: 0.6138310432434082\n",
      "Epoch: 348, Validation Loss: 1.1063580513000488\n",
      "Epoch: 349, Batch: 40, Training Loss: 0.6036956310272217\n",
      "Epoch: 349, Batch: 80, Training Loss: 0.6083292961120605\n",
      "Epoch: 349, Validation Loss: 1.3284653425216675\n",
      "Epoch: 350, Batch: 40, Training Loss: 0.6790354251861572\n",
      "Epoch: 350, Batch: 80, Training Loss: 0.6106649041175842\n",
      "Epoch: 350, Validation Loss: 1.1907944679260254\n",
      "Epoch: 351, Batch: 40, Training Loss: 0.5520592331886292\n",
      "Epoch: 351, Batch: 80, Training Loss: 0.7001435160636902\n",
      "Epoch: 351, Validation Loss: 1.21822988986969\n",
      "Epoch: 352, Batch: 40, Training Loss: 0.5947685837745667\n",
      "Epoch: 352, Batch: 80, Training Loss: 0.6340551972389221\n",
      "Epoch: 352, Validation Loss: 1.1183582544326782\n",
      "Epoch: 353, Batch: 40, Training Loss: 0.6314291954040527\n",
      "Epoch: 353, Batch: 80, Training Loss: 0.5902330875396729\n",
      "Epoch: 353, Validation Loss: 1.0800198316574097\n",
      "Epoch: 354, Batch: 40, Training Loss: 0.626725435256958\n",
      "Epoch: 354, Batch: 80, Training Loss: 0.6621731519699097\n",
      "Epoch: 354, Validation Loss: 1.0944448709487915\n",
      "Epoch: 355, Batch: 40, Training Loss: 0.6398791074752808\n",
      "Epoch: 355, Batch: 80, Training Loss: 0.7144511342048645\n",
      "Epoch: 355, Validation Loss: 1.3802993297576904\n",
      "Epoch: 356, Batch: 40, Training Loss: 0.5769615769386292\n",
      "Epoch: 356, Batch: 80, Training Loss: 0.6668068766593933\n",
      "Epoch: 356, Validation Loss: 1.0708760023117065\n",
      "Epoch: 357, Batch: 40, Training Loss: 0.6260578036308289\n",
      "Epoch: 357, Batch: 80, Training Loss: 0.6262075304985046\n",
      "Epoch: 357, Validation Loss: 1.097936749458313\n",
      "Epoch: 358, Batch: 40, Training Loss: 0.6337043046951294\n",
      "Epoch: 358, Batch: 80, Training Loss: 0.6891107559204102\n",
      "Epoch: 358, Validation Loss: 1.0686769485473633\n",
      "Epoch: 359, Batch: 40, Training Loss: 0.6013020277023315\n",
      "Epoch: 359, Batch: 80, Training Loss: 0.7159220576286316\n",
      "Epoch: 359, Validation Loss: 1.0865886211395264\n",
      "Epoch: 360, Batch: 40, Training Loss: 0.6095835566520691\n",
      "Epoch: 360, Batch: 80, Training Loss: 0.6684439778327942\n",
      "Epoch: 360, Validation Loss: 1.124391794204712\n",
      "Epoch: 361, Batch: 40, Training Loss: 0.631874680519104\n",
      "Epoch: 361, Batch: 80, Training Loss: 0.6123670339584351\n",
      "Epoch: 361, Validation Loss: 1.1377663612365723\n",
      "Epoch: 362, Batch: 40, Training Loss: 0.5423839092254639\n",
      "Epoch: 362, Batch: 80, Training Loss: 0.607146680355072\n",
      "Epoch: 362, Validation Loss: 1.1385313272476196\n",
      "Epoch: 363, Batch: 40, Training Loss: 0.6416286826133728\n",
      "Epoch: 363, Batch: 80, Training Loss: 0.6301748752593994\n",
      "Epoch: 363, Validation Loss: 1.173331379890442\n",
      "Epoch: 364, Batch: 40, Training Loss: 0.6440383791923523\n",
      "Epoch: 364, Batch: 80, Training Loss: 0.6199314594268799\n",
      "Epoch: 364, Validation Loss: 1.0444719791412354\n",
      "Epoch: 365, Batch: 40, Training Loss: 0.6799700260162354\n",
      "Epoch: 365, Batch: 80, Training Loss: 0.6763092875480652\n",
      "Epoch: 365, Validation Loss: 1.1954615116119385\n",
      "Epoch: 366, Batch: 40, Training Loss: 0.6363344788551331\n",
      "Epoch: 366, Batch: 80, Training Loss: 0.6452181935310364\n",
      "Epoch: 366, Validation Loss: 1.1749753952026367\n",
      "Epoch: 367, Batch: 40, Training Loss: 0.5563057661056519\n",
      "Epoch: 367, Batch: 80, Training Loss: 0.7256761193275452\n",
      "Epoch: 367, Validation Loss: 1.1139707565307617\n",
      "Epoch: 368, Batch: 40, Training Loss: 0.5542003512382507\n",
      "Epoch: 368, Batch: 80, Training Loss: 0.6600831747055054\n",
      "Epoch: 368, Validation Loss: 1.0967662334442139\n",
      "Epoch: 369, Batch: 40, Training Loss: 0.6816961169242859\n",
      "Epoch: 369, Batch: 80, Training Loss: 0.6463565230369568\n",
      "Epoch: 369, Validation Loss: 1.2352255582809448\n",
      "Epoch: 370, Batch: 40, Training Loss: 0.6408715844154358\n",
      "Epoch: 370, Batch: 80, Training Loss: 0.6122763752937317\n",
      "Epoch: 370, Validation Loss: 1.3272459506988525\n",
      "Epoch: 371, Batch: 40, Training Loss: 0.6123406291007996\n",
      "Epoch: 371, Batch: 80, Training Loss: 0.5653130412101746\n",
      "Epoch: 371, Validation Loss: 1.3310825824737549\n",
      "Epoch: 372, Batch: 40, Training Loss: 0.5896381139755249\n",
      "Epoch: 372, Batch: 80, Training Loss: 0.6435303092002869\n",
      "Epoch: 372, Validation Loss: 1.1407736539840698\n",
      "Epoch: 373, Batch: 40, Training Loss: 0.6910696029663086\n",
      "Epoch: 373, Batch: 80, Training Loss: 0.6319215893745422\n",
      "Epoch: 373, Validation Loss: 1.0878208875656128\n",
      "Epoch: 374, Batch: 40, Training Loss: 0.6453061103820801\n",
      "Epoch: 374, Batch: 80, Training Loss: 0.6142830848693848\n",
      "Epoch: 374, Validation Loss: 1.078567385673523\n",
      "Epoch: 375, Batch: 40, Training Loss: 0.599717915058136\n",
      "Epoch: 375, Batch: 80, Training Loss: 0.6060472130775452\n",
      "Epoch: 375, Validation Loss: 1.1822984218597412\n",
      "Epoch: 376, Batch: 40, Training Loss: 0.6418488621711731\n",
      "Epoch: 376, Batch: 80, Training Loss: 0.6318627595901489\n",
      "Epoch: 376, Validation Loss: 1.2092385292053223\n",
      "Epoch: 377, Batch: 40, Training Loss: 0.6781330108642578\n",
      "Epoch: 377, Batch: 80, Training Loss: 0.6515682339668274\n",
      "Epoch: 377, Validation Loss: 1.091447353363037\n",
      "Epoch: 378, Batch: 40, Training Loss: 0.6014495491981506\n",
      "Epoch: 378, Batch: 80, Training Loss: 0.6794815063476562\n",
      "Epoch: 378, Validation Loss: 1.2484787702560425\n",
      "Epoch: 379, Batch: 40, Training Loss: 0.7302410006523132\n",
      "Epoch: 379, Batch: 80, Training Loss: 0.6147528886795044\n",
      "Epoch: 379, Validation Loss: 1.2631337642669678\n",
      "Epoch: 380, Batch: 40, Training Loss: 0.5706566572189331\n",
      "Epoch: 380, Batch: 80, Training Loss: 0.593590497970581\n",
      "Epoch: 380, Validation Loss: 1.2071837186813354\n",
      "Epoch: 381, Batch: 40, Training Loss: 0.7085202932357788\n",
      "Epoch: 381, Batch: 80, Training Loss: 0.6955586671829224\n",
      "Epoch: 381, Validation Loss: 1.2136732339859009\n",
      "Epoch: 382, Batch: 40, Training Loss: 0.7142140865325928\n",
      "Epoch: 382, Batch: 80, Training Loss: 0.6314334273338318\n",
      "Epoch: 382, Validation Loss: 1.1475526094436646\n",
      "Epoch: 383, Batch: 40, Training Loss: 0.6181873679161072\n",
      "Epoch: 383, Batch: 80, Training Loss: 0.6787475943565369\n",
      "Epoch: 383, Validation Loss: 1.1802494525909424\n",
      "Epoch: 384, Batch: 40, Training Loss: 0.6549248695373535\n",
      "Epoch: 384, Batch: 80, Training Loss: 0.6001944541931152\n",
      "Epoch: 384, Validation Loss: 1.2857229709625244\n",
      "Epoch: 385, Batch: 40, Training Loss: 0.640266478061676\n",
      "Epoch: 385, Batch: 80, Training Loss: 0.699959933757782\n",
      "Epoch: 385, Validation Loss: 1.1415772438049316\n",
      "Epoch: 386, Batch: 40, Training Loss: 0.6563848853111267\n",
      "Epoch: 386, Batch: 80, Training Loss: 0.5916141867637634\n",
      "Epoch: 386, Validation Loss: 1.1555370092391968\n",
      "Epoch: 387, Batch: 40, Training Loss: 0.5668204426765442\n",
      "Epoch: 387, Batch: 80, Training Loss: 0.6160669922828674\n",
      "Epoch: 387, Validation Loss: 1.3000365495681763\n",
      "Epoch: 388, Batch: 40, Training Loss: 0.5697295069694519\n",
      "Epoch: 388, Batch: 80, Training Loss: 0.6941624879837036\n",
      "Epoch: 388, Validation Loss: 1.116365909576416\n",
      "Epoch: 389, Batch: 40, Training Loss: 0.5883448123931885\n",
      "Epoch: 389, Batch: 80, Training Loss: 0.6408119797706604\n",
      "Epoch: 389, Validation Loss: 1.063215732574463\n",
      "Epoch: 390, Batch: 40, Training Loss: 0.6070940494537354\n",
      "Epoch: 390, Batch: 80, Training Loss: 0.6489361524581909\n",
      "Epoch: 390, Validation Loss: 1.314751148223877\n",
      "Epoch: 391, Batch: 40, Training Loss: 0.6030064225196838\n",
      "Epoch: 391, Batch: 80, Training Loss: 0.541810929775238\n",
      "Epoch: 391, Validation Loss: 1.1110392808914185\n",
      "Epoch: 392, Batch: 40, Training Loss: 0.7149425148963928\n",
      "Epoch: 392, Batch: 80, Training Loss: 0.5581855177879333\n",
      "Epoch: 392, Validation Loss: 1.217637062072754\n",
      "Epoch: 393, Batch: 40, Training Loss: 0.6163361072540283\n",
      "Epoch: 393, Batch: 80, Training Loss: 0.6701512932777405\n",
      "Epoch: 393, Validation Loss: 1.170655608177185\n",
      "Epoch: 394, Batch: 40, Training Loss: 0.6119603514671326\n",
      "Epoch: 394, Batch: 80, Training Loss: 0.6346415877342224\n",
      "Epoch: 394, Validation Loss: 1.0316884517669678\n",
      "Epoch: 395, Batch: 40, Training Loss: 0.6781335473060608\n",
      "Epoch: 395, Batch: 80, Training Loss: 0.6800838708877563\n",
      "Epoch: 395, Validation Loss: 1.1724101305007935\n",
      "Epoch: 396, Batch: 40, Training Loss: 0.6126999258995056\n",
      "Epoch: 396, Batch: 80, Training Loss: 0.6684789657592773\n",
      "Epoch: 396, Validation Loss: 1.2622714042663574\n",
      "Epoch: 397, Batch: 40, Training Loss: 0.6399989724159241\n",
      "Epoch: 397, Batch: 80, Training Loss: 0.584632933139801\n",
      "Epoch: 397, Validation Loss: 1.2326933145523071\n",
      "Epoch: 398, Batch: 40, Training Loss: 0.6013626456260681\n",
      "Epoch: 398, Batch: 80, Training Loss: 0.6456767320632935\n",
      "Epoch: 398, Validation Loss: 1.049207329750061\n",
      "Epoch: 399, Batch: 40, Training Loss: 0.5926364660263062\n",
      "Epoch: 399, Batch: 80, Training Loss: 0.6169540286064148\n",
      "Epoch: 399, Validation Loss: 1.2006465196609497\n",
      "Epoch: 400, Batch: 40, Training Loss: 0.6026812791824341\n",
      "Epoch: 400, Batch: 80, Training Loss: 0.6801732778549194\n",
      "Epoch: 400, Validation Loss: 1.2129169702529907\n",
      "Epoch: 401, Batch: 40, Training Loss: 0.607262134552002\n",
      "Epoch: 401, Batch: 80, Training Loss: 0.6217360496520996\n",
      "Epoch: 401, Validation Loss: 1.1678884029388428\n",
      "Epoch: 402, Batch: 40, Training Loss: 0.6038058400154114\n",
      "Epoch: 402, Batch: 80, Training Loss: 0.5679319500923157\n",
      "Epoch: 402, Validation Loss: 1.0337040424346924\n",
      "Epoch: 403, Batch: 40, Training Loss: 0.631354570388794\n",
      "Epoch: 403, Batch: 80, Training Loss: 0.6699656248092651\n",
      "Epoch: 403, Validation Loss: 1.1517225503921509\n",
      "Epoch: 404, Batch: 40, Training Loss: 0.6302556395530701\n",
      "Epoch: 404, Batch: 80, Training Loss: 0.623775064945221\n",
      "Epoch: 404, Validation Loss: 1.1624164581298828\n",
      "Epoch: 405, Batch: 40, Training Loss: 0.6588398218154907\n",
      "Epoch: 405, Batch: 80, Training Loss: 0.5913442969322205\n",
      "Epoch: 405, Validation Loss: 1.146704077720642\n",
      "Epoch: 406, Batch: 40, Training Loss: 0.6412291526794434\n",
      "Epoch: 406, Batch: 80, Training Loss: 0.6470814347267151\n",
      "Epoch: 406, Validation Loss: 1.1701616048812866\n",
      "Epoch: 407, Batch: 40, Training Loss: 0.6170429587364197\n",
      "Epoch: 407, Batch: 80, Training Loss: 0.6693735718727112\n",
      "Epoch: 407, Validation Loss: 1.2501639127731323\n",
      "Epoch: 408, Batch: 40, Training Loss: 0.6067318320274353\n",
      "Epoch: 408, Batch: 80, Training Loss: 0.5999758243560791\n",
      "Epoch: 408, Validation Loss: 1.1376354694366455\n",
      "Epoch: 409, Batch: 40, Training Loss: 0.6251083612442017\n",
      "Epoch: 409, Batch: 80, Training Loss: 0.5973559617996216\n",
      "Epoch: 409, Validation Loss: 1.1441673040390015\n",
      "Epoch: 410, Batch: 40, Training Loss: 0.5827517509460449\n",
      "Epoch: 410, Batch: 80, Training Loss: 0.5708238482475281\n",
      "Epoch: 410, Validation Loss: 1.2462377548217773\n",
      "Epoch: 411, Batch: 40, Training Loss: 0.6300539970397949\n",
      "Epoch: 411, Batch: 80, Training Loss: 0.549850583076477\n",
      "Epoch: 411, Validation Loss: 1.2918270826339722\n",
      "Epoch: 412, Batch: 40, Training Loss: 0.6153927445411682\n",
      "Epoch: 412, Batch: 80, Training Loss: 0.5956487059593201\n",
      "Epoch: 412, Validation Loss: 1.3043889999389648\n",
      "Epoch: 413, Batch: 40, Training Loss: 0.6218413710594177\n",
      "Epoch: 413, Batch: 80, Training Loss: 0.6332032680511475\n",
      "Epoch: 413, Validation Loss: 1.2273383140563965\n",
      "Epoch: 414, Batch: 40, Training Loss: 0.6224653720855713\n",
      "Epoch: 414, Batch: 80, Training Loss: 0.6013489961624146\n",
      "Epoch: 414, Validation Loss: 1.1434094905853271\n",
      "Epoch: 415, Batch: 40, Training Loss: 0.6299562454223633\n",
      "Epoch: 415, Batch: 80, Training Loss: 0.5492396950721741\n",
      "Epoch: 415, Validation Loss: 1.0999234914779663\n",
      "Epoch: 416, Batch: 40, Training Loss: 0.6191149950027466\n",
      "Epoch: 416, Batch: 80, Training Loss: 0.5980960726737976\n",
      "Epoch: 416, Validation Loss: 1.145613193511963\n",
      "Epoch: 417, Batch: 40, Training Loss: 0.6415855884552002\n",
      "Epoch: 417, Batch: 80, Training Loss: 0.6680698990821838\n",
      "Epoch: 417, Validation Loss: 1.2108737230300903\n",
      "Epoch: 418, Batch: 40, Training Loss: 0.5521031022071838\n",
      "Epoch: 418, Batch: 80, Training Loss: 0.5443724989891052\n",
      "Epoch: 418, Validation Loss: 1.1760904788970947\n",
      "Epoch: 419, Batch: 40, Training Loss: 0.5810863971710205\n",
      "Epoch: 419, Batch: 80, Training Loss: 0.5725648403167725\n",
      "Epoch: 419, Validation Loss: 1.1460256576538086\n",
      "Epoch: 420, Batch: 40, Training Loss: 0.5790086984634399\n",
      "Epoch: 420, Batch: 80, Training Loss: 0.5997490882873535\n",
      "Epoch: 420, Validation Loss: 1.1279467344284058\n",
      "Epoch: 421, Batch: 40, Training Loss: 0.595650851726532\n",
      "Epoch: 421, Batch: 80, Training Loss: 0.6940090656280518\n",
      "Epoch: 421, Validation Loss: 1.210978388786316\n",
      "Epoch: 422, Batch: 40, Training Loss: 0.5663966536521912\n",
      "Epoch: 422, Batch: 80, Training Loss: 0.6005975604057312\n",
      "Epoch: 422, Validation Loss: 1.060854434967041\n",
      "Epoch: 423, Batch: 40, Training Loss: 0.647122859954834\n",
      "Epoch: 423, Batch: 80, Training Loss: 0.6625663638114929\n",
      "Epoch: 423, Validation Loss: 1.2581148147583008\n",
      "Epoch: 424, Batch: 40, Training Loss: 0.6409969925880432\n",
      "Epoch: 424, Batch: 80, Training Loss: 0.539287805557251\n",
      "Epoch: 424, Validation Loss: 1.1140145063400269\n",
      "Epoch: 425, Batch: 40, Training Loss: 0.6604048609733582\n",
      "Epoch: 425, Batch: 80, Training Loss: 0.6848416924476624\n",
      "Epoch: 425, Validation Loss: 1.0845282077789307\n",
      "Epoch: 426, Batch: 40, Training Loss: 0.6451838612556458\n",
      "Epoch: 426, Batch: 80, Training Loss: 0.5467649102210999\n",
      "Epoch: 426, Validation Loss: 1.1803157329559326\n",
      "Epoch: 427, Batch: 40, Training Loss: 0.5903814435005188\n",
      "Epoch: 427, Batch: 80, Training Loss: 0.5969291925430298\n",
      "Epoch: 427, Validation Loss: 1.1107127666473389\n",
      "Epoch: 428, Batch: 40, Training Loss: 0.6633892059326172\n",
      "Epoch: 428, Batch: 80, Training Loss: 0.6152647137641907\n",
      "Epoch: 428, Validation Loss: 0.9987369179725647\n",
      "Epoch: 429, Batch: 40, Training Loss: 0.550825297832489\n",
      "Epoch: 429, Batch: 80, Training Loss: 0.642508327960968\n",
      "Epoch: 429, Validation Loss: 1.1616874933242798\n",
      "Epoch: 430, Batch: 40, Training Loss: 0.692890465259552\n",
      "Epoch: 430, Batch: 80, Training Loss: 0.608881413936615\n",
      "Epoch: 430, Validation Loss: 1.1317791938781738\n",
      "Epoch: 431, Batch: 40, Training Loss: 0.6206226944923401\n",
      "Epoch: 431, Batch: 80, Training Loss: 0.6268198490142822\n",
      "Epoch: 431, Validation Loss: 1.2390977144241333\n",
      "Epoch: 432, Batch: 40, Training Loss: 0.5658798217773438\n",
      "Epoch: 432, Batch: 80, Training Loss: 0.5997228026390076\n",
      "Epoch: 432, Validation Loss: 1.2239423990249634\n",
      "Epoch: 433, Batch: 40, Training Loss: 0.589120626449585\n",
      "Epoch: 433, Batch: 80, Training Loss: 0.5998188853263855\n",
      "Epoch: 433, Validation Loss: 1.1474230289459229\n",
      "Epoch: 434, Batch: 40, Training Loss: 0.5914342999458313\n",
      "Epoch: 434, Batch: 80, Training Loss: 0.6638783812522888\n",
      "Epoch: 434, Validation Loss: 1.1102688312530518\n",
      "Epoch: 435, Batch: 40, Training Loss: 0.6654931902885437\n",
      "Epoch: 435, Batch: 80, Training Loss: 0.5309657454490662\n",
      "Epoch: 435, Validation Loss: 0.9968409538269043\n",
      "Epoch: 436, Batch: 40, Training Loss: 0.678147554397583\n",
      "Epoch: 436, Batch: 80, Training Loss: 0.5684611797332764\n",
      "Epoch: 436, Validation Loss: 1.108418345451355\n",
      "Epoch: 437, Batch: 40, Training Loss: 0.6570827960968018\n",
      "Epoch: 437, Batch: 80, Training Loss: 0.6550670862197876\n",
      "Epoch: 437, Validation Loss: 1.1236287355422974\n",
      "Epoch: 438, Batch: 40, Training Loss: 0.6365481615066528\n",
      "Epoch: 438, Batch: 80, Training Loss: 0.6257554888725281\n",
      "Epoch: 438, Validation Loss: 1.434095859527588\n",
      "Epoch: 439, Batch: 40, Training Loss: 0.5687502026557922\n",
      "Epoch: 439, Batch: 80, Training Loss: 0.6761153340339661\n",
      "Epoch: 439, Validation Loss: 1.1782242059707642\n",
      "Epoch: 440, Batch: 40, Training Loss: 0.5690841674804688\n",
      "Epoch: 440, Batch: 80, Training Loss: 0.6321052312850952\n",
      "Epoch: 440, Validation Loss: 1.2120088338851929\n",
      "Epoch: 441, Batch: 40, Training Loss: 0.6577015519142151\n",
      "Epoch: 441, Batch: 80, Training Loss: 0.6274006962776184\n",
      "Epoch: 441, Validation Loss: 1.2016650438308716\n",
      "Epoch: 442, Batch: 40, Training Loss: 0.6371105313301086\n",
      "Epoch: 442, Batch: 80, Training Loss: 0.5778339505195618\n",
      "Epoch: 442, Validation Loss: 1.2470324039459229\n",
      "Epoch: 443, Batch: 40, Training Loss: 0.5448490381240845\n",
      "Epoch: 443, Batch: 80, Training Loss: 0.6657366156578064\n",
      "Epoch: 443, Validation Loss: 1.1843324899673462\n",
      "Epoch: 444, Batch: 40, Training Loss: 0.663687527179718\n",
      "Epoch: 444, Batch: 80, Training Loss: 0.703090250492096\n",
      "Epoch: 444, Validation Loss: 1.223952054977417\n",
      "Epoch: 445, Batch: 40, Training Loss: 0.5844237804412842\n",
      "Epoch: 445, Batch: 80, Training Loss: 0.6669554710388184\n",
      "Epoch: 445, Validation Loss: 1.1088416576385498\n",
      "Epoch: 446, Batch: 40, Training Loss: 0.655998706817627\n",
      "Epoch: 446, Batch: 80, Training Loss: 0.5671466588973999\n",
      "Epoch: 446, Validation Loss: 1.177169680595398\n",
      "Epoch: 447, Batch: 40, Training Loss: 0.7119477391242981\n",
      "Epoch: 447, Batch: 80, Training Loss: 0.5544873476028442\n",
      "Epoch: 447, Validation Loss: 1.1448320150375366\n",
      "Epoch: 448, Batch: 40, Training Loss: 0.578187108039856\n",
      "Epoch: 448, Batch: 80, Training Loss: 0.6324666142463684\n",
      "Epoch: 448, Validation Loss: 1.0743989944458008\n",
      "Epoch: 449, Batch: 40, Training Loss: 0.616808295249939\n",
      "Epoch: 449, Batch: 80, Training Loss: 0.6360569596290588\n",
      "Epoch: 449, Validation Loss: 1.120872139930725\n",
      "Epoch: 450, Batch: 40, Training Loss: 0.5330857634544373\n",
      "Epoch: 450, Batch: 80, Training Loss: 0.550129234790802\n",
      "Epoch: 450, Validation Loss: 1.1152873039245605\n",
      "Epoch: 451, Batch: 40, Training Loss: 0.6614275574684143\n",
      "Epoch: 451, Batch: 80, Training Loss: 0.6569222807884216\n",
      "Epoch: 451, Validation Loss: 1.184325098991394\n",
      "Epoch: 452, Batch: 40, Training Loss: 0.6124032139778137\n",
      "Epoch: 452, Batch: 80, Training Loss: 0.6505245566368103\n",
      "Epoch: 452, Validation Loss: 1.284082055091858\n",
      "Epoch: 453, Batch: 40, Training Loss: 0.7145890593528748\n",
      "Epoch: 453, Batch: 80, Training Loss: 0.7387057542800903\n",
      "Epoch: 453, Validation Loss: 1.0868335962295532\n",
      "Epoch: 454, Batch: 40, Training Loss: 0.635578989982605\n",
      "Epoch: 454, Batch: 80, Training Loss: 0.585078239440918\n",
      "Epoch: 454, Validation Loss: 1.1691852807998657\n",
      "Epoch: 455, Batch: 40, Training Loss: 0.5715748071670532\n",
      "Epoch: 455, Batch: 80, Training Loss: 0.5505537986755371\n",
      "Epoch: 455, Validation Loss: 1.1563266515731812\n",
      "Epoch: 456, Batch: 40, Training Loss: 0.5915263891220093\n",
      "Epoch: 456, Batch: 80, Training Loss: 0.6115082502365112\n",
      "Epoch: 456, Validation Loss: 1.1569831371307373\n",
      "Epoch: 457, Batch: 40, Training Loss: 0.5886417031288147\n",
      "Epoch: 457, Batch: 80, Training Loss: 0.5633245706558228\n",
      "Epoch: 457, Validation Loss: 1.147359848022461\n",
      "Epoch: 458, Batch: 40, Training Loss: 0.5982982516288757\n",
      "Epoch: 458, Batch: 80, Training Loss: 0.609246015548706\n",
      "Epoch: 458, Validation Loss: 1.2878597974777222\n",
      "Epoch: 459, Batch: 40, Training Loss: 0.5621224641799927\n",
      "Epoch: 459, Batch: 80, Training Loss: 0.5514233112335205\n",
      "Epoch: 459, Validation Loss: 1.2245755195617676\n",
      "Epoch: 460, Batch: 40, Training Loss: 0.6197298169136047\n",
      "Epoch: 460, Batch: 80, Training Loss: 0.5642579197883606\n",
      "Epoch: 460, Validation Loss: 1.1848576068878174\n",
      "Epoch: 461, Batch: 40, Training Loss: 0.6186037659645081\n",
      "Epoch: 461, Batch: 80, Training Loss: 0.6200443506240845\n",
      "Epoch: 461, Validation Loss: 1.2766196727752686\n",
      "Epoch: 462, Batch: 40, Training Loss: 0.5442957878112793\n",
      "Epoch: 462, Batch: 80, Training Loss: 0.624547004699707\n",
      "Epoch: 462, Validation Loss: 0.9883716106414795\n",
      "Epoch: 463, Batch: 40, Training Loss: 0.6261399984359741\n",
      "Epoch: 463, Batch: 80, Training Loss: 0.6149575114250183\n",
      "Epoch: 463, Validation Loss: 1.2886128425598145\n",
      "Epoch: 464, Batch: 40, Training Loss: 0.638609766960144\n",
      "Epoch: 464, Batch: 80, Training Loss: 0.5538433194160461\n",
      "Epoch: 464, Validation Loss: 1.2846713066101074\n",
      "Epoch: 465, Batch: 40, Training Loss: 0.5819638967514038\n",
      "Epoch: 465, Batch: 80, Training Loss: 0.7058656215667725\n",
      "Epoch: 465, Validation Loss: 1.240286946296692\n",
      "Epoch: 466, Batch: 40, Training Loss: 0.5768953561782837\n",
      "Epoch: 466, Batch: 80, Training Loss: 0.6685994267463684\n",
      "Epoch: 466, Validation Loss: 1.2418067455291748\n",
      "Epoch: 467, Batch: 40, Training Loss: 0.555544376373291\n",
      "Epoch: 467, Batch: 80, Training Loss: 0.5505397915840149\n",
      "Epoch: 467, Validation Loss: 1.124158501625061\n",
      "Epoch: 468, Batch: 40, Training Loss: 0.567606508731842\n",
      "Epoch: 468, Batch: 80, Training Loss: 0.5894213318824768\n",
      "Epoch: 468, Validation Loss: 1.2091410160064697\n",
      "Epoch: 469, Batch: 40, Training Loss: 0.5971877574920654\n",
      "Epoch: 469, Batch: 80, Training Loss: 0.5557574033737183\n",
      "Epoch: 469, Validation Loss: 1.1609891653060913\n",
      "Epoch: 470, Batch: 40, Training Loss: 0.6405344605445862\n",
      "Epoch: 470, Batch: 80, Training Loss: 0.5741056203842163\n",
      "Epoch: 470, Validation Loss: 1.2782484292984009\n",
      "Epoch: 471, Batch: 40, Training Loss: 0.628415048122406\n",
      "Epoch: 471, Batch: 80, Training Loss: 0.6799959540367126\n",
      "Epoch: 471, Validation Loss: 1.2714756727218628\n",
      "Epoch: 472, Batch: 40, Training Loss: 0.5758296251296997\n",
      "Epoch: 472, Batch: 80, Training Loss: 0.5786389708518982\n",
      "Epoch: 472, Validation Loss: 1.1250118017196655\n",
      "Epoch: 473, Batch: 40, Training Loss: 0.6237929463386536\n",
      "Epoch: 473, Batch: 80, Training Loss: 0.6172794103622437\n",
      "Epoch: 473, Validation Loss: 1.2063742876052856\n",
      "Epoch: 474, Batch: 40, Training Loss: 0.5616415739059448\n",
      "Epoch: 474, Batch: 80, Training Loss: 0.6113047003746033\n",
      "Epoch: 474, Validation Loss: 1.2371748685836792\n",
      "Epoch: 475, Batch: 40, Training Loss: 0.6138671040534973\n",
      "Epoch: 475, Batch: 80, Training Loss: 0.5994356870651245\n",
      "Epoch: 475, Validation Loss: 1.1523295640945435\n",
      "Epoch: 476, Batch: 40, Training Loss: 0.5853854417800903\n",
      "Epoch: 476, Batch: 80, Training Loss: 0.6262860894203186\n",
      "Epoch: 476, Validation Loss: 1.150460958480835\n",
      "Epoch: 477, Batch: 40, Training Loss: 0.6173214912414551\n",
      "Epoch: 477, Batch: 80, Training Loss: 0.5555413961410522\n",
      "Epoch: 477, Validation Loss: 1.1905772686004639\n",
      "Epoch: 478, Batch: 40, Training Loss: 0.6061599254608154\n",
      "Epoch: 478, Batch: 80, Training Loss: 0.6339868903160095\n",
      "Epoch: 478, Validation Loss: 1.1559836864471436\n",
      "Epoch: 479, Batch: 40, Training Loss: 0.5986629128456116\n",
      "Epoch: 479, Batch: 80, Training Loss: 0.6109128594398499\n",
      "Epoch: 479, Validation Loss: 1.3886172771453857\n",
      "Epoch: 480, Batch: 40, Training Loss: 0.6164133548736572\n",
      "Epoch: 480, Batch: 80, Training Loss: 0.5891132950782776\n",
      "Epoch: 480, Validation Loss: 1.2229490280151367\n",
      "Epoch: 481, Batch: 40, Training Loss: 0.5941604971885681\n",
      "Epoch: 481, Batch: 80, Training Loss: 0.6216763854026794\n",
      "Epoch: 481, Validation Loss: 1.0909656286239624\n",
      "Epoch: 482, Batch: 40, Training Loss: 0.5674957036972046\n",
      "Epoch: 482, Batch: 80, Training Loss: 0.5642093420028687\n",
      "Epoch: 482, Validation Loss: 1.169925332069397\n",
      "Epoch: 483, Batch: 40, Training Loss: 0.6049361228942871\n",
      "Epoch: 483, Batch: 80, Training Loss: 0.5825223326683044\n",
      "Epoch: 483, Validation Loss: 1.2134147882461548\n",
      "Epoch: 484, Batch: 40, Training Loss: 0.5233600735664368\n",
      "Epoch: 484, Batch: 80, Training Loss: 0.6368616819381714\n",
      "Epoch: 484, Validation Loss: 1.2780442237854004\n",
      "Epoch: 485, Batch: 40, Training Loss: 0.593292236328125\n",
      "Epoch: 485, Batch: 80, Training Loss: 0.6647844910621643\n",
      "Epoch: 485, Validation Loss: 1.0930720567703247\n",
      "Epoch: 486, Batch: 40, Training Loss: 0.5695226788520813\n",
      "Epoch: 486, Batch: 80, Training Loss: 0.6365476846694946\n",
      "Epoch: 486, Validation Loss: 1.1851402521133423\n",
      "Epoch: 487, Batch: 40, Training Loss: 0.6181346774101257\n",
      "Epoch: 487, Batch: 80, Training Loss: 0.6002342700958252\n",
      "Epoch: 487, Validation Loss: 1.3019973039627075\n",
      "Epoch: 488, Batch: 40, Training Loss: 0.6237872838973999\n",
      "Epoch: 488, Batch: 80, Training Loss: 0.6807605624198914\n",
      "Epoch: 488, Validation Loss: 1.1027709245681763\n",
      "Epoch: 489, Batch: 40, Training Loss: 0.6425363421440125\n",
      "Epoch: 489, Batch: 80, Training Loss: 0.5262399315834045\n",
      "Epoch: 489, Validation Loss: 1.1961997747421265\n",
      "Epoch: 490, Batch: 40, Training Loss: 0.5665464401245117\n",
      "Epoch: 490, Batch: 80, Training Loss: 0.630945086479187\n",
      "Epoch: 490, Validation Loss: 1.2201859951019287\n",
      "Epoch: 491, Batch: 40, Training Loss: 0.5470668077468872\n",
      "Epoch: 491, Batch: 80, Training Loss: 0.6341535449028015\n",
      "Epoch: 491, Validation Loss: 1.1397736072540283\n",
      "Epoch: 492, Batch: 40, Training Loss: 0.5727088451385498\n",
      "Epoch: 492, Batch: 80, Training Loss: 0.6927347183227539\n",
      "Epoch: 492, Validation Loss: 1.265343427658081\n",
      "Epoch: 493, Batch: 40, Training Loss: 0.5628800988197327\n",
      "Epoch: 493, Batch: 80, Training Loss: 0.6012682318687439\n",
      "Epoch: 493, Validation Loss: 1.1724308729171753\n",
      "Epoch: 494, Batch: 40, Training Loss: 0.5988984107971191\n",
      "Epoch: 494, Batch: 80, Training Loss: 0.5557684302330017\n",
      "Epoch: 494, Validation Loss: 1.1735284328460693\n",
      "Epoch: 495, Batch: 40, Training Loss: 0.5608180165290833\n",
      "Epoch: 495, Batch: 80, Training Loss: 0.6415094137191772\n",
      "Epoch: 495, Validation Loss: 1.195529818534851\n",
      "Epoch: 496, Batch: 40, Training Loss: 0.6389516592025757\n",
      "Epoch: 496, Batch: 80, Training Loss: 0.5536765456199646\n",
      "Epoch: 496, Validation Loss: 1.1651520729064941\n",
      "Epoch: 497, Batch: 40, Training Loss: 0.599828839302063\n",
      "Epoch: 497, Batch: 80, Training Loss: 0.681103527545929\n",
      "Epoch: 497, Validation Loss: 1.119425892829895\n",
      "Epoch: 498, Batch: 40, Training Loss: 0.5719289779663086\n",
      "Epoch: 498, Batch: 80, Training Loss: 0.6056679487228394\n",
      "Epoch: 498, Validation Loss: 1.2256540060043335\n",
      "Epoch: 499, Batch: 40, Training Loss: 0.5485872030258179\n",
      "Epoch: 499, Batch: 80, Training Loss: 0.5833849310874939\n",
      "Epoch: 499, Validation Loss: 1.116913080215454\n",
      "Epoch: 500, Batch: 40, Training Loss: 0.6365840435028076\n",
      "Epoch: 500, Batch: 80, Training Loss: 0.6204608678817749\n",
      "Epoch: 500, Validation Loss: 1.2519491910934448\n",
      "Epoch: 501, Batch: 40, Training Loss: 0.5410358309745789\n",
      "Epoch: 501, Batch: 80, Training Loss: 0.5722329616546631\n",
      "Epoch: 501, Validation Loss: 1.1413992643356323\n",
      "Epoch: 502, Batch: 40, Training Loss: 0.5161899924278259\n",
      "Epoch: 502, Batch: 80, Training Loss: 0.5302387475967407\n",
      "Epoch: 502, Validation Loss: 1.233482837677002\n",
      "Epoch: 503, Batch: 40, Training Loss: 0.6024184823036194\n",
      "Epoch: 503, Batch: 80, Training Loss: 0.6214820742607117\n",
      "Epoch: 503, Validation Loss: 1.0295168161392212\n",
      "Epoch: 504, Batch: 40, Training Loss: 0.57579106092453\n",
      "Epoch: 504, Batch: 80, Training Loss: 0.5706661939620972\n",
      "Epoch: 504, Validation Loss: 1.1007975339889526\n",
      "Epoch: 505, Batch: 40, Training Loss: 0.619425356388092\n",
      "Epoch: 505, Batch: 80, Training Loss: 0.6687089800834656\n",
      "Epoch: 505, Validation Loss: 1.0709781646728516\n",
      "Epoch: 506, Batch: 40, Training Loss: 0.5633748769760132\n",
      "Epoch: 506, Batch: 80, Training Loss: 0.6099072694778442\n",
      "Epoch: 506, Validation Loss: 1.2888234853744507\n",
      "Epoch: 507, Batch: 40, Training Loss: 0.553746223449707\n",
      "Epoch: 507, Batch: 80, Training Loss: 0.535298764705658\n",
      "Epoch: 507, Validation Loss: 1.3593024015426636\n",
      "Epoch: 508, Batch: 40, Training Loss: 0.6138412952423096\n",
      "Epoch: 508, Batch: 80, Training Loss: 0.5952007174491882\n",
      "Epoch: 508, Validation Loss: 1.1288471221923828\n",
      "Epoch: 509, Batch: 40, Training Loss: 0.6473962068557739\n",
      "Epoch: 509, Batch: 80, Training Loss: 0.6091896891593933\n",
      "Epoch: 509, Validation Loss: 1.2326009273529053\n",
      "Epoch: 510, Batch: 40, Training Loss: 0.5497943758964539\n",
      "Epoch: 510, Batch: 80, Training Loss: 0.6183896660804749\n",
      "Epoch: 510, Validation Loss: 1.3203489780426025\n",
      "Epoch: 511, Batch: 40, Training Loss: 0.6230353713035583\n",
      "Epoch: 511, Batch: 80, Training Loss: 0.6400423049926758\n",
      "Epoch: 511, Validation Loss: 1.2615984678268433\n",
      "Epoch: 512, Batch: 40, Training Loss: 0.5669143795967102\n",
      "Epoch: 512, Batch: 80, Training Loss: 0.6145234704017639\n",
      "Epoch: 512, Validation Loss: 1.1959729194641113\n",
      "Epoch: 513, Batch: 40, Training Loss: 0.5449259877204895\n",
      "Epoch: 513, Batch: 80, Training Loss: 0.590336263179779\n",
      "Epoch: 513, Validation Loss: 1.1799730062484741\n",
      "Epoch: 514, Batch: 40, Training Loss: 0.5926634073257446\n",
      "Epoch: 514, Batch: 80, Training Loss: 0.6583128571510315\n",
      "Epoch: 514, Validation Loss: 1.1195164918899536\n",
      "Epoch: 515, Batch: 40, Training Loss: 0.5497635006904602\n",
      "Epoch: 515, Batch: 80, Training Loss: 0.6113598346710205\n",
      "Epoch: 515, Validation Loss: 1.2160428762435913\n",
      "Epoch: 516, Batch: 40, Training Loss: 0.5930370092391968\n",
      "Epoch: 516, Batch: 80, Training Loss: 0.5932762622833252\n",
      "Epoch: 516, Validation Loss: 1.2322837114334106\n",
      "Epoch: 517, Batch: 40, Training Loss: 0.6100348830223083\n",
      "Epoch: 517, Batch: 80, Training Loss: 0.5997368693351746\n",
      "Epoch: 517, Validation Loss: 1.211239218711853\n",
      "Epoch: 518, Batch: 40, Training Loss: 0.5761560201644897\n",
      "Epoch: 518, Batch: 80, Training Loss: 0.6096416115760803\n",
      "Epoch: 518, Validation Loss: 1.1633235216140747\n",
      "Epoch: 519, Batch: 40, Training Loss: 0.5989755392074585\n",
      "Epoch: 519, Batch: 80, Training Loss: 0.614893913269043\n",
      "Epoch: 519, Validation Loss: 1.1696977615356445\n",
      "Epoch: 520, Batch: 40, Training Loss: 0.5822776556015015\n",
      "Epoch: 520, Batch: 80, Training Loss: 0.5754198431968689\n",
      "Epoch: 520, Validation Loss: 1.1202583312988281\n",
      "Epoch: 521, Batch: 40, Training Loss: 0.5481171607971191\n",
      "Epoch: 521, Batch: 80, Training Loss: 0.6036038994789124\n",
      "Epoch: 521, Validation Loss: 1.1756250858306885\n",
      "Epoch: 522, Batch: 40, Training Loss: 0.5590230226516724\n",
      "Epoch: 522, Batch: 80, Training Loss: 0.7378353476524353\n",
      "Epoch: 522, Validation Loss: 1.120131254196167\n",
      "Epoch: 523, Batch: 40, Training Loss: 0.6054381728172302\n",
      "Epoch: 523, Batch: 80, Training Loss: 0.5555886030197144\n",
      "Epoch: 523, Validation Loss: 1.1270757913589478\n",
      "Epoch: 524, Batch: 40, Training Loss: 0.6737912893295288\n",
      "Epoch: 524, Batch: 80, Training Loss: 0.6116418242454529\n",
      "Epoch: 524, Validation Loss: 1.2324122190475464\n",
      "Epoch: 525, Batch: 40, Training Loss: 0.5527400374412537\n",
      "Epoch: 525, Batch: 80, Training Loss: 0.6363447904586792\n",
      "Epoch: 525, Validation Loss: 1.1078174114227295\n",
      "Epoch: 526, Batch: 40, Training Loss: 0.5543067455291748\n",
      "Epoch: 526, Batch: 80, Training Loss: 0.5756644010543823\n",
      "Epoch: 526, Validation Loss: 1.2035458087921143\n",
      "Epoch: 527, Batch: 40, Training Loss: 0.517175555229187\n",
      "Epoch: 527, Batch: 80, Training Loss: 0.637846052646637\n",
      "Epoch: 527, Validation Loss: 1.0987554788589478\n",
      "Epoch: 528, Batch: 40, Training Loss: 0.593740701675415\n",
      "Epoch: 528, Batch: 80, Training Loss: 0.627921998500824\n",
      "Epoch: 528, Validation Loss: 1.2564047574996948\n",
      "Epoch: 529, Batch: 40, Training Loss: 0.6217373609542847\n",
      "Epoch: 529, Batch: 80, Training Loss: 0.5948663949966431\n",
      "Epoch: 529, Validation Loss: 1.2472712993621826\n",
      "Epoch: 530, Batch: 40, Training Loss: 0.6004441976547241\n",
      "Epoch: 530, Batch: 80, Training Loss: 0.5723078846931458\n",
      "Epoch: 530, Validation Loss: 1.2536580562591553\n",
      "Epoch: 531, Batch: 40, Training Loss: 0.6246127486228943\n",
      "Epoch: 531, Batch: 80, Training Loss: 0.5720314383506775\n",
      "Epoch: 531, Validation Loss: 1.2369831800460815\n",
      "Epoch: 532, Batch: 40, Training Loss: 0.5449477434158325\n",
      "Epoch: 532, Batch: 80, Training Loss: 0.6490002274513245\n",
      "Epoch: 532, Validation Loss: 1.221232295036316\n",
      "Epoch: 533, Batch: 40, Training Loss: 0.6122836470603943\n",
      "Epoch: 533, Batch: 80, Training Loss: 0.5197542309761047\n",
      "Epoch: 533, Validation Loss: 1.3079475164413452\n",
      "Epoch: 534, Batch: 40, Training Loss: 0.6002010107040405\n",
      "Epoch: 534, Batch: 80, Training Loss: 0.5917139053344727\n",
      "Epoch: 534, Validation Loss: 1.192488670349121\n",
      "Epoch: 535, Batch: 40, Training Loss: 0.6152139902114868\n",
      "Epoch: 535, Batch: 80, Training Loss: 0.5835134983062744\n",
      "Epoch: 535, Validation Loss: 1.2742130756378174\n",
      "Epoch: 536, Batch: 40, Training Loss: 0.5817311406135559\n",
      "Epoch: 536, Batch: 80, Training Loss: 0.5873956084251404\n",
      "Epoch: 536, Validation Loss: 1.0422390699386597\n",
      "Epoch: 537, Batch: 40, Training Loss: 0.5674633979797363\n",
      "Epoch: 537, Batch: 80, Training Loss: 0.5747054815292358\n",
      "Epoch: 537, Validation Loss: 1.1618386507034302\n",
      "Epoch: 538, Batch: 40, Training Loss: 0.5822880268096924\n",
      "Epoch: 538, Batch: 80, Training Loss: 0.6759160161018372\n",
      "Epoch: 538, Validation Loss: 1.273198127746582\n",
      "Epoch: 539, Batch: 40, Training Loss: 0.6401469111442566\n",
      "Epoch: 539, Batch: 80, Training Loss: 0.5893867015838623\n",
      "Epoch: 539, Validation Loss: 1.2014294862747192\n",
      "Epoch: 540, Batch: 40, Training Loss: 0.6761706471443176\n",
      "Epoch: 540, Batch: 80, Training Loss: 0.5640040636062622\n",
      "Epoch: 540, Validation Loss: 1.2042827606201172\n",
      "Epoch: 541, Batch: 40, Training Loss: 0.5474701523780823\n",
      "Epoch: 541, Batch: 80, Training Loss: 0.6147130727767944\n",
      "Epoch: 541, Validation Loss: 1.2072640657424927\n",
      "Epoch: 542, Batch: 40, Training Loss: 0.655238926410675\n",
      "Epoch: 542, Batch: 80, Training Loss: 0.6611816883087158\n",
      "Epoch: 542, Validation Loss: 1.17180335521698\n",
      "Epoch: 543, Batch: 40, Training Loss: 0.6588872671127319\n",
      "Epoch: 543, Batch: 80, Training Loss: 0.5467685461044312\n",
      "Epoch: 543, Validation Loss: 1.1226680278778076\n",
      "Epoch: 544, Batch: 40, Training Loss: 0.5957642793655396\n",
      "Epoch: 544, Batch: 80, Training Loss: 0.658403754234314\n",
      "Epoch: 544, Validation Loss: 1.1623034477233887\n",
      "Epoch: 545, Batch: 40, Training Loss: 0.5632295608520508\n",
      "Epoch: 545, Batch: 80, Training Loss: 0.572876513004303\n",
      "Epoch: 545, Validation Loss: 1.2376242876052856\n",
      "Epoch: 546, Batch: 40, Training Loss: 0.6113016605377197\n",
      "Epoch: 546, Batch: 80, Training Loss: 0.5957542657852173\n",
      "Epoch: 546, Validation Loss: 1.1663670539855957\n",
      "Epoch: 547, Batch: 40, Training Loss: 0.5878313779830933\n",
      "Epoch: 547, Batch: 80, Training Loss: 0.550047755241394\n",
      "Epoch: 547, Validation Loss: 1.2607969045639038\n",
      "Epoch: 548, Batch: 40, Training Loss: 0.5606129765510559\n",
      "Epoch: 548, Batch: 80, Training Loss: 0.557621419429779\n",
      "Epoch: 548, Validation Loss: 1.1820579767227173\n",
      "Epoch: 549, Batch: 40, Training Loss: 0.6055733561515808\n",
      "Epoch: 549, Batch: 80, Training Loss: 0.6094061136245728\n",
      "Epoch: 549, Validation Loss: 1.1031900644302368\n",
      "Epoch: 550, Batch: 40, Training Loss: 0.5933230519294739\n",
      "Epoch: 550, Batch: 80, Training Loss: 0.5782275199890137\n",
      "Epoch: 550, Validation Loss: 1.0162805318832397\n",
      "Epoch: 551, Batch: 40, Training Loss: 0.6106591820716858\n",
      "Epoch: 551, Batch: 80, Training Loss: 0.6235989332199097\n",
      "Epoch: 551, Validation Loss: 1.2498786449432373\n",
      "Epoch: 552, Batch: 40, Training Loss: 0.5905188322067261\n",
      "Epoch: 552, Batch: 80, Training Loss: 0.558674693107605\n",
      "Epoch: 552, Validation Loss: 1.2688549757003784\n",
      "Epoch: 553, Batch: 40, Training Loss: 0.6464073061943054\n",
      "Epoch: 553, Batch: 80, Training Loss: 0.5879425406455994\n",
      "Epoch: 553, Validation Loss: 1.1675055027008057\n",
      "Epoch: 554, Batch: 40, Training Loss: 0.6500476598739624\n",
      "Epoch: 554, Batch: 80, Training Loss: 0.6197261810302734\n",
      "Epoch: 554, Validation Loss: 1.3276816606521606\n",
      "Epoch: 555, Batch: 40, Training Loss: 0.6199834942817688\n",
      "Epoch: 555, Batch: 80, Training Loss: 0.6308320164680481\n",
      "Epoch: 555, Validation Loss: 1.1275774240493774\n",
      "Epoch: 556, Batch: 40, Training Loss: 0.6464077234268188\n",
      "Epoch: 556, Batch: 80, Training Loss: 0.5997246503829956\n",
      "Epoch: 556, Validation Loss: 1.1957652568817139\n",
      "Epoch: 557, Batch: 40, Training Loss: 0.5409659147262573\n",
      "Epoch: 557, Batch: 80, Training Loss: 0.6316120028495789\n",
      "Epoch: 557, Validation Loss: 1.0835096836090088\n",
      "Epoch: 558, Batch: 40, Training Loss: 0.47647932171821594\n",
      "Epoch: 558, Batch: 80, Training Loss: 0.5845223069190979\n",
      "Epoch: 558, Validation Loss: 1.2776527404785156\n",
      "Epoch: 559, Batch: 40, Training Loss: 0.5648189187049866\n",
      "Epoch: 559, Batch: 80, Training Loss: 0.5834797024726868\n",
      "Epoch: 559, Validation Loss: 1.1488796472549438\n",
      "Epoch: 560, Batch: 40, Training Loss: 0.6264824271202087\n",
      "Epoch: 560, Batch: 80, Training Loss: 0.5832526087760925\n",
      "Epoch: 560, Validation Loss: 1.1967828273773193\n",
      "Epoch: 561, Batch: 40, Training Loss: 0.5741665363311768\n",
      "Epoch: 561, Batch: 80, Training Loss: 0.5609127283096313\n",
      "Epoch: 561, Validation Loss: 1.1268036365509033\n",
      "Epoch: 562, Batch: 40, Training Loss: 0.5780199766159058\n",
      "Epoch: 562, Batch: 80, Training Loss: 0.5857539176940918\n",
      "Epoch: 562, Validation Loss: 1.115023136138916\n",
      "Epoch: 563, Batch: 40, Training Loss: 0.5577443242073059\n",
      "Epoch: 563, Batch: 80, Training Loss: 0.6081846952438354\n",
      "Epoch: 563, Validation Loss: 1.2267751693725586\n",
      "Epoch: 564, Batch: 40, Training Loss: 0.6132903695106506\n",
      "Epoch: 564, Batch: 80, Training Loss: 0.5667106509208679\n",
      "Epoch: 564, Validation Loss: 1.1122373342514038\n",
      "Epoch: 565, Batch: 40, Training Loss: 0.5499506592750549\n",
      "Epoch: 565, Batch: 80, Training Loss: 0.5752997994422913\n",
      "Epoch: 565, Validation Loss: 1.0826236009597778\n",
      "Epoch: 566, Batch: 40, Training Loss: 0.5777575969696045\n",
      "Epoch: 566, Batch: 80, Training Loss: 0.6128436326980591\n",
      "Epoch: 566, Validation Loss: 1.256672739982605\n",
      "Epoch: 567, Batch: 40, Training Loss: 0.5438470840454102\n",
      "Epoch: 567, Batch: 80, Training Loss: 0.5865886211395264\n",
      "Epoch: 567, Validation Loss: 1.2809779644012451\n",
      "Epoch: 568, Batch: 40, Training Loss: 0.637327253818512\n",
      "Epoch: 568, Batch: 80, Training Loss: 0.5550214648246765\n",
      "Epoch: 568, Validation Loss: 1.159506916999817\n",
      "Epoch: 569, Batch: 40, Training Loss: 0.6017478704452515\n",
      "Epoch: 569, Batch: 80, Training Loss: 0.7321063876152039\n",
      "Epoch: 569, Validation Loss: 1.2993923425674438\n",
      "Epoch: 570, Batch: 40, Training Loss: 0.5922831296920776\n",
      "Epoch: 570, Batch: 80, Training Loss: 0.5361859202384949\n",
      "Epoch: 570, Validation Loss: 1.2726209163665771\n",
      "Epoch: 571, Batch: 40, Training Loss: 0.574169397354126\n",
      "Epoch: 571, Batch: 80, Training Loss: 0.556296169757843\n",
      "Epoch: 571, Validation Loss: 1.057054042816162\n",
      "Epoch: 572, Batch: 40, Training Loss: 0.572662353515625\n",
      "Epoch: 572, Batch: 80, Training Loss: 0.5928415656089783\n",
      "Epoch: 572, Validation Loss: 1.2180054187774658\n",
      "Epoch: 573, Batch: 40, Training Loss: 0.5866842269897461\n",
      "Epoch: 573, Batch: 80, Training Loss: 0.6394218802452087\n",
      "Epoch: 573, Validation Loss: 1.1645448207855225\n",
      "Epoch: 574, Batch: 40, Training Loss: 0.6516461968421936\n",
      "Epoch: 574, Batch: 80, Training Loss: 0.6071202158927917\n",
      "Epoch: 574, Validation Loss: 1.154451608657837\n",
      "Epoch: 575, Batch: 40, Training Loss: 0.5546037554740906\n",
      "Epoch: 575, Batch: 80, Training Loss: 0.5882171392440796\n",
      "Epoch: 575, Validation Loss: 1.2412985563278198\n",
      "Epoch: 576, Batch: 40, Training Loss: 0.570619523525238\n",
      "Epoch: 576, Batch: 80, Training Loss: 0.6809305548667908\n",
      "Epoch: 576, Validation Loss: 1.2196190357208252\n",
      "Epoch: 577, Batch: 40, Training Loss: 0.5761390924453735\n",
      "Epoch: 577, Batch: 80, Training Loss: 0.6427964568138123\n",
      "Epoch: 577, Validation Loss: 1.4403423070907593\n",
      "Epoch: 578, Batch: 40, Training Loss: 0.5571638345718384\n",
      "Epoch: 578, Batch: 80, Training Loss: 0.5345466136932373\n",
      "Epoch: 578, Validation Loss: 1.2041616439819336\n",
      "Epoch: 579, Batch: 40, Training Loss: 0.4957987666130066\n",
      "Epoch: 579, Batch: 80, Training Loss: 0.6072027683258057\n",
      "Epoch: 579, Validation Loss: 1.2401171922683716\n",
      "Epoch: 580, Batch: 40, Training Loss: 0.6004252433776855\n",
      "Epoch: 580, Batch: 80, Training Loss: 0.6062077879905701\n",
      "Epoch: 580, Validation Loss: 1.1399155855178833\n",
      "Epoch: 581, Batch: 40, Training Loss: 0.5679227709770203\n",
      "Epoch: 581, Batch: 80, Training Loss: 0.5900449156761169\n",
      "Epoch: 581, Validation Loss: 1.2476023435592651\n",
      "Epoch: 582, Batch: 40, Training Loss: 0.5982303619384766\n",
      "Epoch: 582, Batch: 80, Training Loss: 0.5765004754066467\n",
      "Epoch: 582, Validation Loss: 1.1568917036056519\n",
      "Epoch: 583, Batch: 40, Training Loss: 0.6144714951515198\n",
      "Epoch: 583, Batch: 80, Training Loss: 0.6287152171134949\n",
      "Epoch: 583, Validation Loss: 1.1940083503723145\n",
      "Epoch: 584, Batch: 40, Training Loss: 0.6149258613586426\n",
      "Epoch: 584, Batch: 80, Training Loss: 0.5296366214752197\n",
      "Epoch: 584, Validation Loss: 1.2621766328811646\n",
      "Epoch: 585, Batch: 40, Training Loss: 0.5492790341377258\n",
      "Epoch: 585, Batch: 80, Training Loss: 0.5473068356513977\n",
      "Epoch: 585, Validation Loss: 1.160248041152954\n",
      "Epoch: 586, Batch: 40, Training Loss: 0.6452872157096863\n",
      "Epoch: 586, Batch: 80, Training Loss: 0.6435831785202026\n",
      "Epoch: 586, Validation Loss: 1.1818145513534546\n",
      "Epoch: 587, Batch: 40, Training Loss: 0.5827118754386902\n",
      "Epoch: 587, Batch: 80, Training Loss: 0.6323299407958984\n",
      "Epoch: 587, Validation Loss: 1.195753812789917\n",
      "Epoch: 588, Batch: 40, Training Loss: 0.6361945271492004\n",
      "Epoch: 588, Batch: 80, Training Loss: 0.6260195970535278\n",
      "Epoch: 588, Validation Loss: 1.1542069911956787\n",
      "Epoch: 589, Batch: 40, Training Loss: 0.5466251969337463\n",
      "Epoch: 589, Batch: 80, Training Loss: 0.5647146701812744\n",
      "Epoch: 589, Validation Loss: 1.2460687160491943\n",
      "Epoch: 590, Batch: 40, Training Loss: 0.5460879802703857\n",
      "Epoch: 590, Batch: 80, Training Loss: 0.5689408779144287\n",
      "Epoch: 590, Validation Loss: 1.1047190427780151\n",
      "Epoch: 591, Batch: 40, Training Loss: 0.5512592792510986\n",
      "Epoch: 591, Batch: 80, Training Loss: 0.6232254505157471\n",
      "Epoch: 591, Validation Loss: 1.126327395439148\n",
      "Epoch: 592, Batch: 40, Training Loss: 0.6083880066871643\n",
      "Epoch: 592, Batch: 80, Training Loss: 0.5703567862510681\n",
      "Epoch: 592, Validation Loss: 1.1795545816421509\n",
      "Epoch: 593, Batch: 40, Training Loss: 0.518610954284668\n",
      "Epoch: 593, Batch: 80, Training Loss: 0.6069897413253784\n",
      "Epoch: 593, Validation Loss: 1.3066542148590088\n",
      "Epoch: 594, Batch: 40, Training Loss: 0.5435136556625366\n",
      "Epoch: 594, Batch: 80, Training Loss: 0.6134719848632812\n",
      "Epoch: 594, Validation Loss: 1.2162437438964844\n",
      "Epoch: 595, Batch: 40, Training Loss: 0.5821141004562378\n",
      "Epoch: 595, Batch: 80, Training Loss: 0.608977198600769\n",
      "Epoch: 595, Validation Loss: 1.206207036972046\n",
      "Epoch: 596, Batch: 40, Training Loss: 0.503099262714386\n",
      "Epoch: 596, Batch: 80, Training Loss: 0.5383861660957336\n",
      "Epoch: 596, Validation Loss: 1.3798269033432007\n",
      "Epoch: 597, Batch: 40, Training Loss: 0.6657671928405762\n",
      "Epoch: 597, Batch: 80, Training Loss: 0.5400187969207764\n",
      "Epoch: 597, Validation Loss: 1.2044856548309326\n",
      "Epoch: 598, Batch: 40, Training Loss: 0.588852047920227\n",
      "Epoch: 598, Batch: 80, Training Loss: 0.6126165390014648\n",
      "Epoch: 598, Validation Loss: 1.1871576309204102\n",
      "Epoch: 599, Batch: 40, Training Loss: 0.5524731874465942\n",
      "Epoch: 599, Batch: 80, Training Loss: 0.705075204372406\n",
      "Epoch: 599, Validation Loss: 1.164022445678711\n",
      "Epoch: 600, Batch: 40, Training Loss: 0.5497682094573975\n",
      "Epoch: 600, Batch: 80, Training Loss: 0.5887848138809204\n",
      "Epoch: 600, Validation Loss: 1.1854004859924316\n",
      "Epoch: 601, Batch: 40, Training Loss: 0.49177682399749756\n",
      "Epoch: 601, Batch: 80, Training Loss: 0.616111695766449\n",
      "Epoch: 601, Validation Loss: 1.1219077110290527\n",
      "Epoch: 602, Batch: 40, Training Loss: 0.6402066946029663\n",
      "Epoch: 602, Batch: 80, Training Loss: 0.600315511226654\n",
      "Epoch: 602, Validation Loss: 1.1935946941375732\n",
      "Epoch: 603, Batch: 40, Training Loss: 0.6827141642570496\n",
      "Epoch: 603, Batch: 80, Training Loss: 0.6851372718811035\n",
      "Epoch: 603, Validation Loss: 1.0821266174316406\n",
      "Epoch: 604, Batch: 40, Training Loss: 0.5376941561698914\n",
      "Epoch: 604, Batch: 80, Training Loss: 0.5921961069107056\n",
      "Epoch: 604, Validation Loss: 1.3388047218322754\n",
      "Epoch: 605, Batch: 40, Training Loss: 0.5627705454826355\n",
      "Epoch: 605, Batch: 80, Training Loss: 0.6537349820137024\n",
      "Epoch: 605, Validation Loss: 1.293529987335205\n",
      "Epoch: 606, Batch: 40, Training Loss: 0.5620266795158386\n",
      "Epoch: 606, Batch: 80, Training Loss: 0.5724945068359375\n",
      "Epoch: 606, Validation Loss: 1.3229771852493286\n",
      "Epoch: 607, Batch: 40, Training Loss: 0.5071195363998413\n",
      "Epoch: 607, Batch: 80, Training Loss: 0.5962089896202087\n",
      "Epoch: 607, Validation Loss: 1.3049451112747192\n",
      "Epoch: 608, Batch: 40, Training Loss: 0.5952861309051514\n",
      "Epoch: 608, Batch: 80, Training Loss: 0.6337493658065796\n",
      "Epoch: 608, Validation Loss: 1.1646455526351929\n",
      "Epoch: 609, Batch: 40, Training Loss: 0.6274516582489014\n",
      "Epoch: 609, Batch: 80, Training Loss: 0.6067585349082947\n",
      "Epoch: 609, Validation Loss: 1.2383153438568115\n",
      "Epoch: 610, Batch: 40, Training Loss: 0.6366224884986877\n",
      "Epoch: 610, Batch: 80, Training Loss: 0.596912145614624\n",
      "Epoch: 610, Validation Loss: 1.2279590368270874\n",
      "Epoch: 611, Batch: 40, Training Loss: 0.5746640563011169\n",
      "Epoch: 611, Batch: 80, Training Loss: 0.5582699179649353\n",
      "Epoch: 611, Validation Loss: 1.2392284870147705\n",
      "Epoch: 612, Batch: 40, Training Loss: 0.552003026008606\n",
      "Epoch: 612, Batch: 80, Training Loss: 0.5685628056526184\n",
      "Epoch: 612, Validation Loss: 1.2329928874969482\n",
      "Epoch: 613, Batch: 40, Training Loss: 0.5488170981407166\n",
      "Epoch: 613, Batch: 80, Training Loss: 0.5570659637451172\n",
      "Epoch: 613, Validation Loss: 1.172153353691101\n",
      "Epoch: 614, Batch: 40, Training Loss: 0.5393693447113037\n",
      "Epoch: 614, Batch: 80, Training Loss: 0.5834794044494629\n",
      "Epoch: 614, Validation Loss: 1.2572239637374878\n",
      "Epoch: 615, Batch: 40, Training Loss: 0.6618819832801819\n",
      "Epoch: 615, Batch: 80, Training Loss: 0.577031672000885\n",
      "Epoch: 615, Validation Loss: 1.3158150911331177\n",
      "Epoch: 616, Batch: 40, Training Loss: 0.518966555595398\n",
      "Epoch: 616, Batch: 80, Training Loss: 0.4900470972061157\n",
      "Epoch: 616, Validation Loss: 1.1070611476898193\n",
      "Epoch: 617, Batch: 40, Training Loss: 0.6657358407974243\n",
      "Epoch: 617, Batch: 80, Training Loss: 0.6431013345718384\n",
      "Epoch: 617, Validation Loss: 1.1092307567596436\n",
      "Epoch: 618, Batch: 40, Training Loss: 0.6072640419006348\n",
      "Epoch: 618, Batch: 80, Training Loss: 0.5500136017799377\n",
      "Epoch: 618, Validation Loss: 1.3701130151748657\n",
      "Epoch: 619, Batch: 40, Training Loss: 0.5445342659950256\n",
      "Epoch: 619, Batch: 80, Training Loss: 0.6098488569259644\n",
      "Epoch: 619, Validation Loss: 1.1110202074050903\n",
      "Epoch: 620, Batch: 40, Training Loss: 0.5933098793029785\n",
      "Epoch: 620, Batch: 80, Training Loss: 0.5373314023017883\n",
      "Epoch: 620, Validation Loss: 1.2221684455871582\n",
      "Epoch: 621, Batch: 40, Training Loss: 0.5614603757858276\n",
      "Epoch: 621, Batch: 80, Training Loss: 0.5569214224815369\n",
      "Epoch: 621, Validation Loss: 1.2740281820297241\n",
      "Epoch: 622, Batch: 40, Training Loss: 0.6059385538101196\n",
      "Epoch: 622, Batch: 80, Training Loss: 0.6178027987480164\n",
      "Epoch: 622, Validation Loss: 1.1735985279083252\n",
      "Epoch: 623, Batch: 40, Training Loss: 0.5547148585319519\n",
      "Epoch: 623, Batch: 80, Training Loss: 0.52728670835495\n",
      "Epoch: 623, Validation Loss: 1.273914098739624\n",
      "Epoch: 624, Batch: 40, Training Loss: 0.5668724179267883\n",
      "Epoch: 624, Batch: 80, Training Loss: 0.5608853101730347\n",
      "Epoch: 624, Validation Loss: 1.1485332250595093\n",
      "Epoch: 625, Batch: 40, Training Loss: 0.5022157430648804\n",
      "Epoch: 625, Batch: 80, Training Loss: 0.5378134846687317\n",
      "Epoch: 625, Validation Loss: 1.1450834274291992\n",
      "Epoch: 626, Batch: 40, Training Loss: 0.5170537233352661\n",
      "Epoch: 626, Batch: 80, Training Loss: 0.5507200956344604\n",
      "Epoch: 626, Validation Loss: 1.0179158449172974\n",
      "Epoch: 627, Batch: 40, Training Loss: 0.5760038495063782\n",
      "Epoch: 627, Batch: 80, Training Loss: 0.5352653861045837\n",
      "Epoch: 627, Validation Loss: 1.1789741516113281\n",
      "Epoch: 628, Batch: 40, Training Loss: 0.5345259308815002\n",
      "Epoch: 628, Batch: 80, Training Loss: 0.5420902967453003\n",
      "Epoch: 628, Validation Loss: 1.241445541381836\n",
      "Epoch: 629, Batch: 40, Training Loss: 0.5641041994094849\n",
      "Epoch: 629, Batch: 80, Training Loss: 0.626636803150177\n",
      "Epoch: 629, Validation Loss: 1.0988661050796509\n",
      "Epoch: 630, Batch: 40, Training Loss: 0.5580342411994934\n",
      "Epoch: 630, Batch: 80, Training Loss: 0.5129885673522949\n",
      "Epoch: 630, Validation Loss: 1.2548454999923706\n",
      "Epoch: 631, Batch: 40, Training Loss: 0.5921100378036499\n",
      "Epoch: 631, Batch: 80, Training Loss: 0.5658281445503235\n",
      "Epoch: 631, Validation Loss: 1.1982166767120361\n",
      "Epoch: 632, Batch: 40, Training Loss: 0.6121049523353577\n",
      "Epoch: 632, Batch: 80, Training Loss: 0.6811164617538452\n",
      "Epoch: 632, Validation Loss: 1.2391180992126465\n",
      "Epoch: 633, Batch: 40, Training Loss: 0.6063094139099121\n",
      "Epoch: 633, Batch: 80, Training Loss: 0.45563071966171265\n",
      "Epoch: 633, Validation Loss: 1.2265645265579224\n",
      "Epoch: 634, Batch: 40, Training Loss: 0.5549025535583496\n",
      "Epoch: 634, Batch: 80, Training Loss: 0.6190540790557861\n",
      "Epoch: 634, Validation Loss: 1.1269187927246094\n",
      "Epoch: 635, Batch: 40, Training Loss: 0.5237008333206177\n",
      "Epoch: 635, Batch: 80, Training Loss: 0.6537110209465027\n",
      "Epoch: 635, Validation Loss: 1.1518418788909912\n",
      "Epoch: 636, Batch: 40, Training Loss: 0.5353555679321289\n",
      "Epoch: 636, Batch: 80, Training Loss: 0.5418124198913574\n",
      "Epoch: 636, Validation Loss: 1.1217690706253052\n",
      "Epoch: 637, Batch: 40, Training Loss: 0.6081808805465698\n",
      "Epoch: 637, Batch: 80, Training Loss: 0.581702709197998\n",
      "Epoch: 637, Validation Loss: 1.2489018440246582\n",
      "Epoch: 638, Batch: 40, Training Loss: 0.5874592661857605\n",
      "Epoch: 638, Batch: 80, Training Loss: 0.5708329677581787\n",
      "Epoch: 638, Validation Loss: 1.2266336679458618\n",
      "Epoch: 639, Batch: 40, Training Loss: 0.5335447192192078\n",
      "Epoch: 639, Batch: 80, Training Loss: 0.5993833541870117\n",
      "Epoch: 639, Validation Loss: 1.1049176454544067\n",
      "Epoch: 640, Batch: 40, Training Loss: 0.5801609754562378\n",
      "Epoch: 640, Batch: 80, Training Loss: 0.6048539876937866\n",
      "Epoch: 640, Validation Loss: 1.151729941368103\n",
      "Epoch: 641, Batch: 40, Training Loss: 0.6113399863243103\n",
      "Epoch: 641, Batch: 80, Training Loss: 0.5376508235931396\n",
      "Epoch: 641, Validation Loss: 1.3427654504776\n",
      "Epoch: 642, Batch: 40, Training Loss: 0.5628271102905273\n",
      "Epoch: 642, Batch: 80, Training Loss: 0.5191426873207092\n",
      "Epoch: 642, Validation Loss: 1.2602444887161255\n",
      "Epoch: 643, Batch: 40, Training Loss: 0.5583091378211975\n",
      "Epoch: 643, Batch: 80, Training Loss: 0.5806377530097961\n",
      "Epoch: 643, Validation Loss: 1.1230862140655518\n",
      "Epoch: 644, Batch: 40, Training Loss: 0.6247254014015198\n",
      "Epoch: 644, Batch: 80, Training Loss: 0.5959658026695251\n",
      "Epoch: 644, Validation Loss: 1.2859320640563965\n",
      "Epoch: 645, Batch: 40, Training Loss: 0.5714996457099915\n",
      "Epoch: 645, Batch: 80, Training Loss: 0.6046099066734314\n",
      "Epoch: 645, Validation Loss: 1.1326220035552979\n",
      "Epoch: 646, Batch: 40, Training Loss: 0.5863563418388367\n",
      "Epoch: 646, Batch: 80, Training Loss: 0.6311502456665039\n",
      "Epoch: 646, Validation Loss: 1.194999098777771\n",
      "Epoch: 647, Batch: 40, Training Loss: 0.5795063376426697\n",
      "Epoch: 647, Batch: 80, Training Loss: 0.5310224890708923\n",
      "Epoch: 647, Validation Loss: 1.2847204208374023\n",
      "Epoch: 648, Batch: 40, Training Loss: 0.5858477354049683\n",
      "Epoch: 648, Batch: 80, Training Loss: 0.5593191385269165\n",
      "Epoch: 648, Validation Loss: 1.4344135522842407\n",
      "Epoch: 649, Batch: 40, Training Loss: 0.5651291012763977\n",
      "Epoch: 649, Batch: 80, Training Loss: 0.5744099020957947\n",
      "Epoch: 649, Validation Loss: 1.1170060634613037\n",
      "Epoch: 650, Batch: 40, Training Loss: 0.491318017244339\n",
      "Epoch: 650, Batch: 80, Training Loss: 0.5500583648681641\n",
      "Epoch: 650, Validation Loss: 1.0997923612594604\n",
      "Epoch: 651, Batch: 40, Training Loss: 0.5907750129699707\n",
      "Epoch: 651, Batch: 80, Training Loss: 0.609330415725708\n",
      "Epoch: 651, Validation Loss: 1.0791758298873901\n",
      "Epoch: 652, Batch: 40, Training Loss: 0.5336543917655945\n",
      "Epoch: 652, Batch: 80, Training Loss: 0.5932612419128418\n",
      "Epoch: 652, Validation Loss: 1.3124213218688965\n",
      "Epoch: 653, Batch: 40, Training Loss: 0.5895083546638489\n",
      "Epoch: 653, Batch: 80, Training Loss: 0.5317941308021545\n",
      "Epoch: 653, Validation Loss: 1.173374056816101\n",
      "Epoch: 654, Batch: 40, Training Loss: 0.5654988288879395\n",
      "Epoch: 654, Batch: 80, Training Loss: 0.5311645269393921\n",
      "Epoch: 654, Validation Loss: 1.2662936449050903\n",
      "Epoch: 655, Batch: 40, Training Loss: 0.5116204023361206\n",
      "Epoch: 655, Batch: 80, Training Loss: 0.5540805459022522\n",
      "Epoch: 655, Validation Loss: 1.2502981424331665\n",
      "Epoch: 656, Batch: 40, Training Loss: 0.5574276447296143\n",
      "Epoch: 656, Batch: 80, Training Loss: 0.5788136124610901\n",
      "Epoch: 656, Validation Loss: 1.210293173789978\n",
      "Epoch: 657, Batch: 40, Training Loss: 0.5708851218223572\n",
      "Epoch: 657, Batch: 80, Training Loss: 0.5195049047470093\n",
      "Epoch: 657, Validation Loss: 1.203313946723938\n",
      "Epoch: 658, Batch: 40, Training Loss: 0.5914741158485413\n",
      "Epoch: 658, Batch: 80, Training Loss: 0.6229591965675354\n",
      "Epoch: 658, Validation Loss: 1.449784755706787\n",
      "Epoch: 659, Batch: 40, Training Loss: 0.6025001406669617\n",
      "Epoch: 659, Batch: 80, Training Loss: 0.5341760516166687\n",
      "Epoch: 659, Validation Loss: 1.2352458238601685\n",
      "Epoch: 660, Batch: 40, Training Loss: 0.582986056804657\n",
      "Epoch: 660, Batch: 80, Training Loss: 0.5971614122390747\n",
      "Epoch: 660, Validation Loss: 1.1621990203857422\n",
      "Epoch: 661, Batch: 40, Training Loss: 0.5169624090194702\n",
      "Epoch: 661, Batch: 80, Training Loss: 0.6087566018104553\n",
      "Epoch: 661, Validation Loss: 1.3234093189239502\n",
      "Epoch: 662, Batch: 40, Training Loss: 0.6173774600028992\n",
      "Epoch: 662, Batch: 80, Training Loss: 0.6336877346038818\n",
      "Epoch: 662, Validation Loss: 1.2435728311538696\n",
      "Epoch: 663, Batch: 40, Training Loss: 0.5715134739875793\n",
      "Epoch: 663, Batch: 80, Training Loss: 0.5577130913734436\n",
      "Epoch: 663, Validation Loss: 1.1849770545959473\n",
      "Epoch: 664, Batch: 40, Training Loss: 0.5793054699897766\n",
      "Epoch: 664, Batch: 80, Training Loss: 0.5399994254112244\n",
      "Epoch: 664, Validation Loss: 1.2365189790725708\n",
      "Epoch: 665, Batch: 40, Training Loss: 0.5391319394111633\n",
      "Epoch: 665, Batch: 80, Training Loss: 0.5813997983932495\n",
      "Epoch: 665, Validation Loss: 1.1688226461410522\n",
      "Epoch: 666, Batch: 40, Training Loss: 0.5640643835067749\n",
      "Epoch: 666, Batch: 80, Training Loss: 0.6555313467979431\n",
      "Epoch: 666, Validation Loss: 1.2126182317733765\n",
      "Epoch: 667, Batch: 40, Training Loss: 0.5963287353515625\n",
      "Epoch: 667, Batch: 80, Training Loss: 0.5869373083114624\n",
      "Epoch: 667, Validation Loss: 1.097096562385559\n",
      "Epoch: 668, Batch: 40, Training Loss: 0.566053032875061\n",
      "Epoch: 668, Batch: 80, Training Loss: 0.5370401740074158\n",
      "Epoch: 668, Validation Loss: 1.216984748840332\n",
      "Epoch: 669, Batch: 40, Training Loss: 0.5425737500190735\n",
      "Epoch: 669, Batch: 80, Training Loss: 0.5746691226959229\n",
      "Epoch: 669, Validation Loss: 1.1436907052993774\n",
      "Epoch: 670, Batch: 40, Training Loss: 0.5992432236671448\n",
      "Epoch: 670, Batch: 80, Training Loss: 0.5728035569190979\n",
      "Epoch: 670, Validation Loss: 1.1241239309310913\n",
      "Epoch: 671, Batch: 40, Training Loss: 0.6251112222671509\n",
      "Epoch: 671, Batch: 80, Training Loss: 0.5490800738334656\n",
      "Epoch: 671, Validation Loss: 1.3087048530578613\n",
      "Epoch: 672, Batch: 40, Training Loss: 0.5107961893081665\n",
      "Epoch: 672, Batch: 80, Training Loss: 0.6184653043746948\n",
      "Epoch: 672, Validation Loss: 1.1904041767120361\n",
      "Epoch: 673, Batch: 40, Training Loss: 0.6203164458274841\n",
      "Epoch: 673, Batch: 80, Training Loss: 0.5790160894393921\n",
      "Epoch: 673, Validation Loss: 1.06817626953125\n",
      "Epoch: 674, Batch: 40, Training Loss: 0.5357534289360046\n",
      "Epoch: 674, Batch: 80, Training Loss: 0.6236793398857117\n",
      "Epoch: 674, Validation Loss: 1.0505691766738892\n",
      "Epoch: 675, Batch: 40, Training Loss: 0.5936555862426758\n",
      "Epoch: 675, Batch: 80, Training Loss: 0.6082720160484314\n",
      "Epoch: 675, Validation Loss: 1.0772286653518677\n",
      "Epoch: 676, Batch: 40, Training Loss: 0.5840798616409302\n",
      "Epoch: 676, Batch: 80, Training Loss: 0.5487794280052185\n",
      "Epoch: 676, Validation Loss: 1.1321470737457275\n",
      "Epoch: 677, Batch: 40, Training Loss: 0.6059276461601257\n",
      "Epoch: 677, Batch: 80, Training Loss: 0.4560406804084778\n",
      "Epoch: 677, Validation Loss: 1.255629301071167\n",
      "Epoch: 678, Batch: 40, Training Loss: 0.6342633962631226\n",
      "Epoch: 678, Batch: 80, Training Loss: 0.6125383973121643\n",
      "Epoch: 678, Validation Loss: 1.1494991779327393\n",
      "Epoch: 679, Batch: 40, Training Loss: 0.5626171827316284\n",
      "Epoch: 679, Batch: 80, Training Loss: 0.5878190994262695\n",
      "Epoch: 679, Validation Loss: 1.2246882915496826\n",
      "Epoch: 680, Batch: 40, Training Loss: 0.5103393793106079\n",
      "Epoch: 680, Batch: 80, Training Loss: 0.5536003708839417\n",
      "Epoch: 680, Validation Loss: 1.0822244882583618\n",
      "Epoch: 681, Batch: 40, Training Loss: 0.5712472200393677\n",
      "Epoch: 681, Batch: 80, Training Loss: 0.6142755746841431\n",
      "Epoch: 681, Validation Loss: 1.0092918872833252\n",
      "Epoch: 682, Batch: 40, Training Loss: 0.579866349697113\n",
      "Epoch: 682, Batch: 80, Training Loss: 0.6472393870353699\n",
      "Epoch: 682, Validation Loss: 1.213921308517456\n",
      "Epoch: 683, Batch: 40, Training Loss: 0.5747214555740356\n",
      "Epoch: 683, Batch: 80, Training Loss: 0.6800218820571899\n",
      "Epoch: 683, Validation Loss: 1.1996197700500488\n",
      "Epoch: 684, Batch: 40, Training Loss: 0.5454182028770447\n",
      "Epoch: 684, Batch: 80, Training Loss: 0.5631044507026672\n",
      "Epoch: 684, Validation Loss: 1.3449634313583374\n",
      "Epoch: 685, Batch: 40, Training Loss: 0.5784854292869568\n",
      "Epoch: 685, Batch: 80, Training Loss: 0.5531330704689026\n",
      "Epoch: 685, Validation Loss: 1.2312686443328857\n",
      "Epoch: 686, Batch: 40, Training Loss: 0.5270711183547974\n",
      "Epoch: 686, Batch: 80, Training Loss: 0.6424944400787354\n",
      "Epoch: 686, Validation Loss: 1.1806350946426392\n",
      "Epoch: 687, Batch: 40, Training Loss: 0.6118616461753845\n",
      "Epoch: 687, Batch: 80, Training Loss: 0.6235111951828003\n",
      "Epoch: 687, Validation Loss: 1.3202683925628662\n",
      "Epoch: 688, Batch: 40, Training Loss: 0.6410171985626221\n",
      "Epoch: 688, Batch: 80, Training Loss: 0.6196060180664062\n",
      "Epoch: 688, Validation Loss: 1.3702479600906372\n",
      "Epoch: 689, Batch: 40, Training Loss: 0.5606166124343872\n",
      "Epoch: 689, Batch: 80, Training Loss: 0.5060344338417053\n",
      "Epoch: 689, Validation Loss: 1.2615493535995483\n",
      "Epoch: 690, Batch: 40, Training Loss: 0.5465630888938904\n",
      "Epoch: 690, Batch: 80, Training Loss: 0.6161253452301025\n",
      "Epoch: 690, Validation Loss: 1.2026311159133911\n",
      "Epoch: 691, Batch: 40, Training Loss: 0.5947146415710449\n",
      "Epoch: 691, Batch: 80, Training Loss: 0.6059758067131042\n",
      "Epoch: 691, Validation Loss: 1.277260661125183\n",
      "Epoch: 692, Batch: 40, Training Loss: 0.5775558948516846\n",
      "Epoch: 692, Batch: 80, Training Loss: 0.5792948007583618\n",
      "Epoch: 692, Validation Loss: 1.1551584005355835\n",
      "Epoch: 693, Batch: 40, Training Loss: 0.5798300504684448\n",
      "Epoch: 693, Batch: 80, Training Loss: 0.5069058537483215\n",
      "Epoch: 693, Validation Loss: 1.1305633783340454\n",
      "Epoch: 694, Batch: 40, Training Loss: 0.5620194673538208\n",
      "Epoch: 694, Batch: 80, Training Loss: 0.5869123935699463\n",
      "Epoch: 694, Validation Loss: 1.2067375183105469\n",
      "Epoch: 695, Batch: 40, Training Loss: 0.6048216223716736\n",
      "Epoch: 695, Batch: 80, Training Loss: 0.5650548934936523\n",
      "Epoch: 695, Validation Loss: 1.2133300304412842\n",
      "Epoch: 696, Batch: 40, Training Loss: 0.5901250839233398\n",
      "Epoch: 696, Batch: 80, Training Loss: 0.6021974086761475\n",
      "Epoch: 696, Validation Loss: 1.2521913051605225\n",
      "Epoch: 697, Batch: 40, Training Loss: 0.5381305813789368\n",
      "Epoch: 697, Batch: 80, Training Loss: 0.595901370048523\n",
      "Epoch: 697, Validation Loss: 1.273817539215088\n",
      "Epoch: 698, Batch: 40, Training Loss: 0.566024899482727\n",
      "Epoch: 698, Batch: 80, Training Loss: 0.5725746750831604\n",
      "Epoch: 698, Validation Loss: 1.1587973833084106\n",
      "Epoch: 699, Batch: 40, Training Loss: 0.5194730758666992\n",
      "Epoch: 699, Batch: 80, Training Loss: 0.5051543712615967\n",
      "Epoch: 699, Validation Loss: 1.1671355962753296\n",
      "Epoch: 700, Batch: 40, Training Loss: 0.5097928643226624\n",
      "Epoch: 700, Batch: 80, Training Loss: 0.6017940640449524\n",
      "Epoch: 700, Validation Loss: 1.1722090244293213\n",
      "Epoch: 701, Batch: 40, Training Loss: 0.47760850191116333\n",
      "Epoch: 701, Batch: 80, Training Loss: 0.5141363739967346\n",
      "Epoch: 701, Validation Loss: 1.272062063217163\n",
      "Epoch: 702, Batch: 40, Training Loss: 0.5909985303878784\n",
      "Epoch: 702, Batch: 80, Training Loss: 0.5771216750144958\n",
      "Epoch: 702, Validation Loss: 1.2244117259979248\n",
      "Epoch: 703, Batch: 40, Training Loss: 0.5629962682723999\n",
      "Epoch: 703, Batch: 80, Training Loss: 0.502769410610199\n",
      "Epoch: 703, Validation Loss: 1.2302677631378174\n",
      "Epoch: 704, Batch: 40, Training Loss: 0.5314760804176331\n",
      "Epoch: 704, Batch: 80, Training Loss: 0.5629262924194336\n",
      "Epoch: 704, Validation Loss: 1.244100570678711\n",
      "Epoch: 705, Batch: 40, Training Loss: 0.528311014175415\n",
      "Epoch: 705, Batch: 80, Training Loss: 0.5752589106559753\n",
      "Epoch: 705, Validation Loss: 1.1220123767852783\n",
      "Epoch: 706, Batch: 40, Training Loss: 0.6218770742416382\n",
      "Epoch: 706, Batch: 80, Training Loss: 0.6200122833251953\n",
      "Epoch: 706, Validation Loss: 1.3799012899398804\n",
      "Epoch: 707, Batch: 40, Training Loss: 0.5906044840812683\n",
      "Epoch: 707, Batch: 80, Training Loss: 0.5740275979042053\n",
      "Epoch: 707, Validation Loss: 1.1416372060775757\n",
      "Epoch: 708, Batch: 40, Training Loss: 0.49739429354667664\n",
      "Epoch: 708, Batch: 80, Training Loss: 0.6345309615135193\n",
      "Epoch: 708, Validation Loss: 1.2611045837402344\n",
      "Epoch: 709, Batch: 40, Training Loss: 0.5328033566474915\n",
      "Epoch: 709, Batch: 80, Training Loss: 0.594045102596283\n",
      "Epoch: 709, Validation Loss: 0.972313642501831\n",
      "Epoch: 710, Batch: 40, Training Loss: 0.5296462178230286\n",
      "Epoch: 710, Batch: 80, Training Loss: 0.6270726919174194\n",
      "Epoch: 710, Validation Loss: 1.2303613424301147\n",
      "Epoch: 711, Batch: 40, Training Loss: 0.4974941909313202\n",
      "Epoch: 711, Batch: 80, Training Loss: 0.4962161183357239\n",
      "Epoch: 711, Validation Loss: 1.3065003156661987\n",
      "Epoch: 712, Batch: 40, Training Loss: 0.49219265580177307\n",
      "Epoch: 712, Batch: 80, Training Loss: 0.5551508069038391\n",
      "Epoch: 712, Validation Loss: 1.1179348230361938\n",
      "Epoch: 713, Batch: 40, Training Loss: 0.5193530321121216\n",
      "Epoch: 713, Batch: 80, Training Loss: 0.5763627886772156\n",
      "Epoch: 713, Validation Loss: 1.241969347000122\n",
      "Epoch: 714, Batch: 40, Training Loss: 0.5523892641067505\n",
      "Epoch: 714, Batch: 80, Training Loss: 0.5377249121665955\n",
      "Epoch: 714, Validation Loss: 1.224006175994873\n",
      "Epoch: 715, Batch: 40, Training Loss: 0.5932700634002686\n",
      "Epoch: 715, Batch: 80, Training Loss: 0.6344716548919678\n",
      "Epoch: 715, Validation Loss: 1.095350742340088\n",
      "Epoch: 716, Batch: 40, Training Loss: 0.5741192102432251\n",
      "Epoch: 716, Batch: 80, Training Loss: 0.505788266658783\n",
      "Epoch: 716, Validation Loss: 1.1653399467468262\n",
      "Epoch: 717, Batch: 40, Training Loss: 0.5402548313140869\n",
      "Epoch: 717, Batch: 80, Training Loss: 0.6395311951637268\n",
      "Epoch: 717, Validation Loss: 1.1668627262115479\n",
      "Epoch: 718, Batch: 40, Training Loss: 0.5802412629127502\n",
      "Epoch: 718, Batch: 80, Training Loss: 0.541056752204895\n",
      "Epoch: 718, Validation Loss: 1.2542308568954468\n",
      "Epoch: 719, Batch: 40, Training Loss: 0.5628908276557922\n",
      "Epoch: 719, Batch: 80, Training Loss: 0.57355135679245\n",
      "Epoch: 719, Validation Loss: 1.1554621458053589\n",
      "Epoch: 720, Batch: 40, Training Loss: 0.5581406950950623\n",
      "Epoch: 720, Batch: 80, Training Loss: 0.5659080743789673\n",
      "Epoch: 720, Validation Loss: 1.3054412603378296\n",
      "Epoch: 721, Batch: 40, Training Loss: 0.6097390651702881\n",
      "Epoch: 721, Batch: 80, Training Loss: 0.6088221073150635\n",
      "Epoch: 721, Validation Loss: 1.001159429550171\n",
      "Epoch: 722, Batch: 40, Training Loss: 0.5780833959579468\n",
      "Epoch: 722, Batch: 80, Training Loss: 0.6048215627670288\n",
      "Epoch: 722, Validation Loss: 1.335012435913086\n",
      "Epoch: 723, Batch: 40, Training Loss: 0.5351948738098145\n",
      "Epoch: 723, Batch: 80, Training Loss: 0.5879016518592834\n",
      "Epoch: 723, Validation Loss: 1.2424461841583252\n",
      "Epoch: 724, Batch: 40, Training Loss: 0.5908608436584473\n",
      "Epoch: 724, Batch: 80, Training Loss: 0.5762532949447632\n",
      "Epoch: 724, Validation Loss: 1.1165130138397217\n",
      "Epoch: 725, Batch: 40, Training Loss: 0.5332983136177063\n",
      "Epoch: 725, Batch: 80, Training Loss: 0.5461695194244385\n",
      "Epoch: 725, Validation Loss: 1.2712781429290771\n",
      "Epoch: 726, Batch: 40, Training Loss: 0.5467607378959656\n",
      "Epoch: 726, Batch: 80, Training Loss: 0.5664892792701721\n",
      "Epoch: 726, Validation Loss: 1.0916337966918945\n",
      "Epoch: 727, Batch: 40, Training Loss: 0.6050058603286743\n",
      "Epoch: 727, Batch: 80, Training Loss: 0.5335954427719116\n",
      "Epoch: 727, Validation Loss: 1.1373151540756226\n",
      "Epoch: 728, Batch: 40, Training Loss: 0.5548229217529297\n",
      "Epoch: 728, Batch: 80, Training Loss: 0.5621967911720276\n",
      "Epoch: 728, Validation Loss: 1.2892144918441772\n",
      "Epoch: 729, Batch: 40, Training Loss: 0.532731831073761\n",
      "Epoch: 729, Batch: 80, Training Loss: 0.5896615982055664\n",
      "Epoch: 729, Validation Loss: 1.1671431064605713\n",
      "Epoch: 730, Batch: 40, Training Loss: 0.512964129447937\n",
      "Epoch: 730, Batch: 80, Training Loss: 0.5826221704483032\n",
      "Epoch: 730, Validation Loss: 1.2312496900558472\n",
      "Epoch: 731, Batch: 40, Training Loss: 0.5630754232406616\n",
      "Epoch: 731, Batch: 80, Training Loss: 0.6097050309181213\n",
      "Epoch: 731, Validation Loss: 1.272401213645935\n",
      "Epoch: 732, Batch: 40, Training Loss: 0.47744861245155334\n",
      "Epoch: 732, Batch: 80, Training Loss: 0.5502992272377014\n",
      "Epoch: 732, Validation Loss: 1.2210886478424072\n",
      "Epoch: 733, Batch: 40, Training Loss: 0.5738527178764343\n",
      "Epoch: 733, Batch: 80, Training Loss: 0.5969209671020508\n",
      "Epoch: 733, Validation Loss: 1.182963252067566\n",
      "Epoch: 734, Batch: 40, Training Loss: 0.6130916476249695\n",
      "Epoch: 734, Batch: 80, Training Loss: 0.6028775572776794\n",
      "Epoch: 734, Validation Loss: 1.1973310708999634\n",
      "Epoch: 735, Batch: 40, Training Loss: 0.5004344582557678\n",
      "Epoch: 735, Batch: 80, Training Loss: 0.5271915197372437\n",
      "Epoch: 735, Validation Loss: 1.209505558013916\n",
      "Epoch: 736, Batch: 40, Training Loss: 0.6180368661880493\n",
      "Epoch: 736, Batch: 80, Training Loss: 0.5412532687187195\n",
      "Epoch: 736, Validation Loss: 1.1346338987350464\n",
      "Epoch: 737, Batch: 40, Training Loss: 0.5687956213951111\n",
      "Epoch: 737, Batch: 80, Training Loss: 0.640241265296936\n",
      "Epoch: 737, Validation Loss: 1.254209041595459\n",
      "Epoch: 738, Batch: 40, Training Loss: 0.5005567669868469\n",
      "Epoch: 738, Batch: 80, Training Loss: 0.5609456300735474\n",
      "Epoch: 738, Validation Loss: 1.1252273321151733\n",
      "Epoch: 739, Batch: 40, Training Loss: 0.552541196346283\n",
      "Epoch: 739, Batch: 80, Training Loss: 0.5523771643638611\n",
      "Epoch: 739, Validation Loss: 1.206329345703125\n",
      "Epoch: 740, Batch: 40, Training Loss: 0.5440320372581482\n",
      "Epoch: 740, Batch: 80, Training Loss: 0.5053310990333557\n",
      "Epoch: 740, Validation Loss: 1.1899138689041138\n",
      "Epoch: 741, Batch: 40, Training Loss: 0.5505779981613159\n",
      "Epoch: 741, Batch: 80, Training Loss: 0.5736775994300842\n",
      "Epoch: 741, Validation Loss: 1.1252485513687134\n",
      "Epoch: 742, Batch: 40, Training Loss: 0.5242103934288025\n",
      "Epoch: 742, Batch: 80, Training Loss: 0.5941087007522583\n",
      "Epoch: 742, Validation Loss: 1.07339608669281\n",
      "Epoch: 743, Batch: 40, Training Loss: 0.5954381227493286\n",
      "Epoch: 743, Batch: 80, Training Loss: 0.5275280475616455\n",
      "Epoch: 743, Validation Loss: 1.2007720470428467\n",
      "Epoch: 744, Batch: 40, Training Loss: 0.5879387259483337\n",
      "Epoch: 744, Batch: 80, Training Loss: 0.6462759375572205\n",
      "Epoch: 744, Validation Loss: 1.1766444444656372\n",
      "Epoch: 745, Batch: 40, Training Loss: 0.5645015835762024\n",
      "Epoch: 745, Batch: 80, Training Loss: 0.6367416977882385\n",
      "Epoch: 745, Validation Loss: 1.2223154306411743\n",
      "Epoch: 746, Batch: 40, Training Loss: 0.5410234928131104\n",
      "Epoch: 746, Batch: 80, Training Loss: 0.6149036288261414\n",
      "Epoch: 746, Validation Loss: 1.1569530963897705\n",
      "Epoch: 747, Batch: 40, Training Loss: 0.5324035882949829\n",
      "Epoch: 747, Batch: 80, Training Loss: 0.5914187431335449\n",
      "Epoch: 747, Validation Loss: 1.1911569833755493\n",
      "Epoch: 748, Batch: 40, Training Loss: 0.5289151668548584\n",
      "Epoch: 748, Batch: 80, Training Loss: 0.5670866370201111\n",
      "Epoch: 748, Validation Loss: 1.1982766389846802\n",
      "Epoch: 749, Batch: 40, Training Loss: 0.5149450302124023\n",
      "Epoch: 749, Batch: 80, Training Loss: 0.5425927042961121\n",
      "Epoch: 749, Validation Loss: 1.210111379623413\n",
      "Epoch: 750, Batch: 40, Training Loss: 0.5581823587417603\n",
      "Epoch: 750, Batch: 80, Training Loss: 0.6008685231208801\n",
      "Epoch: 750, Validation Loss: 1.1832609176635742\n",
      "Epoch: 751, Batch: 40, Training Loss: 0.5914719700813293\n",
      "Epoch: 751, Batch: 80, Training Loss: 0.6005477905273438\n",
      "Epoch: 751, Validation Loss: 1.1265619993209839\n",
      "Epoch: 752, Batch: 40, Training Loss: 0.6298606395721436\n",
      "Epoch: 752, Batch: 80, Training Loss: 0.5394513607025146\n",
      "Epoch: 752, Validation Loss: 1.2226744890213013\n",
      "Epoch: 753, Batch: 40, Training Loss: 0.4909432530403137\n",
      "Epoch: 753, Batch: 80, Training Loss: 0.5482074618339539\n",
      "Epoch: 753, Validation Loss: 1.26601243019104\n",
      "Epoch: 754, Batch: 40, Training Loss: 0.5829164385795593\n",
      "Epoch: 754, Batch: 80, Training Loss: 0.5353000164031982\n",
      "Epoch: 754, Validation Loss: 1.0295346975326538\n",
      "Epoch: 755, Batch: 40, Training Loss: 0.5877269506454468\n",
      "Epoch: 755, Batch: 80, Training Loss: 0.6313566565513611\n",
      "Epoch: 755, Validation Loss: 1.0967501401901245\n",
      "Epoch: 756, Batch: 40, Training Loss: 0.4439290463924408\n",
      "Epoch: 756, Batch: 80, Training Loss: 0.5717010498046875\n",
      "Epoch: 756, Validation Loss: 1.1524420976638794\n",
      "Epoch: 757, Batch: 40, Training Loss: 0.4711087942123413\n",
      "Epoch: 757, Batch: 80, Training Loss: 0.6443909406661987\n",
      "Epoch: 757, Validation Loss: 1.23939847946167\n",
      "Epoch: 758, Batch: 40, Training Loss: 0.5711043477058411\n",
      "Epoch: 758, Batch: 80, Training Loss: 0.5981113314628601\n",
      "Epoch: 758, Validation Loss: 1.176255702972412\n",
      "Epoch: 759, Batch: 40, Training Loss: 0.5355657339096069\n",
      "Epoch: 759, Batch: 80, Training Loss: 0.6024332046508789\n",
      "Epoch: 759, Validation Loss: 1.2486631870269775\n",
      "Epoch: 760, Batch: 40, Training Loss: 0.5009779930114746\n",
      "Epoch: 760, Batch: 80, Training Loss: 0.6344739198684692\n",
      "Epoch: 760, Validation Loss: 1.2427736520767212\n",
      "Epoch: 761, Batch: 40, Training Loss: 0.5774675607681274\n",
      "Epoch: 761, Batch: 80, Training Loss: 0.5672089457511902\n",
      "Epoch: 761, Validation Loss: 1.1582916975021362\n",
      "Epoch: 762, Batch: 40, Training Loss: 0.6079508662223816\n",
      "Epoch: 762, Batch: 80, Training Loss: 0.5934485793113708\n",
      "Epoch: 762, Validation Loss: 1.3244528770446777\n",
      "Epoch: 763, Batch: 40, Training Loss: 0.5510892868041992\n",
      "Epoch: 763, Batch: 80, Training Loss: 0.5582050681114197\n",
      "Epoch: 763, Validation Loss: 1.2718216180801392\n",
      "Epoch: 764, Batch: 40, Training Loss: 0.5416296720504761\n",
      "Epoch: 764, Batch: 80, Training Loss: 0.6085801124572754\n",
      "Epoch: 764, Validation Loss: 1.1666176319122314\n",
      "Epoch: 765, Batch: 40, Training Loss: 0.5675350427627563\n",
      "Epoch: 765, Batch: 80, Training Loss: 0.5995932221412659\n",
      "Epoch: 765, Validation Loss: 1.170073390007019\n",
      "Epoch: 766, Batch: 40, Training Loss: 0.5672605037689209\n",
      "Epoch: 766, Batch: 80, Training Loss: 0.4928774833679199\n",
      "Epoch: 766, Validation Loss: 1.154477834701538\n",
      "Epoch: 767, Batch: 40, Training Loss: 0.6038711071014404\n",
      "Epoch: 767, Batch: 80, Training Loss: 0.5403927564620972\n",
      "Epoch: 767, Validation Loss: 1.0918625593185425\n",
      "Epoch: 768, Batch: 40, Training Loss: 0.6073026657104492\n",
      "Epoch: 768, Batch: 80, Training Loss: 0.5506420135498047\n",
      "Epoch: 768, Validation Loss: 1.2208828926086426\n",
      "Epoch: 769, Batch: 40, Training Loss: 0.5846351385116577\n",
      "Epoch: 769, Batch: 80, Training Loss: 0.5589914321899414\n",
      "Epoch: 769, Validation Loss: 1.1722338199615479\n",
      "Epoch: 770, Batch: 40, Training Loss: 0.5711274743080139\n",
      "Epoch: 770, Batch: 80, Training Loss: 0.5470820665359497\n",
      "Epoch: 770, Validation Loss: 1.1308144330978394\n",
      "Epoch: 771, Batch: 40, Training Loss: 0.5469154119491577\n",
      "Epoch: 771, Batch: 80, Training Loss: 0.5550836324691772\n",
      "Epoch: 771, Validation Loss: 1.2237060070037842\n",
      "Epoch: 772, Batch: 40, Training Loss: 0.5728405117988586\n",
      "Epoch: 772, Batch: 80, Training Loss: 0.5863737463951111\n",
      "Epoch: 772, Validation Loss: 1.2579869031906128\n",
      "Epoch: 773, Batch: 40, Training Loss: 0.4847739636898041\n",
      "Epoch: 773, Batch: 80, Training Loss: 0.6226943135261536\n",
      "Epoch: 773, Validation Loss: 1.1965200901031494\n",
      "Epoch: 774, Batch: 40, Training Loss: 0.5678480267524719\n",
      "Epoch: 774, Batch: 80, Training Loss: 0.5875222682952881\n",
      "Epoch: 774, Validation Loss: 1.211279273033142\n",
      "Epoch: 775, Batch: 40, Training Loss: 0.5411516427993774\n",
      "Epoch: 775, Batch: 80, Training Loss: 0.5950332880020142\n",
      "Epoch: 775, Validation Loss: 1.3054637908935547\n",
      "Epoch: 776, Batch: 40, Training Loss: 0.5182808041572571\n",
      "Epoch: 776, Batch: 80, Training Loss: 0.5906224250793457\n",
      "Epoch: 776, Validation Loss: 1.246745228767395\n",
      "Epoch: 777, Batch: 40, Training Loss: 0.5492795705795288\n",
      "Epoch: 777, Batch: 80, Training Loss: 0.5613264441490173\n",
      "Epoch: 777, Validation Loss: 1.3521095514297485\n",
      "Epoch: 778, Batch: 40, Training Loss: 0.5418770909309387\n",
      "Epoch: 778, Batch: 80, Training Loss: 0.6522911787033081\n",
      "Epoch: 778, Validation Loss: 1.1972215175628662\n",
      "Epoch: 779, Batch: 40, Training Loss: 0.5214382410049438\n",
      "Epoch: 779, Batch: 80, Training Loss: 0.6023842692375183\n",
      "Epoch: 779, Validation Loss: 1.1570385694503784\n",
      "Epoch: 780, Batch: 40, Training Loss: 0.540486216545105\n",
      "Epoch: 780, Batch: 80, Training Loss: 0.6034717559814453\n",
      "Epoch: 780, Validation Loss: 1.1618951559066772\n",
      "Epoch: 781, Batch: 40, Training Loss: 0.5869268774986267\n",
      "Epoch: 781, Batch: 80, Training Loss: 0.5735480785369873\n",
      "Epoch: 781, Validation Loss: 1.2945139408111572\n",
      "Epoch: 782, Batch: 40, Training Loss: 0.5096100568771362\n",
      "Epoch: 782, Batch: 80, Training Loss: 0.6126456260681152\n",
      "Epoch: 782, Validation Loss: 1.2543777227401733\n",
      "Epoch: 783, Batch: 40, Training Loss: 0.5499446988105774\n",
      "Epoch: 783, Batch: 80, Training Loss: 0.5039106011390686\n",
      "Epoch: 783, Validation Loss: 1.3146593570709229\n",
      "Epoch: 784, Batch: 40, Training Loss: 0.5802558064460754\n",
      "Epoch: 784, Batch: 80, Training Loss: 0.5062142014503479\n",
      "Epoch: 784, Validation Loss: 1.299486517906189\n",
      "Epoch: 785, Batch: 40, Training Loss: 0.49673083424568176\n",
      "Epoch: 785, Batch: 80, Training Loss: 0.5339143872261047\n",
      "Epoch: 785, Validation Loss: 1.1476868391036987\n",
      "Epoch: 786, Batch: 40, Training Loss: 0.5368728637695312\n",
      "Epoch: 786, Batch: 80, Training Loss: 0.5492658019065857\n",
      "Epoch: 786, Validation Loss: 1.2095979452133179\n",
      "Epoch: 787, Batch: 40, Training Loss: 0.5593034625053406\n",
      "Epoch: 787, Batch: 80, Training Loss: 0.4814148545265198\n",
      "Epoch: 787, Validation Loss: 1.193428635597229\n",
      "Epoch: 788, Batch: 40, Training Loss: 0.5556303262710571\n",
      "Epoch: 788, Batch: 80, Training Loss: 0.6167424917221069\n",
      "Epoch: 788, Validation Loss: 1.1508328914642334\n",
      "Epoch: 789, Batch: 40, Training Loss: 0.6259769797325134\n",
      "Epoch: 789, Batch: 80, Training Loss: 0.5165744423866272\n",
      "Epoch: 789, Validation Loss: 1.1220468282699585\n",
      "Epoch: 790, Batch: 40, Training Loss: 0.5990427732467651\n",
      "Epoch: 790, Batch: 80, Training Loss: 0.5851424336433411\n",
      "Epoch: 790, Validation Loss: 1.242919683456421\n",
      "Epoch: 791, Batch: 40, Training Loss: 0.5584014058113098\n",
      "Epoch: 791, Batch: 80, Training Loss: 0.5452296733856201\n",
      "Epoch: 791, Validation Loss: 1.3059059381484985\n",
      "Epoch: 792, Batch: 40, Training Loss: 0.6319172382354736\n",
      "Epoch: 792, Batch: 80, Training Loss: 0.5556063055992126\n",
      "Epoch: 792, Validation Loss: 1.118683099746704\n",
      "Epoch: 793, Batch: 40, Training Loss: 0.571019172668457\n",
      "Epoch: 793, Batch: 80, Training Loss: 0.5612370371818542\n",
      "Epoch: 793, Validation Loss: 1.1435534954071045\n",
      "Epoch: 794, Batch: 40, Training Loss: 0.5619326233863831\n",
      "Epoch: 794, Batch: 80, Training Loss: 0.5806114673614502\n",
      "Epoch: 794, Validation Loss: 1.210831642150879\n",
      "Epoch: 795, Batch: 40, Training Loss: 0.5304144024848938\n",
      "Epoch: 795, Batch: 80, Training Loss: 0.5835386514663696\n",
      "Epoch: 795, Validation Loss: 1.2301198244094849\n",
      "Epoch: 796, Batch: 40, Training Loss: 0.5559040307998657\n",
      "Epoch: 796, Batch: 80, Training Loss: 0.6303877830505371\n",
      "Epoch: 796, Validation Loss: 1.279929757118225\n",
      "Epoch: 797, Batch: 40, Training Loss: 0.497575968503952\n",
      "Epoch: 797, Batch: 80, Training Loss: 0.5203757882118225\n",
      "Epoch: 797, Validation Loss: 1.2892242670059204\n",
      "Epoch: 798, Batch: 40, Training Loss: 0.5401813387870789\n",
      "Epoch: 798, Batch: 80, Training Loss: 0.5542312264442444\n",
      "Epoch: 798, Validation Loss: 1.2979004383087158\n",
      "Epoch: 799, Batch: 40, Training Loss: 0.5854938626289368\n",
      "Epoch: 799, Batch: 80, Training Loss: 0.4877748489379883\n",
      "Epoch: 799, Validation Loss: 1.060926079750061\n",
      "Epoch: 800, Batch: 40, Training Loss: 0.5558086037635803\n",
      "Epoch: 800, Batch: 80, Training Loss: 0.5909450054168701\n",
      "Epoch: 800, Validation Loss: 1.3570948839187622\n",
      "Epoch: 801, Batch: 40, Training Loss: 0.5725162029266357\n",
      "Epoch: 801, Batch: 80, Training Loss: 0.542722225189209\n",
      "Epoch: 801, Validation Loss: 1.2469764947891235\n",
      "Epoch: 802, Batch: 40, Training Loss: 0.5774998664855957\n",
      "Epoch: 802, Batch: 80, Training Loss: 0.5476039052009583\n",
      "Epoch: 802, Validation Loss: 1.2822643518447876\n",
      "Epoch: 803, Batch: 40, Training Loss: 0.555296778678894\n",
      "Epoch: 803, Batch: 80, Training Loss: 0.6345241069793701\n",
      "Epoch: 803, Validation Loss: 1.1683814525604248\n",
      "Epoch: 804, Batch: 40, Training Loss: 0.6293843984603882\n",
      "Epoch: 804, Batch: 80, Training Loss: 0.6424735188484192\n",
      "Epoch: 804, Validation Loss: 1.209580659866333\n",
      "Epoch: 805, Batch: 40, Training Loss: 0.502571702003479\n",
      "Epoch: 805, Batch: 80, Training Loss: 0.49617934226989746\n",
      "Epoch: 805, Validation Loss: 1.4101319313049316\n",
      "Epoch: 806, Batch: 40, Training Loss: 0.5335736274719238\n",
      "Epoch: 806, Batch: 80, Training Loss: 0.5963925719261169\n",
      "Epoch: 806, Validation Loss: 1.2589167356491089\n",
      "Epoch: 807, Batch: 40, Training Loss: 0.5496716499328613\n",
      "Epoch: 807, Batch: 80, Training Loss: 0.5182779431343079\n",
      "Epoch: 807, Validation Loss: 1.226372241973877\n",
      "Epoch: 808, Batch: 40, Training Loss: 0.5157029628753662\n",
      "Epoch: 808, Batch: 80, Training Loss: 0.5333262085914612\n",
      "Epoch: 808, Validation Loss: 1.2219219207763672\n",
      "Epoch: 809, Batch: 40, Training Loss: 0.5847653746604919\n",
      "Epoch: 809, Batch: 80, Training Loss: 0.5294862985610962\n",
      "Epoch: 809, Validation Loss: 1.161604642868042\n",
      "Epoch: 810, Batch: 40, Training Loss: 0.5638063549995422\n",
      "Epoch: 810, Batch: 80, Training Loss: 0.5370599031448364\n",
      "Epoch: 810, Validation Loss: 1.0744620561599731\n",
      "Epoch: 811, Batch: 40, Training Loss: 0.5202143788337708\n",
      "Epoch: 811, Batch: 80, Training Loss: 0.5581187605857849\n",
      "Epoch: 811, Validation Loss: 1.1418914794921875\n",
      "Epoch: 812, Batch: 40, Training Loss: 0.5107470750808716\n",
      "Epoch: 812, Batch: 80, Training Loss: 0.5383026003837585\n",
      "Epoch: 812, Validation Loss: 1.2330549955368042\n",
      "Epoch: 813, Batch: 40, Training Loss: 0.5100493431091309\n",
      "Epoch: 813, Batch: 80, Training Loss: 0.5369296669960022\n",
      "Epoch: 813, Validation Loss: 1.1992181539535522\n",
      "Epoch: 814, Batch: 40, Training Loss: 0.5659530758857727\n",
      "Epoch: 814, Batch: 80, Training Loss: 0.4926571846008301\n",
      "Epoch: 814, Validation Loss: 1.0466870069503784\n",
      "Epoch: 815, Batch: 40, Training Loss: 0.5150195956230164\n",
      "Epoch: 815, Batch: 80, Training Loss: 0.5672570466995239\n",
      "Epoch: 815, Validation Loss: 1.156498908996582\n",
      "Epoch: 816, Batch: 40, Training Loss: 0.5364959239959717\n",
      "Epoch: 816, Batch: 80, Training Loss: 0.589994490146637\n",
      "Epoch: 816, Validation Loss: 1.1631114482879639\n",
      "Epoch: 817, Batch: 40, Training Loss: 0.5682076811790466\n",
      "Epoch: 817, Batch: 80, Training Loss: 0.46264907717704773\n",
      "Epoch: 817, Validation Loss: 1.1720833778381348\n",
      "Epoch: 818, Batch: 40, Training Loss: 0.5845516920089722\n",
      "Epoch: 818, Batch: 80, Training Loss: 0.5536220669746399\n",
      "Epoch: 818, Validation Loss: 1.3143064975738525\n",
      "Epoch: 819, Batch: 40, Training Loss: 0.5043365359306335\n",
      "Epoch: 819, Batch: 80, Training Loss: 0.5360649228096008\n",
      "Epoch: 819, Validation Loss: 1.311672329902649\n",
      "Epoch: 820, Batch: 40, Training Loss: 0.5474199056625366\n",
      "Epoch: 820, Batch: 80, Training Loss: 0.5281186699867249\n",
      "Epoch: 820, Validation Loss: 1.1548112630844116\n",
      "Epoch: 821, Batch: 40, Training Loss: 0.5007801055908203\n",
      "Epoch: 821, Batch: 80, Training Loss: 0.5016472339630127\n",
      "Epoch: 821, Validation Loss: 1.1967841386795044\n",
      "Epoch: 822, Batch: 40, Training Loss: 0.5545487999916077\n",
      "Epoch: 822, Batch: 80, Training Loss: 0.609288215637207\n",
      "Epoch: 822, Validation Loss: 1.1759806871414185\n",
      "Epoch: 823, Batch: 40, Training Loss: 0.5793894529342651\n",
      "Epoch: 823, Batch: 80, Training Loss: 0.5211817026138306\n",
      "Epoch: 823, Validation Loss: 1.2026885747909546\n",
      "Epoch: 824, Batch: 40, Training Loss: 0.5395956039428711\n",
      "Epoch: 824, Batch: 80, Training Loss: 0.5384371876716614\n",
      "Epoch: 824, Validation Loss: 1.1859745979309082\n",
      "Epoch: 825, Batch: 40, Training Loss: 0.5115211009979248\n",
      "Epoch: 825, Batch: 80, Training Loss: 0.5544790625572205\n",
      "Epoch: 825, Validation Loss: 1.293974757194519\n",
      "Epoch: 826, Batch: 40, Training Loss: 0.5671435594558716\n",
      "Epoch: 826, Batch: 80, Training Loss: 0.5618964433670044\n",
      "Epoch: 826, Validation Loss: 1.2070053815841675\n",
      "Epoch: 827, Batch: 40, Training Loss: 0.5811249613761902\n",
      "Epoch: 827, Batch: 80, Training Loss: 0.5717504620552063\n",
      "Epoch: 827, Validation Loss: 1.2550849914550781\n",
      "Epoch: 828, Batch: 40, Training Loss: 0.5343474745750427\n",
      "Epoch: 828, Batch: 80, Training Loss: 0.5759397745132446\n",
      "Epoch: 828, Validation Loss: 1.3511663675308228\n",
      "Epoch: 829, Batch: 40, Training Loss: 0.514998197555542\n",
      "Epoch: 829, Batch: 80, Training Loss: 0.536227822303772\n",
      "Epoch: 829, Validation Loss: 1.315894603729248\n",
      "Epoch: 830, Batch: 40, Training Loss: 0.5880330204963684\n",
      "Epoch: 830, Batch: 80, Training Loss: 0.4922662377357483\n",
      "Epoch: 830, Validation Loss: 1.143151044845581\n",
      "Epoch: 831, Batch: 40, Training Loss: 0.4808889627456665\n",
      "Epoch: 831, Batch: 80, Training Loss: 0.5560368299484253\n",
      "Epoch: 831, Validation Loss: 1.2349333763122559\n",
      "Epoch: 832, Batch: 40, Training Loss: 0.5432842373847961\n",
      "Epoch: 832, Batch: 80, Training Loss: 0.5386686325073242\n",
      "Epoch: 832, Validation Loss: 1.215238094329834\n",
      "Epoch: 833, Batch: 40, Training Loss: 0.6058999300003052\n",
      "Epoch: 833, Batch: 80, Training Loss: 0.49691343307495117\n",
      "Epoch: 833, Validation Loss: 1.2111984491348267\n",
      "Epoch: 834, Batch: 40, Training Loss: 0.6291464567184448\n",
      "Epoch: 834, Batch: 80, Training Loss: 0.606946587562561\n",
      "Epoch: 834, Validation Loss: 1.1746313571929932\n",
      "Epoch: 835, Batch: 40, Training Loss: 0.5738882422447205\n",
      "Epoch: 835, Batch: 80, Training Loss: 0.583981454372406\n",
      "Epoch: 835, Validation Loss: 1.2256892919540405\n",
      "Epoch: 836, Batch: 40, Training Loss: 0.5335240364074707\n",
      "Epoch: 836, Batch: 80, Training Loss: 0.5697479844093323\n",
      "Epoch: 836, Validation Loss: 1.2907387018203735\n",
      "Epoch: 837, Batch: 40, Training Loss: 0.5252770185470581\n",
      "Epoch: 837, Batch: 80, Training Loss: 0.5499122142791748\n",
      "Epoch: 837, Validation Loss: 1.154848575592041\n",
      "Epoch: 838, Batch: 40, Training Loss: 0.5335423350334167\n",
      "Epoch: 838, Batch: 80, Training Loss: 0.5786904096603394\n",
      "Epoch: 838, Validation Loss: 1.2369426488876343\n",
      "Epoch: 839, Batch: 40, Training Loss: 0.5073534250259399\n",
      "Epoch: 839, Batch: 80, Training Loss: 0.5144702196121216\n",
      "Epoch: 839, Validation Loss: 1.1420626640319824\n",
      "Epoch: 840, Batch: 40, Training Loss: 0.558561384677887\n",
      "Epoch: 840, Batch: 80, Training Loss: 0.4823839068412781\n",
      "Epoch: 840, Validation Loss: 1.221030831336975\n",
      "Epoch: 841, Batch: 40, Training Loss: 0.48675692081451416\n",
      "Epoch: 841, Batch: 80, Training Loss: 0.6314611434936523\n",
      "Epoch: 841, Validation Loss: 1.3190058469772339\n",
      "Epoch: 842, Batch: 40, Training Loss: 0.556879997253418\n",
      "Epoch: 842, Batch: 80, Training Loss: 0.551774263381958\n",
      "Epoch: 842, Validation Loss: 1.1718847751617432\n",
      "Epoch: 843, Batch: 40, Training Loss: 0.5666918158531189\n",
      "Epoch: 843, Batch: 80, Training Loss: 0.4709717035293579\n",
      "Epoch: 843, Validation Loss: 1.2413911819458008\n",
      "Epoch: 844, Batch: 40, Training Loss: 0.5264713764190674\n",
      "Epoch: 844, Batch: 80, Training Loss: 0.5250174403190613\n",
      "Epoch: 844, Validation Loss: 1.1300058364868164\n",
      "Epoch: 845, Batch: 40, Training Loss: 0.5161432027816772\n",
      "Epoch: 845, Batch: 80, Training Loss: 0.5209069848060608\n",
      "Epoch: 845, Validation Loss: 1.267964482307434\n",
      "Epoch: 846, Batch: 40, Training Loss: 0.5328207015991211\n",
      "Epoch: 846, Batch: 80, Training Loss: 0.5427650809288025\n",
      "Epoch: 846, Validation Loss: 1.184324026107788\n",
      "Epoch: 847, Batch: 40, Training Loss: 0.43442824482917786\n",
      "Epoch: 847, Batch: 80, Training Loss: 0.6292887330055237\n",
      "Epoch: 847, Validation Loss: 1.3288607597351074\n",
      "Epoch: 848, Batch: 40, Training Loss: 0.5315252542495728\n",
      "Epoch: 848, Batch: 80, Training Loss: 0.5666943192481995\n",
      "Epoch: 848, Validation Loss: 1.2180216312408447\n",
      "Epoch: 849, Batch: 40, Training Loss: 0.5537115931510925\n",
      "Epoch: 849, Batch: 80, Training Loss: 0.49289464950561523\n",
      "Epoch: 849, Validation Loss: 1.156029462814331\n",
      "Epoch: 850, Batch: 40, Training Loss: 0.6259567737579346\n",
      "Epoch: 850, Batch: 80, Training Loss: 0.5297897458076477\n",
      "Epoch: 850, Validation Loss: 1.2774778604507446\n",
      "Epoch: 851, Batch: 40, Training Loss: 0.5318561792373657\n",
      "Epoch: 851, Batch: 80, Training Loss: 0.4876358211040497\n",
      "Epoch: 851, Validation Loss: 1.1620360612869263\n",
      "Epoch: 852, Batch: 40, Training Loss: 0.5572033524513245\n",
      "Epoch: 852, Batch: 80, Training Loss: 0.5882135033607483\n",
      "Epoch: 852, Validation Loss: 1.2100441455841064\n",
      "Epoch: 853, Batch: 40, Training Loss: 0.5423539876937866\n",
      "Epoch: 853, Batch: 80, Training Loss: 0.5370424389839172\n",
      "Epoch: 853, Validation Loss: 1.2483224868774414\n",
      "Epoch: 854, Batch: 40, Training Loss: 0.5149749517440796\n",
      "Epoch: 854, Batch: 80, Training Loss: 0.5276841521263123\n",
      "Epoch: 854, Validation Loss: 1.3288791179656982\n",
      "Epoch: 855, Batch: 40, Training Loss: 0.613380491733551\n",
      "Epoch: 855, Batch: 80, Training Loss: 0.6112253069877625\n",
      "Epoch: 855, Validation Loss: 1.1273698806762695\n",
      "Epoch: 856, Batch: 40, Training Loss: 0.5671371817588806\n",
      "Epoch: 856, Batch: 80, Training Loss: 0.5240221619606018\n",
      "Epoch: 856, Validation Loss: 1.144049048423767\n",
      "Epoch: 857, Batch: 40, Training Loss: 0.5568494200706482\n",
      "Epoch: 857, Batch: 80, Training Loss: 0.5047375559806824\n",
      "Epoch: 857, Validation Loss: 1.2344162464141846\n",
      "Epoch: 858, Batch: 40, Training Loss: 0.4845050573348999\n",
      "Epoch: 858, Batch: 80, Training Loss: 0.5468077659606934\n",
      "Epoch: 858, Validation Loss: 1.2240104675292969\n",
      "Epoch: 859, Batch: 40, Training Loss: 0.5277794599533081\n",
      "Epoch: 859, Batch: 80, Training Loss: 0.5319712162017822\n",
      "Epoch: 859, Validation Loss: 1.258592128753662\n",
      "Epoch: 860, Batch: 40, Training Loss: 0.6308894157409668\n",
      "Epoch: 860, Batch: 80, Training Loss: 0.5523978471755981\n",
      "Epoch: 860, Validation Loss: 1.0963853597640991\n",
      "Epoch: 861, Batch: 40, Training Loss: 0.5243346691131592\n",
      "Epoch: 861, Batch: 80, Training Loss: 0.5876860022544861\n",
      "Epoch: 861, Validation Loss: 1.2175612449645996\n",
      "Epoch: 862, Batch: 40, Training Loss: 0.5484214425086975\n",
      "Epoch: 862, Batch: 80, Training Loss: 0.5353310704231262\n",
      "Epoch: 862, Validation Loss: 1.3082499504089355\n",
      "Epoch: 863, Batch: 40, Training Loss: 0.526549220085144\n",
      "Epoch: 863, Batch: 80, Training Loss: 0.5921196937561035\n",
      "Epoch: 863, Validation Loss: 1.0785577297210693\n",
      "Epoch: 864, Batch: 40, Training Loss: 0.5665934681892395\n",
      "Epoch: 864, Batch: 80, Training Loss: 0.6367730498313904\n",
      "Epoch: 864, Validation Loss: 1.2269678115844727\n",
      "Epoch: 865, Batch: 40, Training Loss: 0.63055819272995\n",
      "Epoch: 865, Batch: 80, Training Loss: 0.5177232623100281\n",
      "Epoch: 865, Validation Loss: 1.358230471611023\n",
      "Epoch: 866, Batch: 40, Training Loss: 0.5321366190910339\n",
      "Epoch: 866, Batch: 80, Training Loss: 0.5226165652275085\n",
      "Epoch: 866, Validation Loss: 1.2757482528686523\n",
      "Epoch: 867, Batch: 40, Training Loss: 0.5709354281425476\n",
      "Epoch: 867, Batch: 80, Training Loss: 0.5389125943183899\n",
      "Epoch: 867, Validation Loss: 1.2065340280532837\n",
      "Epoch: 868, Batch: 40, Training Loss: 0.5078495144844055\n",
      "Epoch: 868, Batch: 80, Training Loss: 0.5106919407844543\n",
      "Epoch: 868, Validation Loss: 1.2754733562469482\n",
      "Epoch: 869, Batch: 40, Training Loss: 0.4803353548049927\n",
      "Epoch: 869, Batch: 80, Training Loss: 0.5969529747962952\n",
      "Epoch: 869, Validation Loss: 1.1057195663452148\n",
      "Epoch: 870, Batch: 40, Training Loss: 0.5451632142066956\n",
      "Epoch: 870, Batch: 80, Training Loss: 0.5410223603248596\n",
      "Epoch: 870, Validation Loss: 1.2644211053848267\n",
      "Epoch: 871, Batch: 40, Training Loss: 0.5047536492347717\n",
      "Epoch: 871, Batch: 80, Training Loss: 0.5963149666786194\n",
      "Epoch: 871, Validation Loss: 1.2842295169830322\n",
      "Epoch: 872, Batch: 40, Training Loss: 0.6429657936096191\n",
      "Epoch: 872, Batch: 80, Training Loss: 0.6312512755393982\n",
      "Epoch: 872, Validation Loss: 1.1982532739639282\n",
      "Epoch: 873, Batch: 40, Training Loss: 0.5477115511894226\n",
      "Epoch: 873, Batch: 80, Training Loss: 0.5795457363128662\n",
      "Epoch: 873, Validation Loss: 1.2185312509536743\n",
      "Epoch: 874, Batch: 40, Training Loss: 0.5475212931632996\n",
      "Epoch: 874, Batch: 80, Training Loss: 0.5639975070953369\n",
      "Epoch: 874, Validation Loss: 1.2174451351165771\n",
      "Epoch: 875, Batch: 40, Training Loss: 0.5632168650627136\n",
      "Epoch: 875, Batch: 80, Training Loss: 0.5483008027076721\n",
      "Epoch: 875, Validation Loss: 1.0998659133911133\n",
      "Epoch: 876, Batch: 40, Training Loss: 0.539452075958252\n",
      "Epoch: 876, Batch: 80, Training Loss: 0.6043767333030701\n",
      "Epoch: 876, Validation Loss: 1.1852253675460815\n",
      "Epoch: 877, Batch: 40, Training Loss: 0.5691622495651245\n",
      "Epoch: 877, Batch: 80, Training Loss: 0.5218886137008667\n",
      "Epoch: 877, Validation Loss: 1.2051182985305786\n",
      "Epoch: 878, Batch: 40, Training Loss: 0.5956755876541138\n",
      "Epoch: 878, Batch: 80, Training Loss: 0.6101681590080261\n",
      "Epoch: 878, Validation Loss: 1.2547467947006226\n",
      "Epoch: 879, Batch: 40, Training Loss: 0.5482162237167358\n",
      "Epoch: 879, Batch: 80, Training Loss: 0.5388178825378418\n",
      "Epoch: 879, Validation Loss: 1.1691725254058838\n",
      "Epoch: 880, Batch: 40, Training Loss: 0.48391491174697876\n",
      "Epoch: 880, Batch: 80, Training Loss: 0.4897441267967224\n",
      "Epoch: 880, Validation Loss: 1.186834454536438\n",
      "Epoch: 881, Batch: 40, Training Loss: 0.4969520568847656\n",
      "Epoch: 881, Batch: 80, Training Loss: 0.5149457454681396\n",
      "Epoch: 881, Validation Loss: 1.1392711400985718\n",
      "Epoch: 882, Batch: 40, Training Loss: 0.5110529661178589\n",
      "Epoch: 882, Batch: 80, Training Loss: 0.6137408018112183\n",
      "Epoch: 882, Validation Loss: 1.204752802848816\n",
      "Epoch: 883, Batch: 40, Training Loss: 0.49571743607521057\n",
      "Epoch: 883, Batch: 80, Training Loss: 0.5456281900405884\n",
      "Epoch: 883, Validation Loss: 1.2481690645217896\n",
      "Epoch: 884, Batch: 40, Training Loss: 0.4768940806388855\n",
      "Epoch: 884, Batch: 80, Training Loss: 0.6323186755180359\n",
      "Epoch: 884, Validation Loss: 1.2152255773544312\n",
      "Epoch: 885, Batch: 40, Training Loss: 0.5831711888313293\n",
      "Epoch: 885, Batch: 80, Training Loss: 0.5084375143051147\n",
      "Epoch: 885, Validation Loss: 1.1916823387145996\n",
      "Epoch: 886, Batch: 40, Training Loss: 0.5034072399139404\n",
      "Epoch: 886, Batch: 80, Training Loss: 0.5930641293525696\n",
      "Epoch: 886, Validation Loss: 1.269113540649414\n",
      "Epoch: 887, Batch: 40, Training Loss: 0.534232497215271\n",
      "Epoch: 887, Batch: 80, Training Loss: 0.5131540894508362\n",
      "Epoch: 887, Validation Loss: 1.329245924949646\n",
      "Epoch: 888, Batch: 40, Training Loss: 0.5309531688690186\n",
      "Epoch: 888, Batch: 80, Training Loss: 0.5857204794883728\n",
      "Epoch: 888, Validation Loss: 1.130107045173645\n",
      "Epoch: 889, Batch: 40, Training Loss: 0.5325286984443665\n",
      "Epoch: 889, Batch: 80, Training Loss: 0.53716641664505\n",
      "Epoch: 889, Validation Loss: 1.238754391670227\n",
      "Epoch: 890, Batch: 40, Training Loss: 0.5139963030815125\n",
      "Epoch: 890, Batch: 80, Training Loss: 0.5234687924385071\n",
      "Epoch: 890, Validation Loss: 1.2561116218566895\n",
      "Epoch: 891, Batch: 40, Training Loss: 0.5808469653129578\n",
      "Epoch: 891, Batch: 80, Training Loss: 0.6011313199996948\n",
      "Epoch: 891, Validation Loss: 1.2769886255264282\n",
      "Epoch: 892, Batch: 40, Training Loss: 0.5469688177108765\n",
      "Epoch: 892, Batch: 80, Training Loss: 0.4575284719467163\n",
      "Epoch: 892, Validation Loss: 1.1874879598617554\n",
      "Epoch: 893, Batch: 40, Training Loss: 0.6060132384300232\n",
      "Epoch: 893, Batch: 80, Training Loss: 0.6103274822235107\n",
      "Epoch: 893, Validation Loss: 1.3781808614730835\n",
      "Epoch: 894, Batch: 40, Training Loss: 0.6514195799827576\n",
      "Epoch: 894, Batch: 80, Training Loss: 0.5463190674781799\n",
      "Epoch: 894, Validation Loss: 1.2175687551498413\n",
      "Epoch: 895, Batch: 40, Training Loss: 0.5213030576705933\n",
      "Epoch: 895, Batch: 80, Training Loss: 0.5632531642913818\n",
      "Epoch: 895, Validation Loss: 1.1555052995681763\n",
      "Epoch: 896, Batch: 40, Training Loss: 0.4913969337940216\n",
      "Epoch: 896, Batch: 80, Training Loss: 0.5514000654220581\n",
      "Epoch: 896, Validation Loss: 1.29286789894104\n",
      "Epoch: 897, Batch: 40, Training Loss: 0.5673773884773254\n",
      "Epoch: 897, Batch: 80, Training Loss: 0.540776789188385\n",
      "Epoch: 897, Validation Loss: 1.292035698890686\n",
      "Epoch: 898, Batch: 40, Training Loss: 0.5486261248588562\n",
      "Epoch: 898, Batch: 80, Training Loss: 0.5179285407066345\n",
      "Epoch: 898, Validation Loss: 1.207216739654541\n",
      "Epoch: 899, Batch: 40, Training Loss: 0.5474827885627747\n",
      "Epoch: 899, Batch: 80, Training Loss: 0.5373682379722595\n",
      "Epoch: 899, Validation Loss: 1.2112250328063965\n",
      "Epoch: 900, Batch: 40, Training Loss: 0.5745261907577515\n",
      "Epoch: 900, Batch: 80, Training Loss: 0.5232324004173279\n",
      "Epoch: 900, Validation Loss: 1.247556447982788\n",
      "Epoch: 901, Batch: 40, Training Loss: 0.6273922920227051\n",
      "Epoch: 901, Batch: 80, Training Loss: 0.49441787600517273\n",
      "Epoch: 901, Validation Loss: 1.1066335439682007\n",
      "Epoch: 902, Batch: 40, Training Loss: 0.4982774257659912\n",
      "Epoch: 902, Batch: 80, Training Loss: 0.600396990776062\n",
      "Epoch: 902, Validation Loss: 1.21856689453125\n",
      "Epoch: 903, Batch: 40, Training Loss: 0.56180739402771\n",
      "Epoch: 903, Batch: 80, Training Loss: 0.6497765183448792\n",
      "Epoch: 903, Validation Loss: 1.1972074508666992\n",
      "Epoch: 904, Batch: 40, Training Loss: 0.6335515379905701\n",
      "Epoch: 904, Batch: 80, Training Loss: 0.48849231004714966\n",
      "Epoch: 904, Validation Loss: 1.257150650024414\n",
      "Epoch: 905, Batch: 40, Training Loss: 0.578014075756073\n",
      "Epoch: 905, Batch: 80, Training Loss: 0.5549790263175964\n",
      "Epoch: 905, Validation Loss: 1.2812221050262451\n",
      "Epoch: 906, Batch: 40, Training Loss: 0.5934563875198364\n",
      "Epoch: 906, Batch: 80, Training Loss: 0.5305718183517456\n",
      "Epoch: 906, Validation Loss: 1.2449061870574951\n",
      "Epoch: 907, Batch: 40, Training Loss: 0.45409709215164185\n",
      "Epoch: 907, Batch: 80, Training Loss: 0.6013665199279785\n",
      "Epoch: 907, Validation Loss: 1.1934114694595337\n",
      "Epoch: 908, Batch: 40, Training Loss: 0.5212740898132324\n",
      "Epoch: 908, Batch: 80, Training Loss: 0.5506704449653625\n",
      "Epoch: 908, Validation Loss: 1.2189486026763916\n",
      "Epoch: 909, Batch: 40, Training Loss: 0.538015604019165\n",
      "Epoch: 909, Batch: 80, Training Loss: 0.5164264440536499\n",
      "Epoch: 909, Validation Loss: 1.25339674949646\n",
      "Epoch: 910, Batch: 40, Training Loss: 0.544628918170929\n",
      "Epoch: 910, Batch: 80, Training Loss: 0.5438030362129211\n",
      "Epoch: 910, Validation Loss: 1.2285373210906982\n",
      "Epoch: 911, Batch: 40, Training Loss: 0.4604722559452057\n",
      "Epoch: 911, Batch: 80, Training Loss: 0.55711430311203\n",
      "Epoch: 911, Validation Loss: 1.2224310636520386\n",
      "Epoch: 912, Batch: 40, Training Loss: 0.5850695371627808\n",
      "Epoch: 912, Batch: 80, Training Loss: 0.508553147315979\n",
      "Epoch: 912, Validation Loss: 1.2251688241958618\n",
      "Epoch: 913, Batch: 40, Training Loss: 0.48197782039642334\n",
      "Epoch: 913, Batch: 80, Training Loss: 0.5767983198165894\n",
      "Epoch: 913, Validation Loss: 1.2060143947601318\n",
      "Epoch: 914, Batch: 40, Training Loss: 0.529744029045105\n",
      "Epoch: 914, Batch: 80, Training Loss: 0.5449647307395935\n",
      "Epoch: 914, Validation Loss: 1.1912626028060913\n",
      "Epoch: 915, Batch: 40, Training Loss: 0.5600239038467407\n",
      "Epoch: 915, Batch: 80, Training Loss: 0.5538008213043213\n",
      "Epoch: 915, Validation Loss: 1.386902928352356\n",
      "Epoch: 916, Batch: 40, Training Loss: 0.5453286170959473\n",
      "Epoch: 916, Batch: 80, Training Loss: 0.49392056465148926\n",
      "Epoch: 916, Validation Loss: 1.095177173614502\n",
      "Epoch: 917, Batch: 40, Training Loss: 0.5781468749046326\n",
      "Epoch: 917, Batch: 80, Training Loss: 0.5835169553756714\n",
      "Epoch: 917, Validation Loss: 1.230380892753601\n",
      "Epoch: 918, Batch: 40, Training Loss: 0.5240116119384766\n",
      "Epoch: 918, Batch: 80, Training Loss: 0.6194503307342529\n",
      "Epoch: 918, Validation Loss: 1.2493646144866943\n",
      "Epoch: 919, Batch: 40, Training Loss: 0.5963508486747742\n",
      "Epoch: 919, Batch: 80, Training Loss: 0.5485908389091492\n",
      "Epoch: 919, Validation Loss: 1.2785977125167847\n",
      "Epoch: 920, Batch: 40, Training Loss: 0.4548474848270416\n",
      "Epoch: 920, Batch: 80, Training Loss: 0.5312433242797852\n",
      "Epoch: 920, Validation Loss: 1.0827738046646118\n",
      "Epoch: 921, Batch: 40, Training Loss: 0.5443989634513855\n",
      "Epoch: 921, Batch: 80, Training Loss: 0.5417155623435974\n",
      "Epoch: 921, Validation Loss: 1.12888503074646\n",
      "Epoch: 922, Batch: 40, Training Loss: 0.6049579977989197\n",
      "Epoch: 922, Batch: 80, Training Loss: 0.5746881365776062\n",
      "Epoch: 922, Validation Loss: 1.2340960502624512\n",
      "Epoch: 923, Batch: 40, Training Loss: 0.6279680728912354\n",
      "Epoch: 923, Batch: 80, Training Loss: 0.580098032951355\n",
      "Epoch: 923, Validation Loss: 1.1412936449050903\n",
      "Epoch: 924, Batch: 40, Training Loss: 0.530174970626831\n",
      "Epoch: 924, Batch: 80, Training Loss: 0.5554923415184021\n",
      "Epoch: 924, Validation Loss: 1.1529715061187744\n",
      "Epoch: 925, Batch: 40, Training Loss: 0.5886309146881104\n",
      "Epoch: 925, Batch: 80, Training Loss: 0.5375320911407471\n",
      "Epoch: 925, Validation Loss: 1.2039891481399536\n",
      "Epoch: 926, Batch: 40, Training Loss: 0.5217369198799133\n",
      "Epoch: 926, Batch: 80, Training Loss: 0.5826972723007202\n",
      "Epoch: 926, Validation Loss: 1.2214384078979492\n",
      "Epoch: 927, Batch: 40, Training Loss: 0.5776191353797913\n",
      "Epoch: 927, Batch: 80, Training Loss: 0.5635568499565125\n",
      "Epoch: 927, Validation Loss: 1.1696608066558838\n",
      "Epoch: 928, Batch: 40, Training Loss: 0.5592504143714905\n",
      "Epoch: 928, Batch: 80, Training Loss: 0.5852649807929993\n",
      "Epoch: 928, Validation Loss: 1.1949279308319092\n",
      "Epoch: 929, Batch: 40, Training Loss: 0.5912206768989563\n",
      "Epoch: 929, Batch: 80, Training Loss: 0.576200544834137\n",
      "Epoch: 929, Validation Loss: 1.330618143081665\n",
      "Epoch: 930, Batch: 40, Training Loss: 0.5025249123573303\n",
      "Epoch: 930, Batch: 80, Training Loss: 0.5825783014297485\n",
      "Epoch: 930, Validation Loss: 1.1388897895812988\n",
      "Epoch: 931, Batch: 40, Training Loss: 0.5527523756027222\n",
      "Epoch: 931, Batch: 80, Training Loss: 0.5660492777824402\n",
      "Epoch: 931, Validation Loss: 1.1957461833953857\n",
      "Epoch: 932, Batch: 40, Training Loss: 0.47812822461128235\n",
      "Epoch: 932, Batch: 80, Training Loss: 0.5605801939964294\n",
      "Epoch: 932, Validation Loss: 1.0740426778793335\n",
      "Epoch: 933, Batch: 40, Training Loss: 0.44155868887901306\n",
      "Epoch: 933, Batch: 80, Training Loss: 0.5147296786308289\n",
      "Epoch: 933, Validation Loss: 1.3336304426193237\n",
      "Epoch: 934, Batch: 40, Training Loss: 0.5979391932487488\n",
      "Epoch: 934, Batch: 80, Training Loss: 0.5721648335456848\n",
      "Epoch: 934, Validation Loss: 1.1505862474441528\n",
      "Epoch: 935, Batch: 40, Training Loss: 0.5551102161407471\n",
      "Epoch: 935, Batch: 80, Training Loss: 0.5301134586334229\n",
      "Epoch: 935, Validation Loss: 1.193988561630249\n",
      "Epoch: 936, Batch: 40, Training Loss: 0.6168844103813171\n",
      "Epoch: 936, Batch: 80, Training Loss: 0.5259332060813904\n",
      "Epoch: 936, Validation Loss: 1.1447123289108276\n",
      "Epoch: 937, Batch: 40, Training Loss: 0.505382776260376\n",
      "Epoch: 937, Batch: 80, Training Loss: 0.5318218469619751\n",
      "Epoch: 937, Validation Loss: 1.0568203926086426\n",
      "Epoch: 938, Batch: 40, Training Loss: 0.606206476688385\n",
      "Epoch: 938, Batch: 80, Training Loss: 0.5256224274635315\n",
      "Epoch: 938, Validation Loss: 1.0917047262191772\n",
      "Epoch: 939, Batch: 40, Training Loss: 0.5723521709442139\n",
      "Epoch: 939, Batch: 80, Training Loss: 0.4959603548049927\n",
      "Epoch: 939, Validation Loss: 1.2432520389556885\n",
      "Epoch: 940, Batch: 40, Training Loss: 0.5634943246841431\n",
      "Epoch: 940, Batch: 80, Training Loss: 0.5018278360366821\n",
      "Epoch: 940, Validation Loss: 1.2634598016738892\n",
      "Epoch: 941, Batch: 40, Training Loss: 0.5833988189697266\n",
      "Epoch: 941, Batch: 80, Training Loss: 0.5059061050415039\n",
      "Epoch: 941, Validation Loss: 1.117987036705017\n",
      "Epoch: 942, Batch: 40, Training Loss: 0.624452531337738\n",
      "Epoch: 942, Batch: 80, Training Loss: 0.577756941318512\n",
      "Epoch: 942, Validation Loss: 1.2270640134811401\n",
      "Epoch: 943, Batch: 40, Training Loss: 0.6633177995681763\n",
      "Epoch: 943, Batch: 80, Training Loss: 0.5260838270187378\n",
      "Epoch: 943, Validation Loss: 1.0769588947296143\n",
      "Epoch: 944, Batch: 40, Training Loss: 0.49196094274520874\n",
      "Epoch: 944, Batch: 80, Training Loss: 0.48176446557044983\n",
      "Epoch: 944, Validation Loss: 1.2581019401550293\n",
      "Epoch: 945, Batch: 40, Training Loss: 0.5713500380516052\n",
      "Epoch: 945, Batch: 80, Training Loss: 0.5503118634223938\n",
      "Epoch: 945, Validation Loss: 1.304007649421692\n",
      "Epoch: 946, Batch: 40, Training Loss: 0.5722890496253967\n",
      "Epoch: 946, Batch: 80, Training Loss: 0.5996989607810974\n",
      "Epoch: 946, Validation Loss: 1.2125080823898315\n",
      "Epoch: 947, Batch: 40, Training Loss: 0.5393679738044739\n",
      "Epoch: 947, Batch: 80, Training Loss: 0.5338248014450073\n",
      "Epoch: 947, Validation Loss: 1.2781403064727783\n",
      "Epoch: 948, Batch: 40, Training Loss: 0.5854321122169495\n",
      "Epoch: 948, Batch: 80, Training Loss: 0.556888997554779\n",
      "Epoch: 948, Validation Loss: 1.325632095336914\n",
      "Epoch: 949, Batch: 40, Training Loss: 0.5370950698852539\n",
      "Epoch: 949, Batch: 80, Training Loss: 0.5588042736053467\n",
      "Epoch: 949, Validation Loss: 1.213155746459961\n",
      "Epoch: 950, Batch: 40, Training Loss: 0.5256879329681396\n",
      "Epoch: 950, Batch: 80, Training Loss: 0.5855343341827393\n",
      "Epoch: 950, Validation Loss: 1.2496521472930908\n",
      "Epoch: 951, Batch: 40, Training Loss: 0.5550695061683655\n",
      "Epoch: 951, Batch: 80, Training Loss: 0.5624700784683228\n",
      "Epoch: 951, Validation Loss: 1.2567213773727417\n",
      "Epoch: 952, Batch: 40, Training Loss: 0.577686607837677\n",
      "Epoch: 952, Batch: 80, Training Loss: 0.513861894607544\n",
      "Epoch: 952, Validation Loss: 1.1875340938568115\n",
      "Epoch: 953, Batch: 40, Training Loss: 0.546193540096283\n",
      "Epoch: 953, Batch: 80, Training Loss: 0.542542576789856\n",
      "Epoch: 953, Validation Loss: 1.2864813804626465\n",
      "Epoch: 954, Batch: 40, Training Loss: 0.41323909163475037\n",
      "Epoch: 954, Batch: 80, Training Loss: 0.612949013710022\n",
      "Epoch: 954, Validation Loss: 1.2157983779907227\n",
      "Epoch: 955, Batch: 40, Training Loss: 0.4497113525867462\n",
      "Epoch: 955, Batch: 80, Training Loss: 0.5613754391670227\n",
      "Epoch: 955, Validation Loss: 1.2841843366622925\n",
      "Epoch: 956, Batch: 40, Training Loss: 0.5903233885765076\n",
      "Epoch: 956, Batch: 80, Training Loss: 0.4697074592113495\n",
      "Epoch: 956, Validation Loss: 1.1596976518630981\n",
      "Epoch: 957, Batch: 40, Training Loss: 0.5279942154884338\n",
      "Epoch: 957, Batch: 80, Training Loss: 0.4825116991996765\n",
      "Epoch: 957, Validation Loss: 1.2303165197372437\n",
      "Epoch: 958, Batch: 40, Training Loss: 0.5609124302864075\n",
      "Epoch: 958, Batch: 80, Training Loss: 0.5918446779251099\n",
      "Epoch: 958, Validation Loss: 1.138964056968689\n",
      "Epoch: 959, Batch: 40, Training Loss: 0.5479676723480225\n",
      "Epoch: 959, Batch: 80, Training Loss: 0.56366366147995\n",
      "Epoch: 959, Validation Loss: 1.1193076372146606\n",
      "Epoch: 960, Batch: 40, Training Loss: 0.515300989151001\n",
      "Epoch: 960, Batch: 80, Training Loss: 0.5912715792655945\n",
      "Epoch: 960, Validation Loss: 1.3237370252609253\n",
      "Epoch: 961, Batch: 40, Training Loss: 0.5000460147857666\n",
      "Epoch: 961, Batch: 80, Training Loss: 0.5693649649620056\n",
      "Epoch: 961, Validation Loss: 1.1936225891113281\n",
      "Epoch: 962, Batch: 40, Training Loss: 0.5800748467445374\n",
      "Epoch: 962, Batch: 80, Training Loss: 0.5221190452575684\n",
      "Epoch: 962, Validation Loss: 1.3295269012451172\n",
      "Epoch: 963, Batch: 40, Training Loss: 0.6190380454063416\n",
      "Epoch: 963, Batch: 80, Training Loss: 0.5732417106628418\n",
      "Epoch: 963, Validation Loss: 1.2621196508407593\n",
      "Epoch: 964, Batch: 40, Training Loss: 0.5018411874771118\n",
      "Epoch: 964, Batch: 80, Training Loss: 0.5818279385566711\n",
      "Epoch: 964, Validation Loss: 1.3036212921142578\n",
      "Epoch: 965, Batch: 40, Training Loss: 0.5102177262306213\n",
      "Epoch: 965, Batch: 80, Training Loss: 0.506279468536377\n",
      "Epoch: 965, Validation Loss: 1.1994876861572266\n",
      "Epoch: 966, Batch: 40, Training Loss: 0.5559585690498352\n",
      "Epoch: 966, Batch: 80, Training Loss: 0.5745643973350525\n",
      "Epoch: 966, Validation Loss: 1.1790462732315063\n",
      "Epoch: 967, Batch: 40, Training Loss: 0.536228358745575\n",
      "Epoch: 967, Batch: 80, Training Loss: 0.6186615228652954\n",
      "Epoch: 967, Validation Loss: 1.107154130935669\n",
      "Epoch: 968, Batch: 40, Training Loss: 0.5375872850418091\n",
      "Epoch: 968, Batch: 80, Training Loss: 0.5584143400192261\n",
      "Epoch: 968, Validation Loss: 1.3607155084609985\n",
      "Epoch: 969, Batch: 40, Training Loss: 0.5090363621711731\n",
      "Epoch: 969, Batch: 80, Training Loss: 0.4993581473827362\n",
      "Epoch: 969, Validation Loss: 1.192558765411377\n",
      "Epoch: 970, Batch: 40, Training Loss: 0.5588352084159851\n",
      "Epoch: 970, Batch: 80, Training Loss: 0.5255792737007141\n",
      "Epoch: 970, Validation Loss: 1.2361111640930176\n",
      "Epoch: 971, Batch: 40, Training Loss: 0.5278772711753845\n",
      "Epoch: 971, Batch: 80, Training Loss: 0.44948169589042664\n",
      "Epoch: 971, Validation Loss: 1.3320345878601074\n",
      "Epoch: 972, Batch: 40, Training Loss: 0.505127489566803\n",
      "Epoch: 972, Batch: 80, Training Loss: 0.48538193106651306\n",
      "Epoch: 972, Validation Loss: 1.30641770362854\n",
      "Epoch: 973, Batch: 40, Training Loss: 0.5312453508377075\n",
      "Epoch: 973, Batch: 80, Training Loss: 0.5122570395469666\n",
      "Epoch: 973, Validation Loss: 1.1734528541564941\n",
      "Epoch: 974, Batch: 40, Training Loss: 0.5999631881713867\n",
      "Epoch: 974, Batch: 80, Training Loss: 0.5754613876342773\n",
      "Epoch: 974, Validation Loss: 1.1839146614074707\n",
      "Epoch: 975, Batch: 40, Training Loss: 0.5178227424621582\n",
      "Epoch: 975, Batch: 80, Training Loss: 0.556113064289093\n",
      "Epoch: 975, Validation Loss: 1.1246790885925293\n",
      "Epoch: 976, Batch: 40, Training Loss: 0.6039703488349915\n",
      "Epoch: 976, Batch: 80, Training Loss: 0.5864248275756836\n",
      "Epoch: 976, Validation Loss: 1.1803274154663086\n",
      "Epoch: 977, Batch: 40, Training Loss: 0.5333187580108643\n",
      "Epoch: 977, Batch: 80, Training Loss: 0.5938812494277954\n",
      "Epoch: 977, Validation Loss: 1.096185326576233\n",
      "Epoch: 978, Batch: 40, Training Loss: 0.6040821671485901\n",
      "Epoch: 978, Batch: 80, Training Loss: 0.4507860243320465\n",
      "Epoch: 978, Validation Loss: 1.2070839405059814\n",
      "Epoch: 979, Batch: 40, Training Loss: 0.5266604423522949\n",
      "Epoch: 979, Batch: 80, Training Loss: 0.5639925003051758\n",
      "Epoch: 979, Validation Loss: 1.2256708145141602\n",
      "Epoch: 980, Batch: 40, Training Loss: 0.4962843954563141\n",
      "Epoch: 980, Batch: 80, Training Loss: 0.5778639316558838\n",
      "Epoch: 980, Validation Loss: 1.2566673755645752\n",
      "Epoch: 981, Batch: 40, Training Loss: 0.4573499262332916\n",
      "Epoch: 981, Batch: 80, Training Loss: 0.5649508237838745\n",
      "Epoch: 981, Validation Loss: 1.2050460577011108\n",
      "Epoch: 982, Batch: 40, Training Loss: 0.5279322862625122\n",
      "Epoch: 982, Batch: 80, Training Loss: 0.5985062122344971\n",
      "Epoch: 982, Validation Loss: 1.303711175918579\n",
      "Epoch: 983, Batch: 40, Training Loss: 0.5478925108909607\n",
      "Epoch: 983, Batch: 80, Training Loss: 0.5592585802078247\n",
      "Epoch: 983, Validation Loss: 1.3718552589416504\n",
      "Epoch: 984, Batch: 40, Training Loss: 0.502522885799408\n",
      "Epoch: 984, Batch: 80, Training Loss: 0.5127472281455994\n",
      "Epoch: 984, Validation Loss: 1.2520040273666382\n",
      "Epoch: 985, Batch: 40, Training Loss: 0.5456151366233826\n",
      "Epoch: 985, Batch: 80, Training Loss: 0.5905064940452576\n",
      "Epoch: 985, Validation Loss: 1.2964060306549072\n",
      "Epoch: 986, Batch: 40, Training Loss: 0.4777458608150482\n",
      "Epoch: 986, Batch: 80, Training Loss: 0.5625180006027222\n",
      "Epoch: 986, Validation Loss: 1.304230809211731\n",
      "Epoch: 987, Batch: 40, Training Loss: 0.6090706586837769\n",
      "Epoch: 987, Batch: 80, Training Loss: 0.5302972793579102\n",
      "Epoch: 987, Validation Loss: 1.39223313331604\n",
      "Epoch: 988, Batch: 40, Training Loss: 0.5700181126594543\n",
      "Epoch: 988, Batch: 80, Training Loss: 0.5247775316238403\n",
      "Epoch: 988, Validation Loss: 1.11360764503479\n",
      "Epoch: 989, Batch: 40, Training Loss: 0.5457341074943542\n",
      "Epoch: 989, Batch: 80, Training Loss: 0.5492942929267883\n",
      "Epoch: 989, Validation Loss: 1.2457789182662964\n",
      "Epoch: 990, Batch: 40, Training Loss: 0.5347065329551697\n",
      "Epoch: 990, Batch: 80, Training Loss: 0.5555874109268188\n",
      "Epoch: 990, Validation Loss: 1.2282179594039917\n",
      "Epoch: 991, Batch: 40, Training Loss: 0.4705747067928314\n",
      "Epoch: 991, Batch: 80, Training Loss: 0.5673378705978394\n",
      "Epoch: 991, Validation Loss: 1.1210393905639648\n",
      "Epoch: 992, Batch: 40, Training Loss: 0.6300053596496582\n",
      "Epoch: 992, Batch: 80, Training Loss: 0.5355351567268372\n",
      "Epoch: 992, Validation Loss: 1.1925679445266724\n",
      "Epoch: 993, Batch: 40, Training Loss: 0.5469553470611572\n",
      "Epoch: 993, Batch: 80, Training Loss: 0.5618120431900024\n",
      "Epoch: 993, Validation Loss: 1.3313379287719727\n",
      "Epoch: 994, Batch: 40, Training Loss: 0.5144325494766235\n",
      "Epoch: 994, Batch: 80, Training Loss: 0.5956968069076538\n",
      "Epoch: 994, Validation Loss: 1.189149260520935\n",
      "Epoch: 995, Batch: 40, Training Loss: 0.6597833633422852\n",
      "Epoch: 995, Batch: 80, Training Loss: 0.5803740620613098\n",
      "Epoch: 995, Validation Loss: 1.1973413228988647\n",
      "Epoch: 996, Batch: 40, Training Loss: 0.4666183888912201\n",
      "Epoch: 996, Batch: 80, Training Loss: 0.6193265914916992\n",
      "Epoch: 996, Validation Loss: 1.291456937789917\n",
      "Epoch: 997, Batch: 40, Training Loss: 0.598223865032196\n",
      "Epoch: 997, Batch: 80, Training Loss: 0.5607506632804871\n",
      "Epoch: 997, Validation Loss: 1.200971245765686\n",
      "Epoch: 998, Batch: 40, Training Loss: 0.5899796485900879\n",
      "Epoch: 998, Batch: 80, Training Loss: 0.5095406770706177\n",
      "Epoch: 998, Validation Loss: 1.2752015590667725\n",
      "Epoch: 999, Batch: 40, Training Loss: 0.5218266248703003\n",
      "Epoch: 999, Batch: 80, Training Loss: 0.6063757538795471\n",
      "Epoch: 999, Validation Loss: 1.1430730819702148\n",
      "Training took: 7784.838652849197 seconds, or: 129.74731088081995 minutes!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Variables to track things\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "lowest_losses = [float('inf'), float('inf'), float('inf')] # each elem = ()\n",
    "# accuracy of train_corr[0] = train_corr[0]*100 / len(train_data)\n",
    "train_corr = []\n",
    "valid_corr = []\n",
    "\n",
    "# Epoch loop\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_corr_count = 0\n",
    "    valid_corr_count = 0\n",
    "    # Batch training\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "        # start our batches at 1: so batch numbers are in the range [1, batchsize] instead of [0, batchsize-1]\n",
    "        b += 1\n",
    "        # make a prediction on the batch\n",
    "        y_pred = cnn2(X_train) # X_train is dimension [batch_size, 3, 32, 32], making y_pred [batchsize, 10]\n",
    "        # Find the loss using the loss function\n",
    "        loss = criterion2(y_pred, y_train)\n",
    "        # Computes the back-propagation for each parameter:\n",
    "        loss.backward()\n",
    "        # Applies the update for each parameter\n",
    "        optimizer2.step()\n",
    "        # Cleanup step for Pytorch\n",
    "        optimizer2.zero_grad()\n",
    "        \n",
    "        # Keep track of the accuracy of the predictions\n",
    "\n",
    "        # predicted class gives us the index of most probability: i.e. what class the NN predicts the img is\n",
    "        predicted_class = torch.max(y_pred.data, 1)[1]\n",
    "        # batch_corr_count gives us the number of correct guesses in the batch\n",
    "        batch_corr_count = (predicted_class == y_train).sum()\n",
    "        # add that to the total number of correct guesses in the epoch\n",
    "        train_corr_count += batch_corr_count\n",
    "\n",
    "        # Print something so we can monitor the progress of the training\n",
    "        if b % int(len(train_loader) / 2) == 0:\n",
    "            print(f'Epoch: {i}, Batch: {b}, Training Loss: {loss.item()}') # loss.item() = loss[0], which is the value of loss\n",
    "\n",
    "    # Add the final epoch accuracy and loss to train acc and train losses arrays\n",
    "    train_corr.append(train_corr_count)\n",
    "    train_losses.append(loss)\n",
    "\n",
    "    # test on validation set: NO WEIGHT UPDATES\n",
    "    with torch.no_grad():\n",
    "        for b, (X_valid, y_valid) in enumerate(valid_loader):\n",
    "            y_pred = cnn2(X_valid)\n",
    "            predicted_class = torch.max(y_pred.data, 1)[1]\n",
    "            batch_corr_count = (predicted_class == y_valid).sum()\n",
    "            valid_corr_count += batch_corr_count\n",
    "    # add final loss to valid_losses\n",
    "    loss = criterion2(y_pred, y_valid)\n",
    "    valid_losses.append(loss)\n",
    "\n",
    "    # save models with highest performance\n",
    "\n",
    "    # save cur model\n",
    "    torch.save(cnn2.state_dict(), 'cnnbest.pt')\n",
    "\n",
    "    # Check if the current loss is lower than the highest of the three saved losses\n",
    "    if loss < lowest_losses[0]:\n",
    "        # Shift the current lowest losses\n",
    "        lowest_losses = [loss, lowest_losses[0], lowest_losses[1]]\n",
    "        \n",
    "        # Rename files to reflect the new order of losses\n",
    "        if os.path.exists(\"cnnbest2.pt\"):\n",
    "            shutil.move(\"cnnbest2.pt\", \"cnnbest3.pt\")\n",
    "        if os.path.exists(\"cnnbest1.pt\"):\n",
    "            shutil.move(\"cnnbest1.pt\", \"cnnbest2.pt\")\n",
    "        shutil.move(\"cnnbest.pt\", \"cnnbest1.pt\")\n",
    "    \n",
    "    elif loss < lowest_losses[1]:\n",
    "        # Shift the second and third lowest losses\n",
    "        lowest_losses = [lowest_losses[0], loss, lowest_losses[1]]\n",
    "        \n",
    "        # Rename files to reflect the new order of losses\n",
    "        if os.path.exists(\"cnnbest2.pt\"):\n",
    "            shutil.move(\"cnnbest2.pt\", \"cnnbest3.pt\")\n",
    "        shutil.move(\"cnnbest.pt\", \"cnnbest2.pt\")\n",
    "    \n",
    "    elif loss < lowest_losses[2]:\n",
    "        # Update the third lowest loss\n",
    "        lowest_losses[2] = loss\n",
    "        \n",
    "        # Rename the file to reflect the new third lowest loss\n",
    "        shutil.move(\"cnnbest.pt\", \"cnnbest3.pt\")\n",
    "    \n",
    "    # If the current loss isn't among the top three, the temporary file \"cnnbest.pt\" can be removed\n",
    "    else:\n",
    "        os.remove(\"cnnbest.pt\")\n",
    "\n",
    "    # print something to monitor the training\n",
    "    print(f'Epoch: {i}, Validation Loss: {loss.item()}') # loss.item() = loss[0], which is the value of loss\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "total = end_time - start_time\n",
    "\n",
    "print(f'Training took: {total} seconds, or: {total/60} minutes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_losses)), [x.item() for x in train_losses])\n",
    "plt.title(\"Training Losses of Deep CNN\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(valid_losses)), [x.item() for x in valid_losses])\n",
    "plt.title(\"Validation Losses of Deep CNN\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_27780\\1095478608.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best1.load_state_dict(torch.load(\"cnnbest1.pt\"))\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_27780\\1095478608.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best2.load_state_dict(torch.load(\"cnnbest2.pt\"))\n",
      "C:\\Users\\brian\\AppData\\Local\\Temp\\ipykernel_27780\\1095478608.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best3.load_state_dict(torch.load(\"cnnbest3.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "accuracy of the best model: 61.2400016784668\n",
      "accuracy of the second-best model: 62.45000076293945\n",
      "accuracy of the third-best model: 62.68000030517578\n"
     ]
    }
   ],
   "source": [
    "best1 = CNN2()\n",
    "best2 = CNN2()\n",
    "best3 = CNN2()\n",
    "\n",
    "best1.load_state_dict(torch.load(\"cnnbest1.pt\"))\n",
    "best2.load_state_dict(torch.load(\"cnnbest2.pt\"))\n",
    "best3.load_state_dict(torch.load(\"cnnbest3.pt\"))\n",
    "\n",
    "len(test_data)\n",
    "# with torch.no_grad():\n",
    "#     for X_test, y_test in e\n",
    "#     y_eval1 = best3()\n",
    "\n",
    "test_corr_count1 = 0 \n",
    "test_corr_count2 = 0\n",
    "test_corr_count3 = 0 \n",
    "\n",
    "with torch.no_grad():\n",
    "    for b, (X_test, y_test) in enumerate(test_loader):\n",
    "\n",
    "        y_pred1 = best1(X_test)\n",
    "        predicted_class1 = torch.max(y_pred1.data, 1)[1]\n",
    "        batch_corr_count1 = (predicted_class1 == y_test).sum()\n",
    "        test_corr_count1 += batch_corr_count1\n",
    "\n",
    "        y_pred2 = best2(X_test)\n",
    "        predicted_class2 = torch.max(y_pred2.data, 1)[1]\n",
    "        batch_corr_count2 = (predicted_class2 == y_test).sum()\n",
    "        test_corr_count2 += batch_corr_count2\n",
    "\n",
    "        y_pred3 = best3(X_test)\n",
    "        predicted_class3 = torch.max(y_pred3.data, 1)[1]\n",
    "        batch_corr_count3 = (predicted_class3 == y_test).sum()\n",
    "        test_corr_count3 += batch_corr_count3\n",
    "\n",
    "print(b + 1)\n",
    "print(f'accuracy of the best model: {test_corr_count1*100/len(test_data)}')\n",
    "print(f'accuracy of the second-best model: {test_corr_count2*100/len(test_data)}')\n",
    "print(f'accuracy of the third-best model: {test_corr_count3*100/len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not great either\n",
    "- doesnt look like the issue is with CNN architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and future improvements\n",
    "- Have to deal with model overfitting\n",
    "- todo for next time:\n",
    "    - evaluation/debug\n",
    "        - instead of collecting number of total correct, collect number of correct for each class: can see if the model is weak at classifying some classes\n",
    "        - confusion matrices\n",
    "        - calculate accuracy/precision/recall\n",
    "    - regularization\n",
    "        - increase dropout\n",
    "        - weight decay\n",
    "        - early stopping patience\n",
    "    - normalize the data tensors\n",
    "    - try to make model generalize: implement stuff like: \n",
    "        - learning rate scheduling \n",
    "        - increase dropout\n",
    "        - data augmentation\n",
    "        - tweak hyperparameters (least likely to fix the issues completely since we did this)\n",
    "            - increase/decrease model depth \n",
    "                - Try changing model hyperparameters\n",
    "                - least likely to work since we did this "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
